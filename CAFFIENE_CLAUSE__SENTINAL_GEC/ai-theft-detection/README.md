# 店铺盗窃行为监测系统

基于YOLOv11n、XGBoost和自适应权重的店铺盗窃行为监测系统，可以分析图片和视频中的盗窃行为并识别可疑行为特征。系统支持零售环境自动识别，并根据不同场景智能匹配行为分析策略。

## 功能特点

- 支持图片和视频文件上传和分析
- 使用YOLOv11n进行对象检测
- 智能结合XGBoost机器学习模型和规则引擎进行盗窃行为判断
- 自动识别零售/非零售环境并调整行为分析策略
- 自适应权重系统，动态调整不同行为的重要性
- 实时识别多种可疑盗窃行为特征
- 分离的图像和视频行为检测模块
- 视频处理时在右侧显示可疑行为信息
- 环境智能分析（基于视觉特征和物体检测）
- 自动转换AVI格式输出为MP4格式，提高Web兼容性
- 视频分析结果实时自动滚动显示最新内容
- 视频测试页面用于诊断视频播放问题
- 同时支持窗体应用和Web应用两种运行模式
- 美观直观的用户界面
- 团伙行为识别，检测多人协同的可疑行为模式
- 基于MediaPipe的姿态分析，检测不自然或可疑的身体动作
- 增强的物品拿取和隐藏行为序列检测，实现高精度识别

## 系统架构

### 核心模块组成

1. **对象检测模块** - 基于YOLOv11n
   - 识别人物、商品、货架等物体
   - 生成边界框和类别信息
   - 支持多目标同时检测

2. **姿态估计模块** - 基于MediaPipe
   - 提取人体33个关键点
   - 计算关节角度和姿态特征
   - 生成姿态骨架数据

3. **行为分析模块**
   - **规则引擎**：基于专家知识的行为规则判断
   - **ML模型**：基于XGBoost的行为分类器
   - **自适应权重系统**：动态调整检测灵敏度
   - **行为序列分析**：检测连续的动作序列，如拿取并隐藏物品

4. **零售环境识别**
   - 基于检测物体的零售环境判断
   - 调整零售相关行为的检测权重

## 检测流程概述

系统通过以下流程处理视频和图像数据:

1. **初始化阶段**：加载YOLO模型和XGBoost行为分类器
2. **数据输入**：接收视频或图像文件
3. **检测处理**：
   - 对每一帧进行对象检测
   - 识别人物并提取姿态关键点
   - 计算行为特征向量
4. **行为分析**：
   - 规则引擎检测可疑姿态和动作
   - 行为序列分析识别多步骤行为（如拿取-隐藏序列）
   - ML模型预测行为类别
   - 融合多种结果并计算最终置信度
5. **环境感知**：
   - 识别环境是否为零售场景
   - 根据环境调整行为检测参数
6. **结果输出**：
   - 标记检测结果并输出带标注的图像/视频
   - 生成可疑行为列表及时间戳
   - 计算总体风险评分

## 项目目录结构

```
ai-theft-detection/
├── app/                      # 应用程序主要代码目录
│   ├── api/                  # API接口定义和实现
│   ├── controllers/          # 控制器模块
│   ├── models/               # 数据模型定义
│   ├── routes/               # 路由配置
│   ├── static/               # 静态资源文件
│   ├── templates/            # 模板文件
│   └── utils/                # 工具函数
│
├── src/                      # 核心源代码
│   ├── config/               # 配置文件目录
│   │   └── detector_config.json  # 检测器配置
│   ├── data/                 # 数据处理模块
│   ├── models/               # 模型定义和实现
│   │   ├── behavior/         # 行为检测相关模块
│   │   ├── common_detector.py # 基础检测器类
│   │   ├── image_detection.py # 图像检测实现
│   │   └── video_detection.py # 视频检测实现
│   └── utils/                # 实用工具和函数
│
├── models/                   # 模型文件存储目录
│   ├── standard/             # 标准模型
│   └── enhanced/             # 增强模型
│
├── scripts/                  # 脚本工具目录
│   ├── download_models.py    # 模型下载脚本
│   └── convert_video.py      # 视频转换工具
│
├── tests/                    # 测试代码
│   ├── test_behavior.py      # 行为检测测试
│   ├── test_detector.py      # 检测器测试
│   └── test_utils.py         # 工具函数测试
│
├── logs/                     # 日志文件目录
├── output/                   # 输出文件目录
├── docs/                     # 文档
├── requirements.txt          # 依赖项列表
├── run.py                    # 应用启动脚本
└── README.md                 # 项目说明文档
```

## 系统要求

- Python 3.8+
- Windows, macOS, 或 Linux 操作系统
- 2GB+ RAM (建议4GB+)
- CPU或支持CUDA的GPU (GPU可加速检测过程)

## 安装步骤

1. 克隆或下载此仓库

```bash
git clone https://XXXXXXXXXX/ai-theft-detection.git
cd ai-theft-detection
```

2. 安装所需依赖

```bash
pip install -r requirements.txt
```

3. 确保模型文件已下载到 `models` 目录:
   - `models/yolov11n.pt`: YOLOv11n模型文件
   - `models/standard/theft_xgb_model.pkl`: 标准XGBoost模型文件
   - `models/enhanced/enhanced_theft_xgb_model.pkl`: 增强XGBoost模型文件

如果模型文件未下载，可以运行下载脚本：

```bash
python download_models.py
```

## 使用方法

### 运行应用程序

本系统支持两种运行模式，您可以根据需要选择运行方式：

```bash
# 默认以窗体应用模式运行
python run.py

# 以Web应用模式运行，web方式功能不全，暂不推荐使用
python run.py --web

# 显式指定窗体应用模式
python run.py --gui
```

### 窗体应用模式

1. 运行窗体应用程序:

```bash
python run.py
```

2. 在应用程序界面中:
   - 点击"选择图片"或"选择视频"按钮上传媒体文件
   - 点击"开始分析"按钮进行盗窃行为检测
   - 分析过程中可点击"取消分析"按钮随时终止当前分析任务
   - 查看检测结果和可疑行为信息，行为列表会自动滚动显示最新内容
   - 检测结果以MP4格式输出，支持更好的兼容性
   - 点击"保存结果"按钮保存处理后的媒体文件

### Web应用模式

1. 运行Web应用程序:

```bash
python run.py --web
```

2. 在Web浏览器中访问:
   - 默认地址: http://localhost:5000
   - 上传图片或视频文件进行分析
   - 系统会自动识别可疑行为并在右侧显示详细信息
   - 对于视频，处理过的视频会保持固定窗口大小
   - 视频结果会自动转换为MP4格式，确保在所有浏览器中正常播放
   - 可以点击时间轴上的标记或行为列表中的"查看"按钮跳转到可疑行为发生时刻
   - 访问 http://localhost:5000/test 以使用视频测试页面诊断视频播放问题

## 检测流程详解

系统使用多层次融合的检测逻辑，结合机器学习模型和规则引擎进行盗窃行为的识别：

### 1. 输入处理
- 加载图片或视频
- 对视频进行逐帧处理
- 图像预处理优化检测效果

### 2. 对象检测
- 使用YOLOv11n模型检测人物和物体
- 生成对象边界框、类别和置信度
- 过滤低于阈值的检测结果

### 3. 零售环境判断
- 分析检测到的物体类别
- 评估是否为零售环境
- 调整对应检测参数

### 4. 姿态估计
- 对检测到的人物进行姿态分析
- 提取关键点坐标和可见性
- 生成姿态特征向量

### 5. 行为特征提取
- 从姿态数据计算角度、距离等特征
- 跟踪人物历史行为特征
- 生成行为分析输入数据

### 6. 多路径行为检测
- **规则引擎路径**：基于预定义规则判断行为
- **序列分析路径**：检测连续的动作序列模式
- **ML模型路径**：使用XGBoost预测行为类型
- 多路径结果进行加权融合

### 7. 自适应置信度调整
- 根据环境类型调整检测灵敏度
- 连续检测到同一行为时提高置信度
- 根据检测历史动态调整权重

### 8. 结果输出
- 标记检测到的行为及置信度
- 生成分析报告
- 保存处理后的图片或视频

### 自适应权重系统

系统实现了高度智能的自适应权重系统：

1. **初始化**：
   - 从配置文件加载初始权重
   - 为每种行为类型创建权重记录

2. **权重更新机制**：
   - 基于检测准确性动态调整权重
   - 使用指数移动平均算法平滑权重变化
   - 学习率：0.1（可在配置中调整）

3. **准确率评估**：
   - 跟踪每种行为的真阳性和假阳性
   - 计算整体准确率和近期表现（70%侧重近期）
   - 更高准确率的行为获得更高权重

4. **零售环境增强**：
   - 零售环境中特定行为获得置信度提升
   - 提升幅度：+0.2（可配置）
   - 主要针对"快速藏匿物品"和"可疑商品处理"

5. **连续行为增强**：
   - 连续3次以上检测到同一行为时增加权重
   - 每多检测1次增加0.05，最高不超过0.95

## 行为序列检测

系统采用先进的行为序列检测技术，能够识别由多个连续动作组成的复杂行为模式：

### 1. 物品拿取和隐藏序列检测

系统能够检测完整的物品拿取和隐藏行为序列，通过以下步骤实现：

1. **多阶段行为分析**：
   - **伸手动作**：检测手部从身体向外伸展的动作，特别关注正向运动矢量和方向变化
   - **抓取动作**：检测在伸手后手部向身体方向的收回动作
   - **隐藏动作**：检测手部接近身体中心或向下移动到口袋区域的动作

2. **时序约束**：
   - 行为必须按照伸手→抓取→隐藏的顺序发生
   - 各行为间隔时间有合理约束（如2秒内）
   - 行为必须连续多帧被检测到才被确认（避免误判）

3. **空间特征分析**：
   - 分析手腕相对于身体的位置变化
   - 监测手部与躯干的接近程度
   - 考虑手臂角度和运动轨迹的自然度

4. **连续性判断**：
   - 伸手动作需连续3帧以上才被确认
   - 抓取动作需连续2帧以上才被确认
   - 隐藏动作需连续2帧以上才被确认

5. **综合判定**：
   - 当完整序列被检测到时，系统给出高置信度的"grab_and_conceal"行为警报
   - 综合置信度：0.92（高于单一行为的置信度）

### 2. 行为历史跟踪

系统维护多种历史跟踪数据结构，确保行为检测的时间连续性：

1. **手腕位置历史**：
   - 跟踪最近40帧的手腕位置
   - 使用相对于身体的坐标系统，减少姿势变化影响

2. **行为阶段跟踪**：
   - 记录每只手的伸手、抓取和隐藏阶段状态
   - 防止同一行为被重复报告

3. **事件记录**：
   - 记录已报告的完整行为序列
   - 使用唯一事件ID确保不重复报告同一序列

### 3. 误报控制机制

系统采用多层防误报机制，确保检测的准确性：

1. **动作幅度过滤**：
   - 过滤小幅动作，只检测显著的手部运动
   - 要求手部运动达到一定幅度（肩宽的20%以上）

2. **方向变化分析**：
   - 计算手部运动方向变化频率
   - 频繁方向变化被视为随机动作，不触发行为检测

3. **定期重置**：
   - 每100帧重置所有检测状态，防止过时状态影响判断
   - 长时间未完成的行为序列会被自动取消

4. **环境适配**：
   - 在零售环境中提高检测敏感度
   - 非零售环境降低某些行为的检测权重

## 支持的行为类型

系统能够检测以下可疑行为：

| 行为类型 | 中文名称 | 当前权重 | 描述 |
|---------|--------|------|-----|
| Covering Product Area | 遮挡商品区域 | 0.6 | 用身体遮挡商品区域，可能是为了掩盖偷窃行为 |
| Unusual Elbow Position | 手肘内收姿态异常 | 0.6 | 手肘内收的不自然姿势，可能是隐藏物品 |
| Repetitive Position Adjustment | 反复调整位置 | 0.6 | 频繁调整站立位置，表现出紧张不安 |
| Suspected Tag Removal | 疑似撕标签动作 | 0.5 | 手部动作疑似在移除防盗标签 |
| Suspicious Item Handling | 可疑商品处理 | 0.8 | 对商品进行异常操作，可能准备偷窃 |
| Rapid Item Concealment | 快速藏匿物品 | 0.8 | 快速将物品藏入衣物或随身物品中 |
| Abnormal Arm Position | 手臂位置异常 | 0.7 | 手臂呈不自然角度或位置 |
| Suspicious Crouching | 可疑蹲姿 | 0.7 | 蹲下姿势可能是为了拿取或藏匿物品 |
| Unusual Reaching | 不自然的伸手姿势 | 0.7 | 伸手动作异常，可能是取拿高处物品 |
| Body Shielding | 身体屏蔽姿势 | 0.7 | 用身体挡住视线，掩护偷窃行为 |
| Abnormal Head Movement | 头部异常转动 | 0.6 | 频繁观望，检查是否有人注意 |
| Single Arm Hiding | 单臂遮挡 | 0.8 | 单臂遮挡动作，可能是隐藏物品 |
| Concealment Gesture | 遮掩隐藏手势 | 0.7 | 遮掩性质的手势，用于掩盖行为 |
| Distraction Behavior | 分散注意力行为 | 0.8 | 试图分散店员或其他顾客注意力 |
| Group Theft Coordination | 团伙盗窃配合 | 0.8 | 多人协作的可疑盗窃行为 |
| Reaching Motion | 伸手动作 | 0.7 | 手部伸展动作，可能是准备拿取物品 |
| Item Grabbing | 物品抓取 | 0.8 | 拿取物品的行为 |
| Item Concealment | 物品隐藏 | 0.75 | 将物品隐藏的行为 |
| Grab and Conceal | 抓取并隐藏 | 0.92 | 完整的拿取物品并隐藏的行为序列 |
| Hands Behind Back | 双手背后 | 0.85 | 双手放在背后，可能隐藏物品 |
| One Hand Behind Back | 单手背后 | 0.75 | 单手放在背后，可能隐藏物品 |

## 模型技术细节

### 1. 对象检测 - YOLOv11n

- **模型类型**：单阶段检测器
- **输入尺寸**：640x640像素
- **支持类别**：COCO数据集80个类别
- **推理速度**：~45FPS (CPU), ~120FPS (GPU)
- **置信度阈值**：0.25（可配置）

### 2. 姿态估计 - MediaPipe

- **关键点数量**：33个人体关键点
- **输出格式**：归一化坐标(x,y,z)和可见性(visibility)
- **支持单/多人**：单帧最多检测6人

### 3. 行为分类 - XGBoost

- **模型类型**：
  - 标准模型：基于8个静态特征
  - 增强模型：基于14个静态+动态特征
- **特征维度**：8-14维向量
- **分类类别**：盗窃行为 vs 正常行为
- **融合策略**：ML模型权重0.4，规则引擎权重0.6

### 4. 行为序列分析

- **检测算法**：基于状态机和时序分析
- **特征提取**：分段式动作特征分析
- **阈值机制**：动态阈值基于肩宽和身高比例
- **误报控制**：多层连续性确认机制

## 模型训练方法

### 1. XGBoost模型

系统使用两种XGBoost模型：标准模型和增强模型

#### 标准XGBoost模型：

- **训练数据**：
  - 标准数据集：约800个人体姿态样本
  - 正样本：约700个盗窃行为姿态（7种盗窃行为类型）
  - 负样本：约100个正常行为姿态
  - 每种行为类型生成100个样本（在`download_pose_data.py`中设置）

- **行为类型**：
  - normal（正常行为）
  - abnormal_arm（异常手臂位置）
  - crouching（蹲姿）
  - reaching（伸手）
  - body_shielding（身体屏蔽）
  - head_movement（异常头部运动）

## 开发者接口

主要类和方法：

### 1. VideoDetector类

处理视频分析的核心类，继承自CommonDetector

```python
from src.models.video_detection import VideoDetector

# 初始化检测器
detector = VideoDetector(model_path="models/yolov11n.pt")

# 分析视频
results = detector.analyze_video(
    video_path="input.mp4",
    output_path="output.mp4",
    max_frames=None,  # 处理所有帧
    frame_interval=1,  # 每帧都处理
    conf_threshold=0.25  # 检测置信度阈值
)
```

### 2. VideoBehaviorDetector类

处理行为检测的专用类

```python
from src.models.behavior.video_behavior import VideoBehaviorDetector

# 初始化行为检测器
behavior_detector = VideoBehaviorDetector()

# 在单帧图像上检测行为
behaviors = behavior_detector.detect_behaviors_in_image(image, detections)

# 分析视频中的行为
output_path, suspicious_frames, behaviors = behavior_detector.analyze_video_behavior(
    video_path, detector
)
```

### 3. 行为序列检测接口

```python
# 获取行为检测器中的序列分析结果
detector = VideoBehaviorDetector()

# 处理单帧并获取行为
processed_frame, frame_results, behaviors = detector.process_frame(
    frame=current_frame,
    frame_number=frame_idx,
    prev_frame=previous_frame,
    object_history=objects_history,
    prev_person_data=previous_person_data
)

# 从behaviors中获取检测到的行为
for behavior in behaviors:
    if behavior['type'] == 'grab_and_conceal':
        print(f"检测到抓取并隐藏行为，置信度: {behavior['confidence']}")
```

## 配置调整

系统配置文件位于`src/config/detector_config.json`，可以根据需要调整：

- 行为权重
- 检测阈值
- 零售环境配置
- 模型路径
- 本地化设置

### 自定义行为检测

可以通过在`detector_config.json`中添加或调整以下内容来自定义行为检测：

```json
"initial_behavior_weights": {
  "Custom_Behavior": 0.7
},
"behavior_mapping": {
  "Custom_Category": ["Custom_Behavior"]
},
"localization": {
  "en": {
    "behavior_names": {
      "Custom_Behavior": "Custom Behavior Name"
    }
  },
  "zh": {
    "behavior_names": {
      "Custom_Behavior": "自定义行为名称"
    }
  }
}
```

## 判定标准

系统使用多层次判定标准确定盗窃行为：

1. **单一行为判定**：
   - 每种行为有独立的置信度阈值（0.5-0.95）
   - 初始权重在配置文件中设定
   - 通过自适应系统动态调整

2. **行为序列判定**：
   - 伸手→抓取→隐藏的完整序列具有最高可信度(0.92)
   - 序列必须在合理时间内完成(约2秒内)
   - 各阶段行为必须连续多帧确认

3. **行为组合判定**：
   - 多种可疑行为同时出现时，系统进行组合分析
   - 组合分析权重：行为类型、持续时间、发生顺序

4. **ML模型判定**：
   - 当XGBoost模型预测概率 > 0.5 时标记为可疑
   - 模型评分与规则引擎结果进行加权融合
   - ML模型权重：0.4，规则引擎权重：0.6

5. **最终判定**：
   - 融合得分 ≥ 0.7：高度可疑（红色标记）
   - 融合得分 0.5-0.7：中度可疑（黄色标记）
   - 融合得分 < 0.5：正常行为

## 性能优化建议

- 使用GPU加速YOLO模型和MediaPipe姿态估计
- 调整frame_interval以平衡性能和准确性
- 针对特定场景优化行为权重配置
- 使用更高分辨率视频提高检测精度
- 调整连续性检测阈值以优化特定环境的检测精度 