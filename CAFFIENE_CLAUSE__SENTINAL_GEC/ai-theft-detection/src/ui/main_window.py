import os
import sys
import cv2
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from PIL import Image, ImageTk
import threading
import time
import numpy as np
from pathlib import Path
import datetime
import logging
import re
import random

# Add src directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.models.detection import TheftDetector
from src.utils.video_processor import VideoProcessor

class TheftDetectionApp:
    def __init__(self, root, model_path="models/yolov11n.pt"):
        """Initialize the application"""
        # è®¾ç½®åº”ç”¨çª—å£
        self.root = root
        self.root.title("åº—é“ºç›—çªƒè¡Œä¸ºç›‘æµ‹ç³»ç»Ÿ")
        
        # è®¾ç½®çŠ¶æ€å˜é‡
        self.current_media_path = None
        self.current_media_type = None
        self.processed_media_path = None
        self.video_capture = None
        self.processed_video_capture = None
        self.stop_video_thread = False
        self.is_playing = False
        self.current_frame = 0
        self.video_thread = None
        self.is_processing = False
        
        # Initialize detection service - æ¨è¿Ÿåˆå§‹åŒ–ä»¥å‡å°‘å¯åŠ¨æ—¶é—´
        self.theft_detector = None  # å°†åœ¨éœ€è¦æ—¶åˆå§‹åŒ–
        self.video_processor = VideoProcessor()
        
        # æ·»åŠ å…¼å®¹æ€§å±æ€§
        self.detector = None  # å…¼å®¹æ—§ä»£ç ï¼Œä¼šåœ¨åˆå§‹åŒ–theft_detectoræ—¶åŒæ­¥æ›´æ–°
        
        # Processing state
        self.is_processing = False
        self.current_media_path = None
        self.current_media_type = None  # 'image' or 'video'
        self.video_capture = None
        self.video_thread = None
        self.stop_video_thread = False
        self.processed_media_path = None
        self.processed_video_capture = None
        self.is_playing = False  # æ·»åŠ è§†é¢‘æ’­æ”¾çŠ¶æ€å˜é‡
        
        # Create UI components
        self.create_ui()
        
        # ç»‘å®šçª—å£è°ƒæ•´å¤§å°äº‹ä»¶
        self.root.bind("<Configure>", self.on_window_configure)
        
        # è®¾ç½®å…¨å±å¿«æ·é”®
        self.root.bind("<F11>", self.toggle_fullscreen)
        self.root.bind("<Escape>", self.end_fullscreen)
        
        # åˆå§‹åŒ–å…¨å±çŠ¶æ€
        self.is_fullscreen = False
        
        # å±…ä¸­æ˜¾ç¤ºçª—å£
        self._center_window()
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.log("åº—é“ºç›—çªƒè¡Œä¸ºç›‘æµ‹ç³»ç»Ÿå·²å¯åŠ¨")
        
        # é…ç½®æ—¥å¿—é‡å®šå‘ï¼Œå°†æ£€æµ‹æ¨¡å—æ—¥å¿—æ•è·å¹¶å†™å…¥UI
        self.configure_logging_redirect()
    
    def configure_logging_redirect(self):
        """é…ç½®æ—¥å¿—é‡å®šå‘ï¼Œå°†æ£€æµ‹æ¨¡å—çš„æ—¥å¿—è½¬å‘åˆ°UIç•Œé¢"""
        import logging
        
        # åˆ›å»ºä¸€ä¸ªå¤„ç†å™¨ï¼Œå°†æ—¥å¿—æ¶ˆæ¯è½¬å‘åˆ°UI
        class UILogHandler(logging.Handler):
            def __init__(self, ui_instance):
                super().__init__()
                self.ui = ui_instance
                
            def emit(self, record):
                # æ—¥å¿—è®°å½•è½¬å‘åˆ°UI
                log_message = self.format(record)
                
                # å¦‚æœæ—¥å¿—æ¶ˆæ¯æ¥è‡ªdetectionæ¨¡å—ï¼Œä½¿ç”¨self.logè®°å½•åˆ°UI
                # ä½¿ç”¨root.afterç¡®ä¿åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
                self.ui.root.after(0, lambda: self.ui.log(log_message))
        
        # é…ç½®å¤„ç†å™¨
        handler = UILogHandler(self)
        formatter = logging.Formatter('%(message)s')  # ç®€åŒ–æ ¼å¼ï¼Œå› ä¸ºUIæ—¥å¿—ä¼šæ·»åŠ æ—¶é—´æˆ³
        handler.setFormatter(formatter)
        
        # è·å–detectionæ—¥å¿—è®°å½•å™¨å¹¶æ·»åŠ å¤„ç†å™¨
        logger = logging.getLogger('detection')
        logger.addHandler(handler)
        
        # ç¡®ä¿æ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºINFOæˆ–æ›´ä½
        if logger.level > logging.INFO:
            logger.setLevel(logging.INFO)
    
    def create_ui(self):
        """Create the main interface"""
        # è®¾ç½®çª—å£æœ€å°å°ºå¯¸
        self.root.minsize(1024, 768)
        
        # è®¾ç½®åˆå§‹çª—å£å¤§å°
        self.default_width = 1280
        self.default_height = 800
        self.root.geometry(f"{self.default_width}x{self.default_height}")
        
        # è®¾ç½®çª—å£å±…ä¸­
        self._center_window()
        
        # å­˜å‚¨å½“å‰çª—å£çŠ¶æ€
        self.is_maximized = False
        self.last_known_width = self.default_width
        self.last_known_height = self.default_height
        
        # åˆ›å»ºä¸»æ»šåŠ¨åŒºåŸŸ
        self.main_scroll = ttk.Scrollbar(self.root, orient=tk.VERTICAL)
        self.main_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        # åˆ›å»ºå¯æ»šåŠ¨çš„ç”»å¸ƒ
        self.main_canvas = tk.Canvas(self.root, yscrollcommand=self.main_scroll.set)
        self.main_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        # é…ç½®æ»šåŠ¨æ¡
        self.main_scroll.config(command=self.main_canvas.yview)
        
        # åˆ›å»ºæ¡†æ¶æ”¾åœ¨ç”»å¸ƒå†…
        self.main_frame = ttk.Frame(self.main_canvas)
        self.main_canvas.create_window((0, 0), window=self.main_frame, anchor=tk.NW, tags="self.main_frame")
        
        # ç»‘å®šæ¡†æ¶å¤§å°å˜åŒ–äº‹ä»¶
        self.main_frame.bind("<Configure>", self._configure_main_canvas)
        
        # Main frame
        #self.main_frame = ttk.Frame(self.root)
        #self.main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Top section - Media display
        self.media_frame = ttk.Frame(self.main_frame)
        self.media_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Side by side view (original and processed)
        self.original_frame = ttk.LabelFrame(self.media_frame, text="åŸå§‹åª’ä½“")
        self.original_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        self.processed_frame = ttk.LabelFrame(self.media_frame, text="æ£€æµ‹ç»“æœ")
        self.processed_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # ä½¿ç”¨å›ºå®šæ¯”ä¾‹çš„å¸§æ¥åŒ…å«ç”»å¸ƒï¼Œç¡®ä¿è§†é¢‘åŒºåŸŸç¨³å®š
        self.original_canvas_frame = ttk.Frame(self.original_frame)
        self.original_canvas_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        self.processed_canvas_frame = ttk.Frame(self.processed_frame)
        self.processed_canvas_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Original media canvas - å“åº”å¼å°ºå¯¸
        self.original_canvas = tk.Canvas(self.original_canvas_frame, bg="black", highlightthickness=0)
        self.original_canvas.pack(fill=tk.BOTH, expand=True)
        
        # Processed media canvas - å“åº”å¼å°ºå¯¸
        self.processed_canvas = tk.Canvas(self.processed_canvas_frame, bg="black", highlightthickness=0)
        self.processed_canvas.pack(fill=tk.BOTH, expand=True)
        
        # æ·»åŠ è§†é¢‘æ’­æ”¾æ§åˆ¶åŒºåŸŸ - æ”¾åœ¨è§†é¢‘ä¸‹æ–¹ï¼Œä½†åˆå§‹æ—¶éšè—
        self.playback_control_frame = ttk.Frame(self.main_frame)
        # æ³¨æ„ï¼šä¸åœ¨åˆå§‹åŒ–æ—¶packï¼Œè€Œæ˜¯åœ¨è§†é¢‘å¤„ç†å®Œæˆåæ‰æ˜¾ç¤º

        # æ·»åŠ æ’­æ”¾/æš‚åœæŒ‰é’®
        self.play_pause_btn = ttk.Button(self.playback_control_frame, text="æ’­æ”¾", width=10, command=self.toggle_playback)
        self.play_pause_btn.pack(side=tk.LEFT, padx=5)
        
        # æ·»åŠ è§†é¢‘è¿›åº¦æ¡
        self.progress_var = tk.DoubleVar(value=0)
        self.video_slider = ttk.Scale(self.playback_control_frame, orient=tk.HORIZONTAL, 
                                    from_=0, to=100, variable=self.progress_var, 
                                    command=self.on_slider_change)
        self.video_slider.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=10)
        
        # æ·»åŠ è§†é¢‘æ—¶é—´æ ‡ç­¾
        self.time_label = ttk.Label(self.playback_control_frame, text="00:00 / 00:00")
        self.time_label.pack(side=tk.LEFT, padx=5)
        
        # è®¡ç®—å¹¶è®¾ç½®åˆå§‹ç”»å¸ƒå°ºå¯¸
        self.update_canvas_sizes()
        
        # é…ç½®çª—å£è°ƒæ•´å¤§å°äº‹ä»¶ï¼Œä½†é™åˆ¶æ›´æ–°é¢‘ç‡
        self.root.bind("<Configure>", self.on_window_configure)
        
        # ç»‘å®šçª—å£æœ€å¤§åŒ–å’Œæ¢å¤äº‹ä»¶
        self.root.bind("<F11>", self.toggle_fullscreen)
        self.root.bind("<Escape>", self.end_fullscreen)
        
        # Middle section - Control area
        self.control_frame = ttk.Frame(self.main_frame)
        self.control_frame.pack(fill=tk.X, pady=5)
        
        # ä¿®æ”¹æ§åˆ¶æŒ‰é’®å¸ƒå±€ - å·¦ä¾§æ”¾æ–‡ä»¶é€‰æ‹©æŒ‰é’®ï¼Œå³ä¾§æ”¾å¤„ç†å’Œä¿å­˜æŒ‰é’®
        # File selection buttons - å·¦ä¾§å›ºå®š
        self.file_btn_frame = ttk.Frame(self.control_frame)
        self.file_btn_frame.pack(side=tk.LEFT, padx=5)
        
        self.select_image_btn = ttk.Button(self.file_btn_frame, text="é€‰æ‹©å›¾ç‰‡", command=self.select_image)
        self.select_image_btn.pack(side=tk.LEFT, padx=5)
        
        self.select_video_btn = ttk.Button(self.file_btn_frame, text="é€‰æ‹©è§†é¢‘", command=self.select_video)
        self.select_video_btn.pack(side=tk.LEFT, padx=5)
        
        # Processing buttons - å³ä¾§
        self.process_btn_frame = ttk.Frame(self.control_frame)
        self.process_btn_frame.pack(side=tk.RIGHT, padx=5)
        
        self.process_btn = ttk.Button(self.process_btn_frame, text="å¼€å§‹åˆ†æ", command=self.start_processing)
        self.process_btn.pack(side=tk.LEFT, padx=5)
        self.process_btn.state(['disabled'])
        
        self.save_btn = ttk.Button(self.process_btn_frame, text="ä¿å­˜ç»“æœ", command=self.save_result)
        self.save_btn.pack(side=tk.LEFT, padx=5)
        self.save_btn.state(['disabled'])
        
        # Status labels
        self.status_frame = ttk.Frame(self.main_frame)
        self.status_frame.pack(fill=tk.X, pady=5)
        
        ttk.Label(self.status_frame, text="çŠ¶æ€:").pack(side=tk.LEFT, padx=5)
        self.status_label = ttk.Label(self.status_frame, text="å°±ç»ª")
        self.status_label.pack(side=tk.LEFT, padx=5)
        
        # Progress bar
        self.progress_frame = ttk.Frame(self.main_frame)
        self.progress_frame.pack(fill=tk.X, pady=5)
        
        # åˆ›å»ºä¸€ä¸ªåŒ…å«è¿›åº¦æ¡å’Œæ ‡ç­¾çš„æ¡†æ¶
        self.progress_container = ttk.Frame(self.progress_frame)
        self.progress_container.pack(fill=tk.X, padx=5)
        
        # åˆ›å»ºä¸€ä¸ªæ›´æ˜æ˜¾çš„è¿›åº¦æ¡æ ·å¼
        style = ttk.Style()
        style.configure(
            "Thick.Horizontal.TProgressbar", 
            thickness=20,                   # å¢åŠ è¿›åº¦æ¡é«˜åº¦
            background='#4a8af4',           # è¿›åº¦æ¡å¡«å……é¢œè‰²
            troughcolor='#e0e0e0'           # è¿›åº¦æ¡èƒŒæ™¯é¢œè‰²
        )
        
        # åˆ›å»ºè¿›åº¦æ¡ - è®¾ç½®é«˜åº¦è¾ƒé«˜ä»¥ä¾¿æ”¾ç½®æ–‡æœ¬
        self.progress_bar = ttk.Progressbar(
            self.progress_container, 
            orient=tk.HORIZONTAL, 
            mode='determinate',
            length=100,  # ä¼šè¢«packå¡«å……
            style="Thick.Horizontal.TProgressbar"
        )
        self.progress_bar.pack(fill=tk.X, pady=2)
        
        # åˆ›å»ºä¸€ä¸ªStringVarç”¨äºç™¾åˆ†æ¯”æ–‡æœ¬
        self.progress_text = tk.StringVar(value="0%")
        
        # åˆ›å»ºæ ‡ç­¾æ¡†æ¶ä½¿å…¶æœ‰èƒŒæ™¯è‰²
        self.label_frame = tk.Frame(
            self.progress_container,
            bg='#f0f0f0',  # æµ…ç°è‰²èƒŒæ™¯
            bd=1,          # è¾¹æ¡†å¤§å°
            relief=tk.RAISED  # è¾¹æ¡†æ ·å¼
        )
        
        # åˆ›å»ºæ ‡ç­¾ï¼Œç›´æ¥æ”¾åœ¨è¿›åº¦æ¡ä¸Šå¹¶å±…ä¸­
        self.progress_label = ttk.Label(
            self.label_frame, 
            textvariable=self.progress_text,
            anchor="center",
            font=("Arial", 9, "bold"),
            foreground="#000080",  # æ·±è“è‰²æ–‡æœ¬
            background='#f0f0f0'   # ä¸æ ‡ç­¾æ¡†æ¶åŒ¹é…çš„èƒŒæ™¯è‰²
        )
        self.progress_label.pack(padx=5, pady=1)
        
        # ä½¿ç”¨placeå¸ƒå±€å°†æ ‡ç­¾æ¡†æ¶æ”¾åœ¨è¿›åº¦æ¡çš„ä¸­å¿ƒ
        self.progress_bar.update()  # ç¡®ä¿è¿›åº¦æ¡å°ºå¯¸å·²æ›´æ–°
        self.label_frame.place(relx=0.5, rely=0.5, anchor="center")
        
        # æ·»åŠ å¯ç–‘è¡Œä¸ºé¢æ¿
        self.behaviors_frame = ttk.LabelFrame(self.main_frame, text="å¯ç–‘è¡Œä¸º")
        self.behaviors_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # å·¦å³å¸ƒå±€ï¼šå·¦ä¾§æ—¥å¿—ï¼Œå³ä¾§å¯ç–‘è¡Œä¸º
        self.log_behavior_frame = ttk.Frame(self.behaviors_frame)
        self.log_behavior_frame.pack(fill=tk.BOTH, expand=True)
        
        # å·¦ä¾§ - æ—¥å¿—é¢æ¿
        self.result_frame = ttk.LabelFrame(self.log_behavior_frame, text="æ£€æµ‹æ—¥å¿—")
        self.result_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Log text area with scrollbar
        self.log_text = tk.Text(self.result_frame, height=10, wrap=tk.WORD)
        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        self.log_scrollbar = ttk.Scrollbar(self.result_frame, command=self.log_text.yview)
        self.log_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.log_text.config(yscrollcommand=self.log_scrollbar.set)
        
        # å³ä¾§ - å¯ç–‘è¡Œä¸ºåˆ—è¡¨
        self.behavior_list_frame = ttk.LabelFrame(self.log_behavior_frame, text="è¡Œä¸ºåˆ—è¡¨")
        self.behavior_list_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # åˆ›å»ºå¯ç–‘è¡Œä¸ºåˆ—è¡¨
        self.behavior_list = ttk.Treeview(self.behavior_list_frame, columns=("æ—¶é—´", "ç±»å‹", "æ¦‚ç‡"), show="headings")
        self.behavior_list.heading("æ—¶é—´", text="æ—¶é—´")
        self.behavior_list.heading("ç±»å‹", text="è¡Œä¸ºç±»å‹")
        self.behavior_list.heading("æ¦‚ç‡", text="å¯ä¿¡åº¦")
        self.behavior_list.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        self.behavior_scrollbar = ttk.Scrollbar(self.behavior_list_frame, command=self.behavior_list.yview)
        self.behavior_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.behavior_list.config(yscrollcommand=self.behavior_scrollbar.set)
    
    def log(self, message, console_only=False):
        """Add message to log area
        
        Args:
            message: The message to log
            console_only: If True, only logs to console and not to the UI
        """
        try:
            # è®°ä½å½“å‰æ»šåŠ¨ä½ç½®
            try:
                current_view = self.log_text.yview()
            except:
                current_view = (0, 0)
                
            # å§‹ç»ˆå‘æ§åˆ¶å°è¾“å‡º
            timestamp = time.strftime("%H:%M:%S")
            print(f"[{timestamp}] {message}")
            
            # å¦‚æœæ˜¯åªè¾“å‡ºåˆ°æ§åˆ¶å°çš„æ¶ˆæ¯ï¼Œä¸æ·»åŠ åˆ°UI
            if console_only:
                return
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¯ç–‘è¡Œä¸ºæ£€æµ‹ä¿¡æ¯ - è¿™äº›æ¶ˆæ¯éœ€è¦æ˜¾ç¤º
            is_suspicious_behavior = "æ£€æµ‹åˆ°è¡Œä¸º:" in message or "æ·»åŠ è¡Œä¸ºåˆ°åˆ—è¡¨" in message
            
            if is_suspicious_behavior:
                if "æ£€æµ‹åˆ°è¡Œä¸º:" in message:
                    # è¿™æ˜¯ä¸€ä¸ªè¯¦ç»†çš„è¡Œä¸ºæè¿°
                    parts = message.split("è¡Œä¸ºæè¿°:")
                    behavior_info = parts[0].strip()
                    behavior_desc = parts[1].strip() if len(parts) > 1 else ""
                    
                    # æå–å¯ä¿¡åº¦
                    confidence_match = re.search(r'å¯ä¿¡åº¦: (\d+\.\d+%)', behavior_info)
                    confidence_str = confidence_match.group(1) if confidence_match else "æœªçŸ¥"
                    
                    # æ’å…¥å¸¦æœ‰é«˜äº®æ ¼å¼çš„è­¦å‘Šæ¶ˆæ¯
                    self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                    self.log_text.insert(tk.END, f"âš ï¸ {behavior_info}\n", "behavior_alert")
                    self.log_text.insert(tk.END, f"   {behavior_desc}\n", "behavior_desc")
                    
                    # é…ç½®æ ‡ç­¾æ ·å¼
                    self.log_text.tag_configure("timestamp", foreground="blue")
                    self.log_text.tag_configure("behavior_alert", foreground="#FF3300", font=("Helvetica", 10, "bold"))
                    self.log_text.tag_configure("behavior_desc", foreground="#993300", font=("Helvetica", 9, "italic"))
                elif "æ·»åŠ è¡Œä¸ºåˆ°åˆ—è¡¨" in message:
                    # æå–å¯ä¿¡åº¦
                    confidence_match = re.search(r'å¯ä¿¡åº¦=(\d+\.\d+)', message)
                    if confidence_match:
                        confidence = float(confidence_match.group(1))
                        # åªåœ¨å¯ä¿¡åº¦è¾ƒé«˜æ—¶æ‰åœ¨æ£€æµ‹æ—¥å¿—ä¸­é«˜äº®æ˜¾ç¤ºï¼Œä½†æ€»æ˜¯æ˜¾ç¤º
                        confidence_tag = "high_confidence" if confidence > 0.7 else "medium_confidence" if confidence > 0.5 else "low_confidence"
                    else:
                        confidence_tag = "medium_confidence"
                    
                    # æå–å¸§ä¿¡æ¯
                    frame_match = re.search(r'å¸§=(\d+)', message)
                    frame_num = frame_match.group(1) if frame_match else "æœªçŸ¥"
                    
                    # æå–è¡Œä¸ºç±»å‹å’Œæ—¶é—´
                    type_match = re.search(r'ç±»å‹=([^,]+)', message)
                    behavior_type = type_match.group(1) if type_match else "æœªçŸ¥è¡Œä¸º"
                    
                    time_match = re.search(r'æ—¶é—´=(\d+\.\d+)', message)
                    time_point = float(time_match.group(1)) if time_match else 0.0
                    
                    # æå–æ¦‚ç‡
                    probability_match = re.search(r'å¯ä¿¡åº¦=(\d+\.\d+)', message)
                    probability = float(probability_match.group(1)) if probability_match else 0.0
                    
                    # æ ¼å¼åŒ–é«˜äº®è­¦å‘Šæ¶ˆæ¯
                    warning_message = f"åœ¨ç¬¬{frame_num}å¸§ ({time_point:.2f}ç§’) æ£€æµ‹åˆ°è¡Œä¸º: {behavior_type}"
                    
                    # æ’å…¥å¸¦æœ‰é«˜äº®æ ¼å¼çš„è­¦å‘Šæ¶ˆæ¯
                    self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                    self.log_text.insert(tk.END, warning_message, confidence_tag)
                    self.log_text.insert(tk.END, f" (å¯ä¿¡åº¦: {probability:.2%})\n", "confidence")
                    
                    # é…ç½®é«˜äº®æ ‡ç­¾æ ·å¼
                    self.log_text.tag_configure("timestamp", foreground="blue")
                    self.log_text.tag_configure("high_confidence", foreground="#CC0000", font=("Helvetica", 10, "bold"))
                    self.log_text.tag_configure("medium_confidence", foreground="#FF6600", font=("Helvetica", 10))
                    self.log_text.tag_configure("low_confidence", foreground="#666666", font=("Helvetica", 9))
                    self.log_text.tag_configure("confidence", foreground="#333333", font=("Helvetica", 9))
                
                # æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
                self.log_text.see(tk.END)
                return
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºè¿›åº¦ä¿¡æ¯ï¼Œä½¿ç”¨ç‰¹æ®Šæ ¼å¼
            if "å¤„ç†è¿›åº¦" in message:
                # æ˜¾ç¤ºè¿›åº¦ä½†ä¸è¦å¤ªé¢‘ç¹
                if random.random() < 0.05:  # åªæ˜¾ç¤ºçº¦5%çš„è¿›åº¦æ›´æ–°ï¼Œå‡å°‘æ—¥å¿—åˆ·å±
                    self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                    self.log_text.insert(tk.END, message, "progress")
                    self.log_text.insert(tk.END, "\n")
                return
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºç›—çªƒè¡Œä¸ºæ£€æµ‹ç»“æœ
            elif "æ¢æµ‹ç›—çªƒè¡Œä¸º" in message or "æ£€æµ‹å®Œæˆ" in message:
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                
                # æ£€æŸ¥ç»“æœç±»å‹
                if "å‘ç°ç›—çªƒè¡Œä¸º" in message:
                    self.log_text.insert(tk.END, "ğŸš¨ ", "alert_icon")
                    self.log_text.insert(tk.END, message, "theft_yes")
                elif "æœªå‘ç°ç›—çªƒè¡Œä¸º" in message:
                    self.log_text.insert(tk.END, "âœ… ", "check_icon")
                    self.log_text.insert(tk.END, message, "theft_no")
                else:
                    # é»˜è®¤æƒ…å†µ
                    self.log_text.insert(tk.END, message, "normal")
                    
                self.log_text.insert(tk.END, "\n")
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºç›—çªƒæ¦‚ç‡ä¿¡æ¯
            elif "ç›—çªƒæ¦‚ç‡:" in message:
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                
                # æå–æ¦‚ç‡å€¼
                prob_match = re.search(r'ç›—çªƒæ¦‚ç‡: (\d+\.\d+%)', message)
                if prob_match:
                    prob_str = prob_match.group(1)
                    prob = float(prob_str.strip('%')) / 100
                    
                    # åˆ†ç¦»æ¶ˆæ¯çš„ä¸åŒéƒ¨åˆ†
                    before, after = message.split("ç›—çªƒæ¦‚ç‡:")
                    self.log_text.insert(tk.END, before + "ç›—çªƒæ¦‚ç‡: ", "normal")
                    
                    # æ ¹æ®æ¦‚ç‡å€¼ä½¿ç”¨ä¸åŒé¢œè‰²
                    if prob > 0.7:
                        self.log_text.insert(tk.END, after, "high_probability")
                    elif prob > 0.4:
                        self.log_text.insert(tk.END, after, "medium_probability")
                    else:
                        self.log_text.insert(tk.END, after, "low_probability")
                else:
                    # é»˜è®¤æƒ…å†µ
                    self.log_text.insert(tk.END, message, "normal")
                
                self.log_text.insert(tk.END, "\n")
                
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¡Œä¸ºåˆ†æä¿¡æ¯
            elif "è¡Œä¸ºåˆ†æ:" in message or "è¡Œä¸ºå¹³å‡å¯ç–‘åº¦:" in message:
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                
                # æ·»åŠ å›¾æ ‡å‰ç¼€
                if "è¡Œä¸ºåˆ†æ:" in message:
                    self.log_text.insert(tk.END, "ğŸ“Š ", "chart_icon")
                elif "è¡Œä¸ºå¹³å‡å¯ç–‘åº¦:" in message:
                    self.log_text.insert(tk.END, "ğŸ“ˆ ", "trend_icon")
                
                self.log_text.insert(tk.END, message, "behavior_summary")
                self.log_text.insert(tk.END, "\n")
                
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç´¯è®¡å‘ç°ä¿¡æ¯
            elif "å½“å‰ç´¯è®¡å‘ç°å¯ç–‘è¡Œä¸º" in message or "è¡Œä¸ºåˆ—è¡¨ä¸­å…±æœ‰" in message or "å·²æ·»åŠ " in message and "æ¡è¡Œä¸ºè®°å½•åˆ°ç•Œé¢" in message:
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                self.log_text.insert(tk.END, "ğŸ“‘ ", "document_icon")
                self.log_text.insert(tk.END, message, "summary")
                self.log_text.insert(tk.END, "\n")
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºç¯å¢ƒåˆ¤æ–­æ¶ˆæ¯
            elif "ç¯å¢ƒåˆ¤æ–­ä¸º" in message:
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                
                # æ·»åŠ å›¾æ ‡å‰ç¼€
                if "é›¶å”®ç¯å¢ƒ" in message:
                    self.log_text.insert(tk.END, "ğŸª ", "store_icon")
                else:
                    self.log_text.insert(tk.END, "ğŸ¢ ", "office_icon")
                    
                self.log_text.insert(tk.END, message, "environment")
                self.log_text.insert(tk.END, "\n")
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†æå®Œæˆæ¶ˆæ¯
            elif "è§†é¢‘åˆ†æå®Œæˆ" in message or "å›¾ç‰‡åˆ†æå®Œæˆ" in message:
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                self.log_text.insert(tk.END, "âœ… ", "check_icon")
                self.log_text.insert(tk.END, message, "completion")
                self.log_text.insert(tk.END, "\n")
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºé”™è¯¯æ¶ˆæ¯
            elif "é”™è¯¯" in message.lower():
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                self.log_text.insert(tk.END, "âŒ ", "error_icon")
                self.log_text.insert(tk.END, message, "error")
                self.log_text.insert(tk.END, "\n")
                
            # ç³»ç»Ÿå¯åŠ¨å’Œé‡è¦æ“ä½œæ¶ˆæ¯
            elif "å¯åŠ¨" in message or "å¼€å§‹åˆ†æ" in message or "å·²åŠ è½½" in message:
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                self.log_text.insert(tk.END, "ğŸ”„ ", "system_icon")
                self.log_text.insert(tk.END, message, "system")
                self.log_text.insert(tk.END, "\n")
                
            # åˆ†æè¿‡ç¨‹ä¸­çš„æ—¥å¿—ä¹Ÿåº”è¯¥æ˜¾ç¤º
            elif "æ‰§è¡Œå§¿æ€ä¼°è®¡" in message or "æ£€æµ‹åˆ°äººä½“å§¿æ€" in message or "æ­£åœ¨å¤„ç†è§†é¢‘" in message or "è§†é¢‘å¤„ç†" in message:
                self.log_text.insert(tk.END, f"[{timestamp}] ", "timestamp")
                self.log_text.insert(tk.END, "ğŸ” ", "processing_icon")
                self.log_text.insert(tk.END, message, "processing")
                self.log_text.insert(tk.END, "\n")
                
            else:
                # å…¶ä»–æ¶ˆæ¯ç›´æ¥æ˜¾ç¤ºï¼Œä½†æ ¼å¼ç®€å•
                self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")

            # é…ç½®æ ‡ç­¾æ ·å¼
            self.log_text.tag_configure("timestamp", foreground="blue")
            self.log_text.tag_configure("progress", foreground="purple", font=("Helvetica", 9, "bold"))
            self.log_text.tag_configure("theft_yes", foreground="#CC0000", font=("Helvetica", 10, "bold"))
            self.log_text.tag_configure("theft_no", foreground="#009900", font=("Helvetica", 9, "bold"))
            self.log_text.tag_configure("summary", foreground="#663300", font=("Helvetica", 9, "bold"))
            self.log_text.tag_configure("environment", foreground="#003366", font=("Helvetica", 9, "bold"))
            self.log_text.tag_configure("completion", foreground="#006600", font=("Helvetica", 9, "bold"))
            self.log_text.tag_configure("error", foreground="#CC0000", font=("Helvetica", 9, "bold"))
            self.log_text.tag_configure("system", foreground="#333333", font=("Helvetica", 9))
            self.log_text.tag_configure("normal", foreground="black")
            self.log_text.tag_configure("behavior_summary", foreground="#336699", font=("Helvetica", 9, "bold"))
            self.log_text.tag_configure("high_probability", foreground="#CC0000", font=("Helvetica", 10, "bold"))
            self.log_text.tag_configure("medium_probability", foreground="#FF6600", font=("Helvetica", 9, "bold"))
            self.log_text.tag_configure("low_probability", foreground="#009900", font=("Helvetica", 9))
            self.log_text.tag_configure("processing", foreground="#333399", font=("Helvetica", 9))
            
            # é…ç½®å›¾æ ‡æ ·å¼
            self.log_text.tag_configure("alert_icon", foreground="#CC0000", font=("Helvetica", 12))
            self.log_text.tag_configure("check_icon", foreground="#009900", font=("Helvetica", 12))
            self.log_text.tag_configure("chart_icon", foreground="#336699", font=("Helvetica", 12))
            self.log_text.tag_configure("trend_icon", foreground="#663399", font=("Helvetica", 12))
            self.log_text.tag_configure("document_icon", foreground="#663300", font=("Helvetica", 12))
            self.log_text.tag_configure("store_icon", foreground="#006633", font=("Helvetica", 12))
            self.log_text.tag_configure("office_icon", foreground="#333366", font=("Helvetica", 12))
            self.log_text.tag_configure("error_icon", foreground="#CC0000", font=("Helvetica", 12))
            self.log_text.tag_configure("system_icon", foreground="#333333", font=("Helvetica", 12))
            self.log_text.tag_configure("processing_icon", foreground="#333399", font=("Helvetica", 12))
            
            # æ¢å¤åŸå§‹æ»šåŠ¨ä½ç½®ï¼Œå¦‚æœç”¨æˆ·ä¹‹å‰æœ‰æ»šåŠ¨ï¼Œå¦åˆ™æ‰æ»šåŠ¨åˆ°æœ«å°¾
            if current_view != (0, 0) and current_view[1] < 1.0:
                try:
                    self.log_text.yview_moveto(current_view[0])
                except:
                    pass
            else:
                # å¦‚æœåŸæ¥å°±åœ¨åº•éƒ¨æˆ–è€…æ–°å†…å®¹ï¼Œåˆ™æ»šåŠ¨åˆ°åº•éƒ¨
                self.log_text.see(tk.END)
        except Exception as e:
            print(f"æ—¥å¿—é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—çª—å£å†…å®¹"""
        try:
            self.log_text.delete(1.0, tk.END)
            self.root.update_idletasks()
        except Exception as e:
            print(f"æ¸…ç©ºæ—¥å¿—é”™è¯¯: {str(e)}")
    
    def select_image(self):
        """Select image file"""
        filetypes = [
            ("å›¾ç‰‡æ–‡ä»¶", "*.jpg *.jpeg *.png *.bmp"),
            ("æ‰€æœ‰æ–‡ä»¶", "*.*")
        ]
        filepath = filedialog.askopenfilename(
            title="é€‰æ‹©å›¾ç‰‡",
            filetypes=filetypes
        )
        
        if filepath:
            self.load_image(filepath)
    
    def select_video(self):
        """Select video file"""
        filetypes = [
            ("è§†é¢‘æ–‡ä»¶", "*.mp4 *.avi *.mov *.mkv"),
            ("æ‰€æœ‰æ–‡ä»¶", "*.*")
        ]
        filepath = filedialog.askopenfilename(
            title="é€‰æ‹©è§†é¢‘",
            filetypes=filetypes
        )
        
        if filepath:
            self.load_video(filepath)
    
    def load_image(self, filepath):
        """Load and display image"""
        try:
            # Clean previous video state
            self.stop_video_playback()
            
            # ç¡®ä¿æ’­æ”¾æ§åˆ¶åŒºåŸŸéšè—
            self.playback_control_frame.pack_forget()
            
            # Update status
            self.current_media_path = filepath
            self.current_media_type = 'image'
            self.processed_media_path = None
            self.status_label.config(text=f"å·²åŠ è½½å›¾ç‰‡: {os.path.basename(filepath)}")
            
            # Read and display image
            self.original_image = cv2.imread(filepath)
            if self.original_image is None:
                raise Exception(f"æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶: {filepath}")
                
            img_rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
            self.display_image(img_rgb, self.original_canvas)
            
            # Clear processed canvas
            self.processed_canvas.delete("all")
            
            # Enable processing button
            self.process_btn.state(['!disabled'])
            self.save_btn.state(['disabled'])
            
            # Log
            self.log(f"å·²åŠ è½½å›¾ç‰‡: {os.path.basename(filepath)}")
            self.update_progress(0)
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"åŠ è½½å›¾ç‰‡å¤±è´¥: {str(e)}")
            self.log(f"é”™è¯¯: åŠ è½½å›¾ç‰‡å¤±è´¥: {str(e)}")
    
    def load_video(self, filepath):
        """Load and display video"""
        try:
            # Clean previous video state
            self.stop_video_playback()
            
            # ç¡®ä¿æ’­æ”¾æ§åˆ¶åŒºåŸŸéšè—
            self.playback_control_frame.pack_forget()
            
            # ç¡®ä¿è§†é¢‘æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(filepath):
                raise Exception(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
                
            # åˆ›å»ºstatic/videosç›®å½•ä»¥ç¡®ä¿å­˜åœ¨
            videos_dir = os.path.join("static", "videos")
            os.makedirs(videos_dir, exist_ok=True)
            
            # å¦‚æœè§†é¢‘ä¸åœ¨static/videosç›®å½•ä¸‹ï¼Œå¤åˆ¶åˆ°è¯¥ç›®å½•
            filename = os.path.basename(filepath)
            target_path = os.path.join(videos_dir, filename)
            
            # åªåœ¨éœ€è¦æ—¶å¤åˆ¶ï¼Œé¿å…é‡å¤æ“ä½œ
            if filepath != target_path and not os.path.exists(target_path):
                import shutil
                shutil.copy2(filepath, target_path)
                self.log(f"å·²å°†è§†é¢‘å¤åˆ¶åˆ°: {target_path}")
            
            # è®¾ç½®å½“å‰åª’ä½“è·¯å¾„ä¸ºstatic/videosä¸­çš„è·¯å¾„
            self.current_media_path = target_path
            
            # ä½¿ç”¨ç›®æ ‡è·¯å¾„æ‰“å¼€è§†é¢‘
            cap = cv2.VideoCapture(target_path)
            if not cap.isOpened():
                raise Exception("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
                
            # Update status
            self.current_media_type = 'video'
            self.processed_media_path = None
            self.video_capture = cap
            
            # é‡ç½®å¯ç–‘è¡Œä¸ºåˆ—è¡¨
            if hasattr(self, 'suspicious_behaviors'):
                self.suspicious_behaviors = []
            
            # Get video info
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else 0
            
            # Display video info
            self.status_label.config(text=f"å·²åŠ è½½è§†é¢‘: {os.path.basename(target_path)}")
            video_info = f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.2f}fps, æ—¶é•¿: {duration:.2f}ç§’"
            self.log(video_info)
            
            # æ˜¾ç¤ºç¬¬ä¸€å¸§ä½œä¸ºé¢„è§ˆï¼ˆè€Œä¸æ˜¯è‡ªåŠ¨å¼€å§‹æ’­æ”¾ï¼‰
            ret, frame = cap.read()
            if ret:
                # æ˜¾ç¤ºç¬¬ä¸€å¸§ä½œä¸ºé¢„è§ˆ
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                self.display_image(frame_rgb, self.original_canvas)
                # é‡ç½®è§†é¢‘åˆ°å¼€å§‹ä½ç½®
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            
            # Enable processing button
            self.process_btn.state(['!disabled'])
            self.save_btn.state(['disabled'])
            
            # ç¡®ä¿è¿›åº¦æ¡è¢«é‡ç½®
            if hasattr(self, 'progress_bar') and self.progress_bar:
                self.progress_bar['value'] = 0
            if hasattr(self, 'progress_label') and self.progress_label:
                self.progress_label.config(text="0%")
                
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"åŠ è½½è§†é¢‘å¤±è´¥: {str(e)}")
            self.log(f"é”™è¯¯: åŠ è½½è§†é¢‘å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def start_video_preview(self):
        """Start video preview thread"""
        self.stop_video_thread = False
        self.video_thread = threading.Thread(target=self.video_preview_loop)
        self.video_thread.daemon = True
        self.video_thread.start()
    
    def video_preview_loop(self):
        """Video preview loop"""
        if self.video_capture is None:
            return
        
        # Reset to beginning of video
        self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
        
        while not self.stop_video_thread:
            ret, frame = self.video_capture.read()
            if not ret:
                # Loop back to beginning
                self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue
            
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            self.display_image(frame_rgb, self.original_canvas)
            time.sleep(0.03)  # Limit frame rate
    
    def stop_video_playback(self):
        """åœæ­¢è§†é¢‘æ’­æ”¾"""
        self.stop_video_thread = True
        self.is_playing = False
        
        if self.video_thread:
            self.video_thread.join(timeout=1.0)
            self.video_thread = None
        
        if self.video_capture:
            self.video_capture.release()
            self.video_capture = None
            
        if self.processed_video_capture:
            self.processed_video_capture.release()
            self.processed_video_capture = None
            
        # é‡ç½®æ’­æ”¾æŒ‰é’®
        self.play_pause_btn.config(text="æ’­æ”¾")
        
        # å¦‚æœä¸æ˜¯åœ¨å¤„ç†è¿‡ç¨‹ä¸­ï¼Œéšè—æ’­æ”¾æ§åˆ¶åŒºåŸŸ
        if not self.is_processing:
            self.playback_control_frame.pack_forget()
    
    def display_image(self, image, canvas, title=None, forced_width=None, forced_height=None):
        """åœ¨æŒ‡å®šç”»å¸ƒä¸Šæ˜¾ç¤ºå›¾åƒ"""
        try:
            # ç¡®ä¿imageæ˜¯æœ‰æ•ˆçš„numpyæ•°ç»„
            if image is None or not isinstance(image, np.ndarray):
                self.log(f"æ— æ•ˆçš„å›¾åƒæ•°æ®ç±»å‹: {type(image)}", console_only=True)
                return False
                
            # ç¡®ä¿å›¾åƒæœ‰æ­£ç¡®çš„å½¢çŠ¶
            if len(image.shape) < 2:
                self.log(f"æ— æ•ˆçš„å›¾åƒå½¢çŠ¶: {image.shape}", console_only=True)
                return False
                
            # è·å–ç”»å¸ƒå°ºå¯¸ï¼Œä¼˜å…ˆä½¿ç”¨forcedå‚æ•°
            canvas_width = forced_width if forced_width else canvas.winfo_width()
            canvas_height = forced_height if forced_height else canvas.winfo_height()
            
            # ç¡®ä¿ç”»å¸ƒå°ºå¯¸æœ‰æ•ˆ
            if canvas_width <= 1 or canvas_height <= 1:
                canvas_width = int(canvas.cget('width')) if canvas.cget('width') else 640
                canvas_height = int(canvas.cget('height')) if canvas.cget('height') else 360
            
            # è®¡ç®—è°ƒæ•´å¤§å°çš„æ¯”ä¾‹
            img_height, img_width = image.shape[:2]
            
            # ä¿æŒåŸå§‹å®½é«˜æ¯”
            ratio = min(canvas_width / img_width, canvas_height / img_height)
            new_width = int(img_width * ratio)
            new_height = int(img_height * ratio)
            
            # è°ƒæ•´å›¾åƒå¤§å°
            resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # å°†OpenCVçš„BGRæ ¼å¼è½¬æ¢ä¸ºPILå¯ç”¨çš„RGBæ ¼å¼
            if len(resized_image.shape) == 3 and resized_image.shape[2] == 3:
                # å·²ç»æ˜¯RGBæ ¼å¼ï¼Œä¸éœ€è¦è½¬æ¢
                pil_image = Image.fromarray(resized_image)
            else:
                # ç°åº¦æˆ–å…¶ä»–æ ¼å¼è½¬æ¢ä¸ºRGB
                pil_image = Image.fromarray(resized_image).convert('RGB')
            
            # åˆ›å»ºTkinterå¯ä»¥æ˜¾ç¤ºçš„PhotoImage
            photo = ImageTk.PhotoImage(image=pil_image)
            
            # æ¸…é™¤ç”»å¸ƒå¹¶æ˜¾ç¤ºæ–°å›¾åƒ
            canvas.delete("all")
            
            # è®¡ç®—å›¾åƒåœ¨ç”»å¸ƒä¸Šçš„ä¸­å¿ƒä½ç½®
            x_center = canvas_width // 2
            y_center = canvas_height // 2
            
            # åœ¨ç”»å¸ƒä¸Šåˆ›å»ºå›¾åƒ
            canvas.create_image(x_center, y_center, image=photo)
            
            # ä¿å­˜å¯¹å›¾åƒçš„å¼•ç”¨ï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶
            if canvas == self.original_canvas:
                self._original_photo = photo
            else:
                self._processed_photo = photo
            
            # å¦‚æœæä¾›äº†æ ‡é¢˜ï¼Œæ˜¾ç¤ºåœ¨å›¾åƒä¸Šæ–¹
            if title:
                canvas.create_text(x_center, 20, text=title, fill="white", 
                                  font=("Arial", 14, "bold"))
                
            # æ›´æ–°æ—¶é—´æˆ³æ ‡ç­¾ï¼ˆç”¨äºè§†é¢‘ï¼‰
            if hasattr(self, 'current_frame_index') and self.current_frame_index is not None:
                frame_timestamp = self.current_frame_index / self.fps if hasattr(self, 'fps') and self.fps else 0
                mins, secs = divmod(frame_timestamp, 60)
                time_str = f"{int(mins):02d}:{secs:05.2f}"
                
                # åœ¨è§†é¢‘ä¸‹æ–¹æ˜¾ç¤ºæ—¶é—´æˆ³
                if canvas == self.original_canvas:
                    if hasattr(self, 'time_label_original'):
                        self.time_label_original.config(text=f"æ—¶é—´: {time_str}")
                elif canvas == self.processed_canvas:
                    if hasattr(self, 'time_label_processed'):
                        self.time_label_processed.config(text=f"æ—¶é—´: {time_str}")
            
            return True
        except Exception as e:
            self.log(f"æ˜¾ç¤ºå›¾åƒé”™è¯¯: {str(e)}")
            import traceback
            self.log(traceback.format_exc(), console_only=True)
            return False
    
    def start_processing(self):
        """Start processing the image or video"""
        # ç«‹å³ç¦ç”¨æ‰€æœ‰æŒ‰é’®ï¼Œä¸ç­‰å¾…åç»­çš„å¤„ç†
        self.process_btn.state(['disabled'])
        self.select_image_btn.state(['disabled'])
        self.select_video_btn.state(['disabled'])
        
        if self.is_processing:
            self.log("å¤„ç†å·²åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ")
            return
        
        if not self.current_media_path:
            self.log("æœªé€‰æ‹©ä»»ä½•åª’ä½“æ–‡ä»¶")
            # å¦‚æœæ²¡æœ‰é€‰æ‹©åª’ä½“æ–‡ä»¶ï¼Œæ¢å¤æŒ‰é’®çŠ¶æ€
            self.process_btn.state(['!disabled'])
            self.select_image_btn.state(['!disabled'])
            self.select_video_btn.state(['!disabled'])
            return
        
        # é‡ç½®è§†é¢‘æ’­æ”¾æ ‡å¿—
        if hasattr(self, 'video_playback_started'):
            del self.video_playback_started
        
        # éšè—æ’­æ”¾æ§åˆ¶åŒºåŸŸ
        self.playback_control_frame.pack_forget()
        
        # åœæ­¢æ­£åœ¨è¿›è¡Œçš„è§†é¢‘æ’­æ”¾
        self.stop_video_playback()
        
        # æ¸…ç©ºè¡Œä¸ºåˆ—è¡¨
        for item in self.behavior_list.get_children():
            self.behavior_list.delete(item)
        
        # é‡ç½®è¡Œä¸ºæ•°æ®
        if hasattr(self, 'behaviors_data'):
            self.behaviors_data = []
        
        # æ¸…ç©ºæ—¥å¿—æ–‡æœ¬åŒºåŸŸ
        self.log_text.delete(1.0, tk.END)
        self.log("å¼€å§‹æ–°çš„åˆ†æä»»åŠ¡...")
        
        # æ›´æ–°UIçŠ¶æ€
        self.is_processing = True
        
        # è®¾ç½®ä¸€ä¸ªå¼ºåˆ¶ç¦ç”¨æŒ‰é’®çš„æ ‡å¿—
        self._force_disable_buttons = True
        
        self.log(f"å¼€å§‹åˆ†æ {'å›¾ç‰‡' if self.current_media_type == 'image' else 'è§†é¢‘'}...")
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        processing_thread = threading.Thread(target=self.processing_thread)
        processing_thread.daemon = True
        processing_thread.start()
        
        # å¯åŠ¨æŒ‰é’®ç¦ç”¨æ£€æŸ¥å¾ªç¯
        self._check_and_disable_buttons()
    
    def _check_and_disable_buttons(self):
        """å¾ªç¯æ£€æŸ¥å¹¶å¼ºåˆ¶ç¦ç”¨æŒ‰é’®ï¼Œç›´åˆ°å¤„ç†å®Œæˆ"""
        if hasattr(self, '_force_disable_buttons') and self._force_disable_buttons:
            # å¼ºåˆ¶ç¦ç”¨æ‰€æœ‰æŒ‰é’®
            self.process_btn.state(['disabled'])
            self.select_image_btn.state(['disabled'])
            self.select_video_btn.state(['disabled'])
            # æ¯25æ¯«ç§’æ‰§è¡Œä¸€æ¬¡ï¼Œç¡®ä¿æŒ‰é’®çŠ¶æ€ä¸ä¼šè¢«å…¶ä»–æ“ä½œæ›´æ”¹
            self.root.after(25, self._check_and_disable_buttons)
        else:
            # å¦‚æœæ ‡å¿—è¢«ç§»é™¤æˆ–è®¾ä¸ºFalseï¼Œåˆ™åœæ­¢å¾ªç¯
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¯ç”¨æŒ‰é’®
            if not self.is_processing:
                # åœ¨å¤„ç†å®Œæˆåä¸»åŠ¨ç¡®ä¿æŒ‰é’®è¢«å¯ç”¨
                self.root.after(50, self._ensure_buttons_enabled)
    
    def _ensure_buttons_enabled(self):
        """ç¡®ä¿æŒ‰é’®åœ¨å¤„ç†å®Œæˆåè¢«å¯ç”¨"""
        if not self.is_processing:
            self.process_btn.state(['!disabled'])
            self.select_image_btn.state(['!disabled'])
            self.select_video_btn.state(['!disabled'])
            # å¦‚æœæœ‰å¤„ç†ç»“æœï¼Œå¯ç”¨ä¿å­˜æŒ‰é’®
            if hasattr(self, 'processed_media_path') and self.processed_media_path and os.path.exists(self.processed_media_path):
                self.save_btn.state(['!disabled'])
    
    def processing_thread(self):
        """Background thread for processing"""
        try:
            # é‡ç½®æ‘˜è¦ç”Ÿæˆæ ‡å¿—ï¼Œç¡®ä¿æ¯æ¬¡æ–°çš„å¤„ç†éƒ½ä¼šç”Ÿæˆæ–°çš„æ‘˜è¦
            self.summary_generated = False
            
            # æ ¹æ®åª’ä½“ç±»å‹é€‰æ‹©å¤„ç†æ–¹æ³•
            if self.current_media_type == 'image':
                self.process_image()
            elif self.current_media_type == 'video':
                self.process_video()
            else:
                self.handle_processing_error("æœªçŸ¥çš„åª’ä½“ç±»å‹")
                return
        except Exception as e:
            import traceback
            error_msg = f"å¤„ç†çº¿ç¨‹é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.log(error_msg)
            self.handle_processing_error(error_msg)
    
    def finalize_processing(self):
        """Finalize processing"""
        # å…³é—­å¼ºåˆ¶ç¦ç”¨æŒ‰é’®æ ‡å¿—
        self._force_disable_buttons = False
        
        self.is_processing = False
        self.process_btn.state(['!disabled'])
        self.select_image_btn.state(['!disabled'])
        self.select_video_btn.state(['!disabled'])
        self.log("åˆ†æå®Œæˆ")
        
        # ç¡®ä¿æ‘˜è¦å·²ç”Ÿæˆ
        if hasattr(self, 'behaviors_data') and not hasattr(self, 'summary_generated'):
            self.log("å¤„ç†å®Œæˆåæ£€æŸ¥åˆ°å°šæœªç”Ÿæˆè¡Œä¸ºæ‘˜è¦ï¼Œå°†ç”Ÿæˆæ‘˜è¦...")
            behaviors = self.behaviors_data
            
            # ç¡®ä¿å¯ç–‘å¸§åˆ—è¡¨å­˜åœ¨
            if not hasattr(self, 'suspicious_frames'):
                self.suspicious_frames = []
                
            suspicious_frames = self.suspicious_frames
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡åˆ†æ
            is_image_analysis = len(behaviors) == 1 and behaviors[0][0] == 0
            
            # è®¡ç®—ç›¸å…³å‚æ•°
            theft_frames = len(suspicious_frames)
            if is_image_analysis:
                total_frames = 1
                # å¦‚æœæ˜¯å›¾ç‰‡åˆ†æä¸”æœ‰è¡Œä¸ºä½†æ²¡æœ‰å¯ç–‘å¸§ï¼Œå°†å¯ç–‘å¸§è®¡ä¸º1
                if theft_frames == 0:
                    for _, frame_behaviors in behaviors:
                        if frame_behaviors:
                            theft_frames = 1
                            break
            else:
                # è·å–è§†é¢‘æ€»å¸§æ•°
                cap = cv2.VideoCapture(self.current_media_path)
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.isOpened() else 1
                cap.release()
            
            # è®¡ç®—æœ€å¤§æ¦‚ç‡
            max_probability = 0.0
            for _, frame_behaviors in behaviors:
                for behavior in frame_behaviors:
                    max_probability = max(max_probability, behavior.get('confidence', 0.0))
            
            # ç”Ÿæˆæ‘˜è¦
            self.create_behavior_summary(behaviors, max_probability, theft_frames, total_frames)
        
        # å¦‚æœæ˜¯è§†é¢‘å¤„ç†ï¼Œå¹¶ä¸”å­˜åœ¨å¤„ç†åçš„è§†é¢‘æ–‡ä»¶ï¼Œåˆ™å¯åŠ¨è§†é¢‘å¯¹æ¯”æ’­æ”¾
        # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦ç¡®ä¿è¿™é‡Œä¸ä¼šä¸video_processing_threadä¸­çš„æ’­æ”¾å¯åŠ¨å†²çª
        # åªæœ‰å½“è§†é¢‘å¤„ç†æ˜¯åœ¨ä¸»çº¿ç¨‹ä¸­å®Œæˆæ—¶ï¼ˆæ¯”å¦‚ç›´æ¥è°ƒç”¨process_videoè€Œä¸æ˜¯é€šè¿‡çº¿ç¨‹ï¼‰ï¼Œæ‰ä¼šæ‰§è¡Œæ­¤ä»£ç 
        if (self.current_media_type == 'video' and 
            hasattr(self, 'processed_media_path') and 
            self.processed_media_path and 
            os.path.exists(self.processed_media_path)):
            
            # ä½¿ç”¨æ ‡å¿—æ£€æŸ¥è§†é¢‘æ’­æ”¾æ˜¯å¦å·²ç»å¯åŠ¨
            if not hasattr(self, 'video_playback_started') or not self.video_playback_started:
                self.log("ä¸»çº¿ç¨‹ä¸­æ£€æµ‹åˆ°è§†é¢‘å¤„ç†å®Œæˆï¼Œå‡†å¤‡å¯åŠ¨åŒæ­¥æ’­æ”¾è§†é¢‘å¯¹æ¯”...")
                self.video_playback_started = True
                # ä½¿ç”¨çŸ­å»¶è¿Ÿç¡®ä¿UIæ›´æ–°å®Œæˆåå†å¯åŠ¨è§†é¢‘æ’­æ”¾
                self.root.after(300, self.start_processed_video_playback)
        
        if self.processed_media_path:
            self.save_btn.state(['!disabled'])
    
    def handle_processing_error(self, error_message):
        """Handle processing error"""
        # å…³é—­å¼ºåˆ¶ç¦ç”¨æŒ‰é’®æ ‡å¿—
        self._force_disable_buttons = False
        
        self.is_processing = False
        self.process_btn.state(['!disabled'])
        self.select_image_btn.state(['!disabled'])
        self.select_video_btn.state(['!disabled'])
        self.log(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {error_message}")
        self.update_progress(0)
        messagebox.showerror("å¤„ç†é”™è¯¯", f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {error_message}")
    
    def process_image(self):
        """å¤„ç†å½“å‰åŠ è½½çš„å›¾ç‰‡"""
        if self.current_media_path is None or not os.path.exists(self.current_media_path):
            messagebox.showerror("å¤„ç†é”™è¯¯", "è¯·å…ˆé€‰æ‹©ä¸€å¼ æœ‰æ•ˆçš„å›¾ç‰‡")
            return
            
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        try:
            # æ›´æ–°å¤„ç†çŠ¶æ€
            self.is_processing = True
            self.update_progress(10)
            self.progress_label.config(text="æ­£åœ¨åŠ è½½å›¾ç‰‡...")
            
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            if not hasattr(self, 'theft_detector') or self.theft_detector is None:
                self.update_progress(20)
                self.progress_label.config(text="æ­£åœ¨åˆå§‹åŒ–æ£€æµ‹æ¨¡å‹...")
                
                from src.models.detection import TheftDetector
                self.theft_detector = TheftDetector()
                # è®¾ç½®å…¼å®¹æ€§å±æ€§
                self.detector = self.theft_detector
                
                if self.theft_detector.model is None:
                    messagebox.showerror("æ¨¡å‹é”™è¯¯", "æ— æ³•åŠ è½½æ£€æµ‹æ¨¡å‹ï¼Œè¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
                    self.is_processing = False
                    return
            
            # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å·²åŠ è½½
            if self.original_image is None:
                # åŠ è½½å›¾ç‰‡
                self.update_progress(30)
                self.progress_label.config(text="æ­£åœ¨è¯»å–å›¾ç‰‡...")
                self.original_image = cv2.imread(self.current_media_path)
                if self.original_image is None:
                    messagebox.showerror("å›¾ç‰‡é”™è¯¯", "æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶")
                    self.is_processing = False
                    return
            
            # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥é€‚åº”å±å¹•
            self.update_progress(40)
            self.progress_label.config(text="æ­£åœ¨è°ƒæ•´å›¾ç‰‡å¤§å°...")
            
            # è¿›è¡Œæ£€æµ‹
            self.update_progress(50)
            self.progress_label.config(text="æ­£åœ¨è¿›è¡Œæ£€æµ‹åˆ†æ...")
            
            # ä¿å­˜åŸå§‹å¸§ç”¨äºåç»­ä½¿ç”¨
            frame_copy = self.original_image.copy()
            self.processed_frame = frame_copy.copy()  # ä¿å­˜ä¸€ä»½å¤„ç†å¸§çš„å‰¯æœ¬
            
            # ä½¿ç”¨æ£€æµ‹å™¨è¿›è¡Œåˆ†æ
            result, theft_probability = self.theft_detector.detect_theft(frame_copy)
            
            # ä¿å­˜æ£€æµ‹ç»“æœä¾›åç»­ä½¿ç”¨
            self._last_detection_result = result
            
            # ä¿å­˜ç¯å¢ƒåˆ¤æ–­ç»“æœ
            self.is_retail_environment = self.theft_detector._is_retail_environment(result)
            
            # åˆ›å»ºæ£€æµ‹æ ‡æ³¨
            self.update_progress(70)
            self.progress_label.config(text="æ­£åœ¨ç”Ÿæˆæ£€æµ‹ç»“æœ...")
            
            # ä¿å­˜æœ€å¤§ç›—çªƒæ¦‚ç‡
            self.max_theft_probability = theft_probability
            annotated_frame = self.theft_detector.draw_detection(frame_copy, result, theft_probability)
            
            # å°†æ£€æµ‹ç»“æœæ·»åŠ åˆ°æ—¥å¿—ä¸­
            self.log(f"æ£€æµ‹åˆ°ç›—çªƒæ¦‚ç‡åŸå§‹å€¼: {theft_probability}")
            import datetime
            with open("debug_log.txt", "a") as f:
                f.write(f"[{datetime.datetime.now()}] æ£€æµ‹åˆ°çš„ç›—çªƒæ¦‚ç‡: {theft_probability}\n")
                if hasattr(result, 'boxes'):
                    for i, box in enumerate(result.boxes):
                        cls_id = int(box.cls[0])
                        class_name = result.names.get(cls_id, "")
                        conf = float(box.conf[0])
                        f.write(f"[{datetime.datetime.now()}] æ£€æµ‹å¯¹è±¡ {i}: {class_name}, å¯ä¿¡åº¦: {conf}\n")
            
            # åˆ›å»ºè§†é¢‘è¡Œä¸ºæ£€æµ‹å™¨ç”¨äºå›¾ç‰‡åˆ†æ
            # æ³¨é‡Šæ‰è¿™è¡Œä»£ç ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´ä¸test_detector.pyçš„ç»“æœä¸ä¸€è‡´
            # from src.models.behavior.video_behavior import VideoBehaviorDetector
            # behavior_detector = VideoBehaviorDetector()
            
            # æ·»åŠ å›¾åƒè¡Œä¸ºæ£€æµ‹å™¨ç”¨äºè§„åˆ™å¼•æ“åˆ†æ - ä¸test_detector.pyä¿æŒä¸€è‡´
            try:
                from src.models.behavior.image_behavior import ImageBehaviorDetector
                image_behavior_detector = ImageBehaviorDetector()
                # ä¸ºä¿æŒä¸test_detector.pyä¸€è‡´ï¼Œä¸å†ä½¿ç”¨VideoBehaviorDetector
                behavior_detector = image_behavior_detector
            except Exception as e:
                self.log(f"åˆå§‹åŒ–å›¾åƒè¡Œä¸ºæ£€æµ‹å™¨å‡ºé”™: {str(e)}")
                image_behavior_detector = None
                behavior_detector = None
            
            self.log("æ‰§è¡Œå§¿æ€ä¼°è®¡å’Œè¡Œä¸ºåˆ†æ...")
            # ä½¿ç”¨ImageBehaviorDetectorä¸­çš„å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œä¸test_detector.pyä¿æŒä¸€è‡´
            pose_results = image_behavior_detector._extract_pose_landmarks(frame_copy)
            
            # åˆå§‹åŒ–è¡Œä¸ºåˆ—è¡¨
            behaviors = []
            
            # å§‹ç»ˆåˆå§‹åŒ–behaviors_dataä»¥é¿å…å±æ€§ä¸å­˜åœ¨é”™è¯¯
            self.behaviors_data = [(0, [])]
            
            # æ£€æµ‹åŸºäºå§¿æ€çš„è¡Œä¸º
            if pose_results:
                self.log("æ£€æµ‹åˆ°äººä½“å§¿æ€ï¼Œåˆ†æå¯ç–‘è¡Œä¸º...")
                
                # ä»æ£€æµ‹ç»“æœä¸­æå–äººç‰©è¾¹ç•Œæ¡†
                person_detections = []
                try:
                    # é€‚é…ä¸åŒæ ¼å¼çš„æ£€æµ‹ç»“æœ
                    if hasattr(result, 'boxes'):
                        # å¤„ç†ultralytics Resultså¯¹è±¡
                        for i in range(len(result.boxes)):
                            box = result.boxes[i]
                            cls_id = int(box.cls[0]) if hasattr(box, 'cls') and len(box.cls) > 0 else -1
                            if cls_id >= 0 and result.names.get(cls_id, "") == "person":
                                x1, y1, x2, y2 = map(int, box.xyxy[0])
                                conf = float(box.conf[0]) if hasattr(box, 'conf') and len(box.conf) > 0 else 0.0
                                # ä»¥ä¸test_detector.pyä¸€è‡´çš„æ ¼å¼å­˜å‚¨
                                person_detections.append([(x1, y1, x2, y2), conf])
                                self.log(f"æ£€æµ‹åˆ°äººç‰©è¾¹ç•Œæ¡†: {(x1, y1, x2, y2)}, ç½®ä¿¡åº¦: {conf:.2f}")
                    elif isinstance(result, list):
                        # å¤„ç†å­—å…¸åˆ—è¡¨æ ¼å¼
                        for d in result:
                            if d.get('class', '') == 'person':
                                bbox = d.get('bbox')
                                conf = d.get('confidence', 0.0)
                                if bbox:
                                    person_detections.append([bbox, conf])
                except Exception as e:
                    self.log(f"æå–äººå‘˜æ£€æµ‹ç»“æœé”™è¯¯: {str(e)}")
                
                # æå–ç‰©ä½“ä¿¡æ¯ç”¨äºè§„åˆ™å¼•æ“
                objects = []
                try:
                    if hasattr(result, 'boxes'):
                        for i in range(len(result.boxes)):
                            box = result.boxes[i]
                            cls_id = int(box.cls[0]) if hasattr(box, 'cls') and len(box.cls) > 0 else -1
                            class_name = result.names.get(cls_id, "")
                            if cls_id >= 0 and class_name != "person":
                                x1, y1, x2, y2 = map(int, box.xyxy[0])
                                conf = float(box.conf[0]) if hasattr(box, 'conf') and len(box.conf) > 0 else 0.0
                                objects.append({
                                    'bbox': (x1, y1, x2, y2),
                                    'class': class_name,
                                    'confidence': conf
                                })
                    self.log(f"æå–äº† {len(objects)} ä¸ªç‰©ä½“ä¿¡æ¯ç”¨äºè§„åˆ™å¼•æ“åˆ†æ")
                except Exception as e:
                    self.log(f"æå–ç‰©ä½“ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
                
                # ä½¿ç”¨è§„åˆ™å¼•æ“è¿›è¡Œåˆ†æ
                if image_behavior_detector:
                    try:
                        self.log("ä½¿ç”¨è§„åˆ™å¼•æ“åˆ†æå§¿æ€æ•°æ®...")
                        
                        # ç›´æ¥è°ƒç”¨å„ç§è§„åˆ™å¼•æ“æ–¹æ³•è¿›è¡Œè¡Œä¸ºæ£€æµ‹ï¼Œæ¨¡ä»¿test_detector.pyçš„è°ƒç”¨æ–¹å¼
                        image_behavior_detector.detected_behaviors = []
                        
                        self.log(f"äººç‰©æ£€æµ‹æ ¼å¼: {type(person_detections)}, é•¿åº¦: {len(person_detections)}")
                        if len(person_detections) > 0:
                            self.log(f"ç¬¬ä¸€ä¸ªäººç‰©æ•°æ®: {person_detections[0]}, ç±»å‹: {type(person_detections[0])}")
                        
                        # å‡†å¤‡è½¬æ¢person_detectionsæ ¼å¼ï¼Œä»å­—å…¸åˆ—è¡¨åˆ°åæ ‡å’Œç½®ä¿¡åº¦å…ƒç»„åˆ—è¡¨
                        person_list = []
                        for person in person_detections:
                            if isinstance(person, dict) and 'bbox' in person:
                                bbox = person['bbox']
                                conf = person.get('confidence', 0.0)
                                person_list.append([bbox, conf])
                                self.log(f"ä»å­—å…¸è½¬æ¢äººç‰©æ•°æ®: bbox={bbox}, conf={conf}")
                            elif isinstance(person, (list, tuple)) and len(person) >= 1:
                                person_list.append(person)
                                self.log(f"ä¿ç•™åˆ—è¡¨æ ¼å¼äººç‰©æ•°æ®: {person}")
                        
                        self.log(f"è½¬æ¢åçš„äººç‰©åˆ—è¡¨: {person_list}")
                        
                        # æŒ‰ç…§test_detector.pyçš„æ–¹å¼è°ƒç”¨æ£€æµ‹æ–¹æ³•
                        image_behavior_detector._detect_pose_based_behaviors(frame_copy, pose_results, person_list, objects)
                        image_behavior_detector._detect_suspicious_arm_posture(frame_copy, pose_results, person_list)
                        image_behavior_detector._detect_abnormal_arm_positions(frame_copy, pose_results, person_list)
                        image_behavior_detector._detect_body_shielding(frame_copy, pose_results, person_list, objects)
                        image_behavior_detector._detect_hands_behind_back(frame_copy, pose_results, person_list)
                        
                        # è·å–è¡Œä¸ºæ£€æµ‹ç»“æœ
                        if image_behavior_detector.detected_behaviors:
                            rule_behaviors = image_behavior_detector.detected_behaviors
                            self.log(f"è§„åˆ™å¼•æ“æ£€æµ‹åˆ° {len(rule_behaviors)} ä¸ªå¯ç–‘è¡Œä¸º")
                            for behavior in rule_behaviors:
                                self.log(f" - {behavior['type']}: {behavior['confidence']:.2f}")
                            behaviors.extend(rule_behaviors)
                        
                        # ä½¿ç”¨è§„åˆ™å¼•æ“ä¸­çš„å£è¢‹æ£€æµ‹æ–¹æ³•
                        try:
                            image_behavior_detector._detect_pocket_concealment(frame_copy, pose_results, person_list, objects)
                            if len(image_behavior_detector.detected_behaviors) > len(behaviors):
                                new_behaviors = image_behavior_detector.detected_behaviors[len(behaviors):]
                                self.log(f"å£è¢‹æ£€æµ‹é¢å¤–å‘ç° {len(new_behaviors)} ä¸ªå¯ç–‘è¡Œä¸º")
                                for behavior in new_behaviors:
                                    self.log(f" - {behavior['type']}: {behavior['confidence']:.2f}")
                                behaviors = image_behavior_detector.detected_behaviors
                        except Exception as e:
                            self.log(f"æ‰§è¡Œå£è¢‹æ£€æµ‹å‡ºé”™: {str(e)}")
                        
                        # ä½¿ç”¨ç‰©å“åˆ°å£è¢‹æ£€æµ‹æ–¹æ³•
                        try:
                            # ä¸test_detector.pyä¿æŒä¸€è‡´çš„è°ƒç”¨å’Œå¤„ç†æ–¹å¼
                            self.log("è°ƒç”¨_check_item_to_pocketè¿›è¡Œç‰©å“éšè—æ£€æµ‹...")
                            item_to_pocket_result = image_behavior_detector._check_item_to_pocket(pose_results, objects)
                            self.log(f"ç‰©å“åˆ°å£è¢‹æ£€æµ‹ç»“æœ: {item_to_pocket_result}")
                            
                            # ä¸¥æ ¼æŒ‰ç…§test_detector.pyçš„æ–¹å¼å¤„ç†è¿”å›ç»“æœ
                            if item_to_pocket_result and isinstance(item_to_pocket_result, dict):
                                # è¿”å›äº†æ­£ç¡®çš„è¡Œä¸ºå­—å…¸
                                behaviors.append(item_to_pocket_result)
                                self.log(f" - æ·»åŠ è¡Œä¸º: {item_to_pocket_result['type']}: {item_to_pocket_result['confidence']:.2f}")
                            elif item_to_pocket_result == True:
                                # å¦‚æœè¿”å›Trueä½†ä¸æ˜¯å­—å…¸ï¼Œæ·»åŠ æ ‡å‡†è¡Œä¸º
                                pocket_behavior = {
                                    'type': 'Item Concealed in Pocket',
                                    'confidence': 0.95
                                }
                                behaviors.append(pocket_behavior)
                                self.log(f" - æ·»åŠ è¡Œä¸º: {pocket_behavior['type']}: {pocket_behavior['confidence']:.2f}")
                        except Exception as e:
                            self.log(f"æ‰§è¡Œç‰©å“åˆ°å£è¢‹æ£€æµ‹æ—¶å‡ºé”™: {str(e)}")
                            
                    except Exception as e:
                        self.log(f"è§„åˆ™å¼•æ“åˆ†æå‡ºé”™: {str(e)}")
                        
                self.update_progress(60)
                
                # æ·»åŠ è¯¦ç»†æ—¥å¿—ï¼Œè®°å½•æ‰§è¡ŒçŠ¶æ€
                self.log("å³å°†æ‰§è¡ŒVideoBehaviorDetectoråˆ†æï¼Œä½†è¯¥éƒ¨åˆ†å¯èƒ½å¯¼è‡´ä¸test_detector.pyä¸ä¸€è‡´...")
                self.log(f"behavior_detectorç±»å‹: {type(behavior_detector).__name__}")
                self.log(f"person_detectionsç±»å‹: {type(person_detections)}, é•¿åº¦: {len(person_detections)}")
                
                # è·³è¿‡è¿™éƒ¨åˆ†VideoBehaviorDetectorå¤„ç†ï¼Œç¡®ä¿ä¸test_detector.pyç»“æœä¸€è‡´
                # skip_video_detector = True
                # if not skip_video_detector:
                #     # å¦‚æœæ£€æµ‹åˆ°äººï¼Œåˆ†æè¡Œä¸º
                #     if person_detections:
                #         for i, person in enumerate(person_detections):
                #             self.log(f"å¤„ç†ç¬¬{i+1}ä¸ªäººç‰©: {person}")
                #             # æ ¹æ®personçš„ç±»å‹è·å–bbox
                #             if isinstance(person, dict) and 'bbox' in person:
                #     for person in person_detections:
                #         person_bbox = person[0]  # ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼
                #         # æ£€æµ‹åŸºäºå§¿æ€çš„è¡Œä¸º
                #         pose_behaviors = behavior_detector._detect_pose_based_behaviors(
                #             frame_copy, 
                #             pose_results.get('landmarks'), 
                #             person_bbox,
                #             [d for d in result if isinstance(d, dict) and d.get('class') != 'person']
                #         )
                        
                #         # æ·»åŠ åˆ°è¡Œä¸ºåˆ—è¡¨
                #         if pose_behaviors:
                #             behaviors.extend(pose_behaviors)
                    
                #     # æ£€æµ‹åŸºæœ¬è¡Œä¸º
                #     basic_behaviors = behavior_detector.detect_behaviors_in_image(frame_copy, result)
                #     if basic_behaviors:
                #         behaviors.extend(basic_behaviors)
                # """
            
            self.update_progress(70)
            
            # å°†è¡Œä¸ºæ·»åŠ åˆ°è¡Œä¸ºåˆ—è¡¨UIä¸­
            if behaviors:
                self.log(f"æ£€æµ‹åˆ° {len(behaviors)} ä¸ªå¯ç–‘è¡Œä¸º")
                for behavior in behaviors:
                    behavior_type = behavior.get('type', 'æœªçŸ¥è¡Œä¸º')
                    confidence = behavior.get('confidence', 0.0)
                    # æ·»åŠ åˆ°UIä¸­çš„è¡Œä¸ºåˆ—è¡¨
                    self.add_behavior_to_list(0, 0, behavior_type, confidence)
                
                # æ›´æ–°è¡Œä¸ºæ•°æ®
                self.behaviors_data = [(0, behaviors)]
                
                # è®¡ç®—è¡Œä¸ºå¹³å‡å¯ç–‘åº¦ï¼Œç”¨äºæ˜¾ç¤º
                avg_confidence = sum(b.get('confidence', 0) for b in behaviors) / len(behaviors) if behaviors else 0
                self.log(f"è¡Œä¸ºå¹³å‡å¯ç–‘åº¦: {avg_confidence:.2%}")
                
                # ä½¿ç”¨è¡Œä¸ºå¹³å‡å¯ç–‘åº¦ä½œä¸ºç»˜åˆ¶åˆ°å›¾ç‰‡ä¸Šçš„æ¦‚ç‡
                theft_proba = avg_confidence
                
                # åŸºäºè§„åˆ™å¼•æ“å’Œæ¨¡å‹æ£€æµ‹åˆ°çš„è¡Œä¸ºè°ƒæ•´ç›—çªƒæ¦‚ç‡
                try:
                    # ä½¿ç”¨è§„åˆ™è€Œéç¡¬ç¼–ç å€¼è®¡ç®—ç›—çªƒæ¦‚ç‡
                    if len(behaviors) > 0 and image_behavior_detector:
                        # è¯»å–é…ç½®ä¸­çš„è¡Œä¸ºæƒé‡
                        behavior_weights = image_behavior_detector._load_config().get('behavior_weights', {})
                        
                        # æ ¹æ®æ£€æµ‹åˆ°çš„è¡Œä¸ºå’Œé…ç½®çš„æƒé‡è®¡ç®—ç›—çªƒæ¦‚ç‡
                        behavior_confidence_sum = 0
                        behavior_weight_sum = 0
                        
                        for behavior in behaviors:
                            behavior_type = behavior['type']
                            confidence = behavior['confidence']
                            # ä½¿ç”¨é…ç½®çš„æƒé‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼0.5
                            weight = behavior_weights.get(behavior_type, 0.5)
                            
                            behavior_confidence_sum += confidence * weight
                            behavior_weight_sum += weight
                        
                        # è®¡ç®—åŠ æƒå¹³å‡ç½®ä¿¡åº¦
                        if behavior_weight_sum > 0:
                            avg_weighted_confidence = behavior_confidence_sum / behavior_weight_sum
                            # ä½¿ç”¨åŸºæœ¬ç›—çªƒæ¦‚ç‡å’Œè¡Œä¸ºåˆ†æç»“æœçš„åŠ æƒå¹³å‡ - ä¸test_detector.pyä¿æŒä¸€è‡´
                            # åŸå§‹ç›—çªƒæ¦‚ç‡ä½¿ç”¨theft_probabilityè€Œä¸æ˜¯å…¶ä»–å€¼
                            theft_proba = theft_probability * 0.3 + avg_weighted_confidence * 0.7
                            self.log(f"åˆå§‹ç›—çªƒæ¦‚ç‡: {theft_probability:.2f}, è¡Œä¸ºåŠ æƒå¹³å‡: {avg_weighted_confidence:.2f}")
                        else:
                            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„è¡Œä¸ºæƒé‡å’Œï¼Œåˆ™ä¿æŒåŸå§‹ç›—çªƒæ¦‚ç‡
                            theft_proba = theft_probability
                    else:
                        # æ²¡æœ‰æ£€æµ‹åˆ°è¡Œä¸ºï¼Œä¿æŒåŸå§‹ç›—çªƒæ¦‚ç‡
                        theft_proba = theft_probability
                    
                    self.log(f"åŸºäºè§„åˆ™å¼•æ“è®¡ç®—çš„ç›—çªƒæ¦‚ç‡: {theft_proba:.2f}")
                except Exception as e:
                    self.log(f"è®¡ç®—ç›—çªƒæ¦‚ç‡å‡ºé”™: {str(e)}")
                    # ä½¿ç”¨åˆå§‹è®¡ç®—çš„ç›—çªƒæ¦‚ç‡
                    theft_proba = theft_probability
                
                self.log(f"å¤„ç†åçš„æ¦‚ç‡å€¼: {theft_proba}, å°†æ˜¾ç¤ºä¸º: {theft_proba:.2%}")
                # æ›´æ–°ç›—çªƒæ¦‚ç‡å€¼
                theft_probability = theft_proba
                
                # ä¿å­˜è¡Œä¸ºåˆ°æ£€æµ‹å™¨ï¼Œä½¿å…¶èƒ½å¤Ÿè¢«å…¶ä»–æµç¨‹ä½¿ç”¨
                self.theft_detector.suspicious_behaviors = behaviors
            else:
                self.log("æœªæ£€æµ‹åˆ°å¯ç–‘è¡Œä¸º")
                # ç¡®ä¿behaviors_dataå³ä½¿åœ¨æ²¡æœ‰æ£€æµ‹åˆ°è¡Œä¸ºæ—¶ä¹Ÿå­˜åœ¨
                self.behaviors_data = [(0, [])]
                # ç¡®ä¿suspicious_behaviorså±æ€§å­˜åœ¨
                self.theft_detector.suspicious_behaviors = []
            
            # Draw results, including pose and behaviors
            self.log("ç»˜åˆ¶æ£€æµ‹ç»“æœ...")
            result_img = self.theft_detector.draw_detection(frame_copy, result, theft_probability)
            
            # ç»˜åˆ¶å§¿æ€å…³é”®ç‚¹
            if pose_results:
                result_img = behavior_detector._draw_pose_landmarks(result_img, pose_results)
            
            # ç»˜åˆ¶è¡Œä¸ºè¾¹ç•Œæ¡†å’Œæ ‡ç­¾
            for behavior in behaviors:
                if 'bbox' in behavior:
                    bbox = behavior['bbox']
                    color = behavior.get('color', (0, 0, 255))  # é»˜è®¤çº¢è‰²
                    cv2.rectangle(result_img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)
                    
                    # æ˜¾ç¤ºè¡Œä¸ºç±»å‹
                    behavior_type = behavior['type']
                    # ç›´æ¥ä½¿ç”¨è‹±æ–‡è¡Œä¸ºç±»å‹ï¼Œé¿å…ä¸­æ–‡ä¹±ç 
                    display_type = behavior_type
                    # å°†è¡Œä¸ºæ ‡ç­¾ç§»åˆ°è¾¹ç•Œæ¡†å³ä¸Šè§’
                    (label_width, label_height), _ = cv2.getTextSize(display_type, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
                    # æ ‡ç­¾èƒŒæ™¯
                    cv2.rectangle(result_img, (bbox[2] - label_width - 10, bbox[1]), (bbox[2], bbox[1] + label_height + 5), color, -1)
                    # æ ‡ç­¾æ–‡æœ¬
                    cv2.putText(result_img, display_type, (bbox[2] - label_width - 5, bbox[1] + label_height), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            
            self.update_progress(90)
            
            # Save result image
            
            # ç¡®ä¿å§‹ç»ˆç”Ÿæˆè¡Œä¸ºåˆ†ææ‘˜è¦
            if not hasattr(self, 'summary_generated') or not self.summary_generated:
                self.log("ç”Ÿæˆè¡Œä¸ºåˆ†ææ‘˜è¦...")
                theft_frames = 1 if behaviors else 0
                total_frames = 1  # å›¾ç‰‡åªæœ‰1å¸§
                max_probability = theft_probability  # Use the updated theft_probability instead of recalculating
                self.create_behavior_summary(self.behaviors_data, max_probability, theft_frames, total_frames)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs("static/output", exist_ok=True)
            
            output_path = os.path.join("static", "output", f"result_{int(time.time())}.jpg")
            cv2.imwrite(output_path, result_img)
            self.processed_media_path = output_path
            
            # Display result
            result_img_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
            # ä½¿ç”¨æ­£ç¡®çš„canvaså¯¹è±¡åç§° - processed_canvasè€Œä¸æ˜¯processed_media_canvas
            self.root.after(0, lambda: self.display_image(result_img_rgb, self.processed_canvas))
            
            # æ›´æ–°è¡Œä¸ºåˆ—è¡¨UI
            if hasattr(self, 'behaviors_data') and self.behaviors_data:
                self.root.after(100, self.update_ui_with_behaviors)
            
            # Log results
            is_theft = theft_probability > 0.5 or (behaviors and len(behaviors) > 0)
            self.log(f"æ£€æµ‹å®Œæˆ: {'å‘ç°ç›—çªƒè¡Œä¸º' if is_theft else 'æœªå‘ç°ç›—çªƒè¡Œä¸º'}")
            self.log(f"ç›—çªƒæ¦‚ç‡: {theft_probability:.2%}")
            
            if behaviors:
                self.log(f"è¡Œä¸ºåˆ†æ: å…±æ£€æµ‹åˆ° {len(behaviors)} ä¸ªå¯ç–‘è¡Œä¸º")
                avg_confidence = sum(b.get('confidence', 0) for b in behaviors) / len(behaviors) if behaviors else 0
                self.log(f"è¡Œä¸ºå¹³å‡å¯ç–‘åº¦: {avg_confidence:.2%}")
            
            self.update_progress(100)
            
            # æœ€åéœ€è¦æ¢å¤æŒ‰é’®çŠ¶æ€
            self.is_processing = False
            self._force_disable_buttons = False
            self.process_btn.state(['!disabled'])
            self.select_image_btn.state(['!disabled'])
            self.select_video_btn.state(['!disabled'])
            
            # å¯ç”¨ä¿å­˜æŒ‰é’®
            if self.processed_media_path:
                self.save_btn.state(['!disabled'])
            
            # ç¡®ä¿æŒ‰é’®è¢«å¯ç”¨
            self.root.after(50, self._ensure_buttons_enabled)
            
            self.log("å›¾ç‰‡åˆ†æå®Œæˆ")
            
        except Exception as e:
            import traceback
            error_msg = f"å›¾ç‰‡å¤„ç†é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.log(error_msg)
            self.handle_processing_error(error_msg)
    
    def process_video(self):
        """Process video file"""
        try:
            # æ¸…ç©ºæ—¥å¿—çª—å£
            self.clear_log()
            
            # ç¡®ä¿æ‰€æœ‰æŒ‰é’®åœ¨å¤„ç†å¼€å§‹æ—¶å°±è¢«ç¦ç”¨
            # ç”±äºprocess_videoå·²ç»åœ¨processing_threadçº¿ç¨‹ä¸­è¿è¡Œï¼Œç›´æ¥è®¾ç½®æŒ‰é’®çŠ¶æ€å¯èƒ½ä¸å®‰å…¨
            # ä½¿ç”¨æ›´å¼ºçš„ä¿è¯æœºåˆ¶ï¼Œç¡®ä¿æŒ‰é’®ç¦ç”¨çŠ¶æ€å·²ç»ç”Ÿæ•ˆ
            self.is_processing = True
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´å½“å‰åª’ä½“è·¯å¾„
            if not os.path.exists(self.current_media_path):
                # å°è¯•åœ¨static/videosç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
                filename = os.path.basename(self.current_media_path)
                static_video_path = os.path.join("static", "videos", filename)
                if os.path.exists(static_video_path):
                    self.current_media_path = static_video_path
                    self.log(f"å·²æ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {self.current_media_path}")
                else:
                    self.log(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {self.current_media_path}")
                    self.is_processing = False
                    return
            
            self.log(f"æ­£åœ¨åˆ†æè§†é¢‘: {os.path.basename(self.current_media_path)}")
            self.update_progress(5)
            
            # åˆ›å»ºå¤„ç†çº¿ç¨‹ï¼Œé˜²æ­¢UIå†»ç»“
            import threading
            
            # åˆ›å»ºè¾“å‡ºè§†é¢‘æ–‡ä»¶å
            base_name = os.path.basename(self.current_media_path)
            name_without_ext = os.path.splitext(base_name)[0]
            output_dir = os.path.join("static", "videos", "output")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)
            
            # æ„å»ºè¾“å‡ºè·¯å¾„
            self.processed_media_path = os.path.join(
                output_dir, 
                f"{name_without_ext}_analyzed.mp4"
            )
            
            # å¯åŠ¨å¤„ç†çº¿ç¨‹
            self.processing_thread = threading.Thread(
                target=self.video_processing_thread,
                args=(self.current_media_path, self.processed_media_path)
            )
            self.processing_thread.daemon = True
            self.processing_thread.start()
            
            # æ›´æ–°UIçŠ¶æ€
            self.update_progress(15)
            self.log("æ­£åœ¨å¤„ç†è§†é¢‘...è¯·ç­‰å¾…å®Œæˆ")
            
        except Exception as e:
            import traceback
            error_msg = f"è§†é¢‘å¤„ç†åˆå§‹åŒ–é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.log(error_msg)
            self.handle_processing_error(error_msg)
    
    def video_processing_thread(self, video_path, output_path):
        """å•ç‹¬çº¿ç¨‹å¤„ç†è§†é¢‘"""
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        try:
            # é‡ç½®æ‘˜è¦ç”Ÿæˆæ ‡å¿—
            self.summary_generated = False
            
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            from src.models.detection import TheftDetector
            from src.models.behavior import VideoBehaviorDetector
            
            # åˆå§‹åŒ–YOLOæ¨¡å‹
            self.theft_detector = TheftDetector()
            behavior_detector = VideoBehaviorDetector()
            
            # åˆå§‹åŒ–è§†é¢‘è¯»å†™å™¨
            cap = cv2.VideoCapture(video_path)
            
            # è¯»å–è§†é¢‘å±æ€§
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # åˆ›å»ºè§†é¢‘ç¼–å†™å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            # åˆå§‹åŒ–å…‰æµè®¡ç®—å™¨
            flow_calculator = None
            last_gray = None
            
            # åˆå§‹åŒ–è¡Œä¸ºåˆ†ææ•°æ®
            consecutive_theft_frames = 0
            behaviors_data = []
            frame_count = 0
            processed_frames = 0
            processed_with_error = 0
            max_theft_probability = 0.0
            theft_frames = 0
            all_retail_environment_results = []  # ä¿å­˜æ‰€æœ‰å¸§çš„ç¯å¢ƒåˆ¤æ–­ç»“æœ
            
            # åˆå§‹åŒ–è¡Œä¸ºå­˜å‚¨åˆ—è¡¨å’ŒIDè®¡æ•°å™¨
            self.behavior_data = []  # æ¸…ç©ºæ—§æ•°æ®ï¼Œå‡†å¤‡å­˜å‚¨æ–°çš„è¡Œä¸ºæ•°æ®
            self.next_behavior_id = 1  # é‡ç½®è¡Œä¸ºID
            
            # æ›´æ–°è¿›åº¦å’ŒçŠ¶æ€å›è°ƒ
            def update_progress_callback(value, text):
                self.root.after(0, lambda: self.restore_progress_state(value, text))
            
            # å¸§å¤„ç†å›è°ƒ
            def frame_callback(frame_index, output_frame, behaviors, original_frame=None):
                nonlocal processed_frames, processed_with_error, max_theft_probability, theft_frames
                processed_frames += 1
                
                # å¢åŠ è¿›åº¦æ¡æ›´æ–°é¢‘ç‡ï¼Œæ¯5å¸§æ›´æ–°ä¸€æ¬¡
                if frame_index % 5 == 0:
                    progress = int((frame_index / total_frames) * 100)
                    current_time = time.time() - start_time
                    processing_speed = frame_index / current_time if current_time > 0 else 0
                    remaining_frames = total_frames - frame_index
                    remaining_time = remaining_frames / processing_speed if processing_speed > 0 else 0
                    
                    # æ›´æ–°è¿›åº¦ä¿¡æ¯
                    progress_text = f"æ­£åœ¨å¤„ç†è§†é¢‘ {progress}% - å¸§ {frame_index}/{total_frames} - é¢„è®¡å‰©ä½™æ—¶é—´: {int(remaining_time/60)}åˆ†{int(remaining_time%60)}ç§’"
                    update_progress_callback(progress, progress_text)
                
                # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
                if frame_index % 10 == 0 or frame_index == total_frames - 1:
                    # åˆ›å»ºå¸§ä¿¡æ¯
                    frame_data = {
                        'frame': output_frame,  # å¤„ç†åçš„å¸§ï¼ˆå¸¦æœ‰æ£€æµ‹ç»“æœï¼‰æ˜¾ç¤ºåœ¨å³ä¾§
                        'frame_index': frame_index,
                        'time': '{:.2f}s'.format(frame_index / fps),
                        'behaviors': behaviors,
                        'original_frame': original_frame,  # åŸå§‹å¸§æ˜¾ç¤ºåœ¨å·¦ä¾§
                        'theft_probability': 0.0
                    }
                    
                    # è·å–å½“å‰å¸§çš„ç›—çªƒæ¦‚ç‡
                    if behaviors is not None and isinstance(behaviors, list) and behaviors:
                        probabilities = [b.get('probability', 0.0) for b in behaviors if isinstance(b, dict)]
                        if probabilities:
                            frame_data['theft_probability'] = max(probabilities)
                    
                    # æ›´æ–°æœ€å¤§ç›—çªƒæ¦‚ç‡
                    if frame_data['theft_probability'] > max_theft_probability:
                        max_theft_probability = frame_data['theft_probability']
                    
                    # ç»Ÿè®¡ç›—çªƒå¸§æ•°
                    if frame_data['theft_probability'] > 0.4:
                        theft_frames += 1
                    
                    # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
                    self.root.after(0, lambda: self.update_frame_display(frame_data))
                    
                    # å®æ—¶æ›´æ–°è¡Œä¸ºåˆ—è¡¨ - æ¯å½“æ£€æµ‹åˆ°è¡Œä¸ºæ—¶æ·»åŠ åˆ°UI
                    if behaviors and len(behaviors) > 0:
                        time_point = frame_index / fps if fps > 0 else 0
                        for behavior in behaviors:
                            behavior_type = behavior.get('type', 'æœªçŸ¥è¡Œä¸º')
                            confidence = behavior.get('confidence', 0.0)
                            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°è¡Œä¸ºåˆ—è¡¨
                            self.root.after(0, lambda f=frame_index, t=time_point, bt=behavior_type, c=confidence: 
                                           self.add_behavior_to_list(f, t, bt, c))
                
                # æ— é”™è¯¯å¤„ç†å®Œæˆå¤„ç†
                return True
            
            # è§†é¢‘å¤„ç†å®Œæˆåçš„å›è°ƒ
            def finalize_video_processing():
                # ä¿å­˜å¤„ç†ç»“æœçš„è§†é¢‘è·¯å¾„
                self.processed_media_path = output_path
                
                # æ›´æ–°UI
                self.update_progress(95)
                self.progress_label.config(text="è§†é¢‘å¤„ç†å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆç»“æœ...")
                
                # ç¡®å®šæ˜¯å¦ä¸ºé›¶å”®ç¯å¢ƒï¼Œä½¿ç”¨æœ€é¢‘ç¹çš„ç¯å¢ƒåˆ¤æ–­ç»“æœ
                if all_retail_environment_results:
                    # è®¡ç®—æ‰€æœ‰å¸§ä¸­Trueå’ŒFalseçš„æ•°é‡
                    true_count = all_retail_environment_results.count(True)
                    false_count = all_retail_environment_results.count(False)
                    
                    # ä½¿ç”¨å¤šæ•°è¡¨å†³ç¡®å®šæœ€ç»ˆç¯å¢ƒç±»å‹
                    self.is_retail_environment = true_count > false_count
                    self.log(f"åŸºäºè§†é¢‘ä¸­çš„{len(all_retail_environment_results)}å¸§åˆ†æï¼Œç¯å¢ƒåˆ¤æ–­ä¸º: {'é›¶å”®ç¯å¢ƒ' if self.is_retail_environment else 'éé›¶å”®ç¯å¢ƒ'} (é›¶å”®åˆ¤æ–­ç‡: {true_count/len(all_retail_environment_results):.2%})")
                else:
                    # é»˜è®¤ä½¿ç”¨éé›¶å”®ç¯å¢ƒ
                    self.is_retail_environment = False
                    self.log("æ— æ³•ç¡®å®šç¯å¢ƒç±»å‹ï¼Œé»˜è®¤ä¸ºéé›¶å”®ç¯å¢ƒ")
            
            # è®¾ç½®å¸§å›è°ƒ
            behavior_detector.frame_processed_callback = frame_callback
            
            # æ‰§è¡Œè§†é¢‘åˆ†æ
            self.processed_media_path, suspicious_frames, behaviors = behavior_detector.analyze_video_behavior(
                video_path, self.theft_detector, callback=update_progress_callback, frame_callback=frame_callback)
            
            # åœ¨è§†é¢‘åˆ†ææœŸé—´æ•è·é›¶å”®ç¯å¢ƒåˆ¤æ–­ç»“æœ
            # æ¯éš”10å¸§æ£€æŸ¥ä¸€æ¬¡ç¯å¢ƒ
            cap = cv2.VideoCapture(video_path)
            sample_frames = []
            
            # è¯»å–è§†é¢‘çš„ä¸€äº›é‡‡æ ·å¸§æ¥åˆ¤æ–­ç¯å¢ƒ
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            sample_interval = max(1, total_frames // 10)  # è‡³å°‘é‡‡æ ·10å¸§
            
            try:
                for i in range(0, total_frames, sample_interval):
                    cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                    ret, frame = cap.read()
                    if ret:
                        sample_frames.append(frame)
                
                # ä¸ºæ¯ä¸ªé‡‡æ ·å¸§åˆ¤æ–­ç¯å¢ƒç±»å‹
                for frame in sample_frames:
                    if frame is not None:
                        try:
                            result = self.theft_detector.model.predict(frame, conf=0.25)[0]
                            is_retail = self.theft_detector._is_retail_environment(result)
                            all_retail_environment_results.append(is_retail)
                        except Exception as e:
                            self.log(f"ç¯å¢ƒåˆ¤æ–­å‡ºé”™: {str(e)}")
            except Exception as e:
                self.log(f"é‡‡æ ·å¸§åˆ†æé”™è¯¯: {str(e)}")
            finally:
                cap.release()
            
            # å¦‚æœæœ‰è¶³å¤Ÿçš„ç¯å¢ƒåˆ¤æ–­ç»“æœï¼Œä½¿ç”¨å¤šæ•°æŠ•ç¥¨ç¡®å®šæœ€ç»ˆç¯å¢ƒç±»å‹
            if all_retail_environment_results:
                true_count = all_retail_environment_results.count(True)
                false_count = len(all_retail_environment_results) - true_count
                self.is_retail_environment = true_count > false_count
                self.log(f"åŸºäº{len(all_retail_environment_results)}ä¸ªé‡‡æ ·å¸§çš„ç¯å¢ƒåˆ¤æ–­: {'é›¶å”®ç¯å¢ƒ' if self.is_retail_environment else 'éé›¶å”®ç¯å¢ƒ'} (é›¶å”®åˆ¤æ–­ç‡: {true_count/len(all_retail_environment_results)*100:.1f}%)")
            
            # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å˜é‡ä¿å­˜è¡Œä¸ºæ•°æ®ï¼Œä»¥ä¾¿åœ¨å¼‚æ­¥æ“ä½œä¸­ä¹Ÿèƒ½è®¿é—®
            self.behaviors_data = behaviors
            self.suspicious_frames = suspicious_frames
            
            # è®¡ç®—æœ€å¤§æ¦‚ç‡ - ä¸ºæ‘˜è¦åšå‡†å¤‡
            max_probability = 0.0
            for _, frame_behaviors in behaviors:
                for behavior in frame_behaviors:
                    max_probability = max(max_probability, behavior.get('confidence', 0.0))
            
            # è·å–è§†é¢‘æ€»å¸§æ•°
            total_frames = 1
            try:
                cap = cv2.VideoCapture(video_path)
                if cap.isOpened():
                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    cap.release()
            except Exception as e:
                self.log(f"è·å–è§†é¢‘å¸§æ•°é”™è¯¯: {str(e)}")
            
            # å®Œæˆåæ›´æ–°UIå¹¶ç”Ÿæˆæ‘˜è¦
            def finalize_video_processing():
                try:
                    # ä¿å­˜å¤„ç†ç»“æœè·¯å¾„
                    if self.processed_media_path:
                        self.log(f"è§†é¢‘åˆ†æå®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {os.path.basename(self.processed_media_path)}")
                    else:
                        self.log("è§†é¢‘åˆ†æå®Œæˆï¼Œä½†æ²¡æœ‰ç”Ÿæˆè¾“å‡ºæ–‡ä»¶")
                    
                    # ä¸éœ€è¦é‡æ–°æ·»åŠ è¡Œä¸ºåˆ°UIåˆ—è¡¨ï¼Œå› ä¸ºå·²ç»åœ¨åˆ†æè¿‡ç¨‹ä¸­å®æ—¶æ·»åŠ äº†
                    self.log("è§†é¢‘åˆ†æå®Œæˆï¼Œæ‰€æœ‰è¡Œä¸ºå·²å®æ—¶æ·»åŠ åˆ°ç•Œé¢")
                    
                    # è·å–è¡Œä¸ºåˆ—è¡¨ä¸­çš„è¡Œä¸ºæ•°é‡
                    behavior_count = len(self.behavior_list.get_children())
                    self.log(f"è¡Œä¸ºåˆ—è¡¨ä¸­å…±æœ‰ {behavior_count} æ¡è¡Œä¸ºè®°å½•")
                    
                    # åœ¨è§†é¢‘å¤„ç†å®Œæˆåç”Ÿæˆè¡Œä¸ºåˆ†ææ‘˜è¦
                    if not hasattr(self, 'summary_generated') or not self.summary_generated:
                        self.log("è§†é¢‘å¤„ç†å®Œæˆåç”Ÿæˆè¡Œä¸ºåˆ†ææ‘˜è¦")
                        theft_frames = len(self.suspicious_frames)
                        # ç›´æ¥è°ƒç”¨create_behavior_summaryè€Œä¸æ˜¯update_ui_with_behaviors
                        self.create_behavior_summary(self.behaviors_data, max_probability, theft_frames, total_frames)
                    
                    # å¤„ç†å®Œæˆï¼Œé€šçŸ¥ä¸»çº¿ç¨‹
                    self.update_progress(100)
                    
                    # è®¾ç½®å¤„ç†çŠ¶æ€ä¸ºå®Œæˆï¼Œå¯ç”¨å¤„ç†æŒ‰é’®
                    self.is_processing = False
                    
                    # ç¡®ä¿ç¦ç”¨æŒ‰é’®æ ‡å¿—è¢«å…³é—­
                    self._force_disable_buttons = False
                    
                    # ç¡®ä¿å¤„ç†æŒ‰é’®é‡æ–°å¯ç”¨
                    self.process_btn.state(['!disabled'])
                    self.select_image_btn.state(['!disabled'])
                    self.select_video_btn.state(['!disabled'])
                    
                    # å¦‚æœæœ‰å¤„ç†ç»“æœï¼Œå¯ç”¨ä¿å­˜æŒ‰é’®
                    if self.processed_media_path and os.path.exists(self.processed_media_path):
                        self.save_btn.state(['!disabled'])
                    
                    # åœ¨åˆ†æå®Œæˆåè‡ªåŠ¨å¯åŠ¨åŒæ­¥æ’­æ”¾åŸå§‹è§†é¢‘å’Œåˆ†æåçš„è§†é¢‘
                    if self.processed_media_path and os.path.exists(self.processed_media_path):
                        self.log("å‡†å¤‡å¯åŠ¨åŒæ­¥æ’­æ”¾è§†é¢‘å¯¹æ¯”...")
                        # è®¾ç½®æ ‡å¿—è¡¨ç¤ºè§†é¢‘æ’­æ”¾å·²ç»å¯åŠ¨ï¼Œé¿å…finalize_processingä¸­é‡å¤å¯åŠ¨
                        self.video_playback_started = True
                        # ä½¿ç”¨çŸ­å»¶è¿Ÿç¡®ä¿UIæ›´æ–°å®Œæˆåå†å¯åŠ¨è§†é¢‘æ’­æ”¾
                        self.root.after(300, self.start_processed_video_playback)
                    
                except Exception as e:
                    self.log(f"è§†é¢‘å¤„ç†å®Œæˆåæ›´æ–°UIé”™è¯¯: {str(e)}")
                    import traceback
                    error_traceback = traceback.format_exc()
                    self.log(error_traceback)
                    # å°†é”™è¯¯ä¿¡æ¯æ·»åŠ åˆ°æ‘˜è¦åŒºåŸŸï¼Œç¡®ä¿ç”¨æˆ·èƒ½å¤Ÿçœ‹åˆ°
                    if hasattr(self, 'log_text'):
                        self.log_text.delete(1.0, tk.END)
                        self.log_text.insert(tk.END, "----------- è§†é¢‘å¤„ç†é”™è¯¯ -----------\n", "title")
                        self.log_text.insert(tk.END, f"é”™è¯¯ä¿¡æ¯: {str(e)}\n\n", "error")
                        self.log_text.insert(tk.END, "è¯¦ç»†è·Ÿè¸ªä¿¡æ¯:\n", "subtitle")
                        self.log_text.insert(tk.END, error_traceback, "traceback")
                        self.log_text.tag_configure("title", font=("Arial", 10, "bold"), foreground="red")
                        self.log_text.tag_configure("error", font=("Arial", 9, "bold"), foreground="red")
                        self.log_text.tag_configure("subtitle", font=("Arial", 9, "bold"), foreground="black")
                        self.log_text.tag_configure("traceback", font=("Courier", 8), foreground="gray")
                    
                    # å³ä½¿å‡ºé”™ä¹Ÿè¦è®¾ç½®å¤„ç†çŠ¶æ€ä¸ºå®Œæˆ
                    self.is_processing = False
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œæœ€ç»ˆå¤„ç†
            self.root.after(100, finalize_video_processing)
            
            # å¯¼è‡´å†…å­˜æº¢å‡ºçš„å¯¹è±¡è®¾ä¸º None
            behavior_detector = None
            
            # å¼ºåˆ¶æ‰§è¡Œåƒåœ¾å›æ”¶
            import gc
            gc.collect()
            
            # é‡Šæ”¾èµ„æº
            writer.release()
            
        except Exception as e:
            self.log(f"è§†é¢‘å¤„ç†çº¿ç¨‹é”™è¯¯: {str(e)}")
            import traceback
            error_traceback = traceback.format_exc()
            self.log(error_traceback)
            
            # å°†é”™è¯¯ä¿¡æ¯æ·»åŠ åˆ°æ‘˜è¦åŒºåŸŸï¼Œç¡®ä¿ç”¨æˆ·èƒ½å¤Ÿçœ‹åˆ°
            def display_error_summary():
                if hasattr(self, 'log_text'):
                    self.log_text.delete(1.0, tk.END)
                    self.log_text.insert(tk.END, "----------- è§†é¢‘å¤„ç†é”™è¯¯ -----------\n", "title")
                    self.log_text.insert(tk.END, f"é”™è¯¯ä¿¡æ¯: {str(e)}\n\n", "error")
                    self.log_text.insert(tk.END, "è¯¦ç»†è·Ÿè¸ªä¿¡æ¯:\n", "subtitle")
                    self.log_text.insert(tk.END, error_traceback, "traceback")
                    self.log_text.tag_configure("title", font=("Arial", 10, "bold"), foreground="red")
                    self.log_text.tag_configure("error", font=("Arial", 9, "bold"), foreground="red")
                    self.log_text.tag_configure("subtitle", font=("Arial", 9, "bold"), foreground="black")
                    self.log_text.tag_configure("traceback", font=("Courier", 8), foreground="gray")
                    
                # æ›´æ–°è¿›åº¦ä¸º0ï¼Œè¡¨ç¤ºå¤„ç†å¤±è´¥
                self.update_progress(0)
                
                # ç¡®ä¿åœ¨é”™è¯¯å‘ç”Ÿåæ¢å¤æŒ‰é’®çŠ¶æ€
                self.is_processing = False
                # å…³é—­å¼ºåˆ¶ç¦ç”¨æŒ‰é’®æ ‡å¿—
                self._force_disable_buttons = False
                self.process_btn.state(['!disabled'])
                self.select_image_btn.state(['!disabled'])
                self.select_video_btn.state(['!disabled'])
                self.log("åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œå·²ç»ˆæ­¢")
            
            # ç¡®ä¿åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(100, display_error_summary)
        except Exception as e:
            import traceback
            error_traceback = traceback.format_exc()
            self.log(f"è§†é¢‘å¤„ç†çº¿ç¨‹é”™è¯¯: {str(e)}")
            
            # ç¡®ä¿å³ä½¿display_error_summaryå‡½æ•°ä¹Ÿå‡ºé”™ï¼Œä¹Ÿèƒ½æ¢å¤æŒ‰é’®çŠ¶æ€
            def emergency_recovery():
                self.is_processing = False
                # å…³é—­å¼ºåˆ¶ç¦ç”¨æŒ‰é’®æ ‡å¿—
                self._force_disable_buttons = False
                self.process_btn.state(['!disabled'])
                self.select_image_btn.state(['!disabled'])
                self.select_video_btn.state(['!disabled'])
                self.update_progress(0)
                self.log("è§†é¢‘å¤„ç†çº¿ç¨‹å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œå·²æ¢å¤æŒ‰é’®çŠ¶æ€")
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ¢å¤UIçŠ¶æ€
            self.root.after(100, emergency_recovery)
    
    def update_frame_display(self, callback_data):
        """Update the frame display in the UI.
        
        Args:
            callback_data: Dictionary containing the following keys:
                - frame: Processed frame
                - original_frame: Original frame
                - frame_index: Current frame index
                - total_frames: Total number of frames
                - log_message: Optional log message
                - behaviors: Optional behaviors list
                - theft_probability: Theft probability
                - detections: Detection results
        """
        try:
            # ä»frame_dataä¸­æå–æ•°æ®
            processed_frame = callback_data.get('frame')  # å¤„ç†åçš„å¸§
            original_frame = callback_data.get('original_frame')  # åŸå§‹å¸§
            frame_idx = callback_data.get('frame_index', 0)
            
            # è·å–æ€»å¸§æ•° - ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å€¼ï¼Œæ²¡æœ‰åˆ™å°è¯•è¯»å–è§†é¢‘å±æ€§
            total_frames = callback_data.get('total_frames')
            if total_frames is None and hasattr(self, 'current_media_path') and self.current_media_path:
                cap = cv2.VideoCapture(self.current_media_path)
                if cap.isOpened():
                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    cap.release()
                else:
                    total_frames = 1  # é»˜è®¤å€¼
            else:
                total_frames = total_frames or 1  # ç¡®ä¿éç©º
                
            log_message = callback_data.get('log_message')
            behaviors = callback_data.get('behaviors', [])
            theft_probability = callback_data.get('theft_probability', 0.0)
            
            # æ›´æ–°è¿›åº¦æ¡ - æ˜¾ç¤ºæ•´ä½“è¿›åº¦
            if total_frames > 0:
                progress = min(100, int(100 * frame_idx / total_frames))
                self.progress_bar['value'] = progress
                self.progress_text.set(f"{progress}%")
                
            # åŸå§‹è§†é¢‘å¸§æ˜¾ç¤ºåœ¨å·¦ä¾§ï¼ˆåŸå§‹åª’ä½“åŒºåŸŸï¼‰
            if original_frame is not None:
                # å°†åŸå§‹å¸§è½¬æ¢ä¸ºRGBæ ¼å¼
                original_frame_rgb = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)
                # æ˜¾ç¤ºåˆ°åŸå§‹ç”»å¸ƒä¸Šï¼ˆå·¦ä¾§ï¼‰
                self.display_image(original_frame_rgb, self.original_canvas)
            
            # å¤„ç†åçš„å¸§æ˜¾ç¤ºåœ¨å³ä¾§ï¼ˆæ£€æµ‹ç»“æœåŒºåŸŸï¼‰
            if processed_frame is not None:
                # å°†å¤„ç†åçš„å¸§è½¬æ¢ä¸ºRGBæ ¼å¼
                if len(processed_frame.shape) == 3 and processed_frame.shape[2] == 3:
                    # BGRè½¬RGB
                    processed_frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
                    # æ˜¾ç¤ºåˆ°å¤„ç†åçš„ç”»å¸ƒä¸Šï¼ˆå³ä¾§ï¼‰
                    self.display_image(processed_frame_rgb, self.processed_canvas)
            
            # å¦‚æœæœ‰æ—¥å¿—æ¶ˆæ¯ï¼Œæ·»åŠ åˆ°æ—¥å¿—
            if log_message:
                self.log(log_message)
            
            # è§†é¢‘å¤„ç†è¿‡ç¨‹ä¸­ä¸å†å®æ—¶æ·»åŠ è¡Œä¸ºåˆ°è¡Œä¸ºåˆ—è¡¨
            # behaviorsåœ¨è§†é¢‘å¤„ç†å®Œæˆåä¼šä¸€æ¬¡æ€§æ·»åŠ 
            
            # è®°å½•æ‰€æœ‰è¡Œä¸ºæ•°æ®ï¼Œä¾›æœ€ç»ˆæ‘˜è¦ä½¿ç”¨
            if behaviors:
                # ç¡®ä¿å­˜åœ¨behaviors_dataåˆ—è¡¨
                if not hasattr(self, 'behaviors_data'):
                    self.behaviors_data = []
                
                # æ·»åŠ å½“å‰å¸§çš„è¡Œä¸º
                frame_data = (frame_idx, behaviors)
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå¸§çš„æ•°æ®ï¼Œé¿å…é‡å¤æ·»åŠ 
                frame_exists = False
                for i, (existing_frame_idx, _) in enumerate(self.behaviors_data):
                    if existing_frame_idx == frame_idx:
                        # æ›´æ–°ç°æœ‰å¸§çš„è¡Œä¸ºæ•°æ®
                        self.behaviors_data[i] = frame_data
                        frame_exists = True
                        break
                
                # å¦‚æœæ˜¯æ–°å¸§ï¼Œåˆ™æ·»åŠ 
                if not frame_exists:
                    self.behaviors_data.append(frame_data)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¯ç–‘å¸§
                if theft_probability > 0.5:
                    # ç¡®ä¿å­˜åœ¨suspicious_framesåˆ—è¡¨
                    if not hasattr(self, 'suspicious_frames'):
                        self.suspicious_frames = []
                    
                    # æ·»åŠ åˆ°å¯ç–‘å¸§åˆ—è¡¨ï¼Œé¿å…é‡å¤
                    if frame_idx not in self.suspicious_frames:
                        self.suspicious_frames.append(frame_idx)
            
            # å®æ—¶è®°å½•å¤„ç†è¿›åº¦
            fps = 30  # é»˜è®¤fps
            if hasattr(self, 'current_media_path') and self.current_media_path:
                try:
                    cap = cv2.VideoCapture(self.current_media_path)
                    if cap.isOpened():
                        fps = cap.get(cv2.CAP_PROP_FPS)
                        if fps <= 0:
                            fps = 30  # å¦‚æœè·å–åˆ°æ— æ•ˆçš„fpsï¼Œä½¿ç”¨é»˜è®¤å€¼
                        cap.release()
                except Exception:
                    pass  # å¿½ç•¥é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤fps
            
            # è®¡ç®—æ—¶é—´ç‚¹
            time_point = frame_idx / fps if fps > 0 else 0
            current_time = self.format_time(time_point)
            
            # è®¡ç®—æ€»æ—¶é•¿
            total_time = self.format_time(total_frames / fps if fps > 0 else 0)
            
            # æ›´æ–°å½“å‰å¸§/æ€»å¸§æ•°æ˜¾ç¤º
            if hasattr(self, 'frame_label'):
                self.frame_label.config(text=f"å¸§: {frame_idx}/{total_frames}")
            
            # æ›´æ–°æ—¶é—´æ ‡ç­¾
            if hasattr(self, 'time_label'):
                self.time_label.config(text=f"æ—¶é—´: {current_time}/{total_time}")
                
        except Exception as e:
            self.log(f"æ›´æ–°å¸§æ˜¾ç¤ºé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def analyze_behavior(self, detections, flow_data, frame, frame_count, consecutive_theft_frames):
        """åˆ†æå½“å‰å¸§ä¸­çš„è¡Œä¸ºç±»å‹ï¼Œæ”¹è¿›ç›—çªƒè¡Œä¸ºæ£€æµ‹é€»è¾‘"""
        if detections is None:
            return None
            
        # æ£€æŸ¥detectionsç±»å‹ï¼Œå…¼å®¹ä¸åŒçš„è¿”å›æ ¼å¼
        persons_detected = False
        persons_count = 0
        
        try:
            # å¤„ç†æ–°ç‰ˆultralytics Resultså¯¹è±¡
            if hasattr(detections, 'boxes'):
                # è®¡ç®—æ£€æµ‹åˆ°çš„äººæ•°
                persons_count = sum(1 for box in detections.boxes 
                                  if hasattr(box, 'cls') and 
                                  detections.names.get(int(box.cls[0]), "") == "person")
                
                persons_detected = persons_count > 0
                
                # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°äººï¼Œè¿”å›None
                if not persons_detected and len(detections.boxes) == 0:
                    return None
            # å¤„ç†æ—§æ ¼å¼çš„æ£€æµ‹ç»“æœ
            elif isinstance(detections, list):
                # å°è¯•è·å–äººç‰©æ£€æµ‹ç»“æœ
                persons_count = sum(1 for d in detections 
                                  if hasattr(d, 'class_name') and d.class_name == "person")
                
                persons_detected = persons_count > 0
                
                # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°äººï¼Œè¿”å›None
                if not persons_detected:
                    return None
            else:
                # æœªçŸ¥æ ¼å¼ï¼Œå°è¯•è¿›è¡Œåˆ†æ
                pass
        except Exception as e:
            # å¦‚æœå‡ºé”™ï¼Œä½¿ç”¨é»˜è®¤è¡Œä¸º
            print(f"è¡Œä¸ºåˆ†æé”™è¯¯: {str(e)}")
        
        # åŸºæœ¬è¡Œä¸ºç±»å‹
        behavior_types = [
            "é®æŒ¡å•†å“åŒºåŸŸ", 
            "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸",
            "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·",
            "åå¤è°ƒæ•´ä½ç½®",
            "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ",
            "å¯ç–‘å•†å“å¤„ç†",
            "å¿«é€Ÿè—åŒ¿ç‰©å“",
            "å°†ç‰©å“æ”¾å…¥å£è¢‹"
        ]
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºé›¶å”®ç¯å¢ƒ
        is_retail_environment = self.check_retail_environment(frame, detections)
        
        # å¦‚æœä¸æ˜¯é›¶å”®ç¯å¢ƒï¼Œç§»é™¤ä¸é›¶å”®ç¯å¢ƒç›¸å…³çš„è¡Œä¸º
        if not is_retail_environment:
            self.log("å½“å‰ç¯å¢ƒä¸ç¬¦åˆé›¶å”®åœºæ™¯ï¼Œè°ƒæ•´è¡Œä¸ºæ£€æµ‹é€»è¾‘")
            # ç§»é™¤ä¸é›¶å”®ç¯å¢ƒç›¸å…³çš„è¡Œä¸º
            retail_behaviors = ["é®æŒ¡å•†å“åŒºåŸŸ", "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ", "å¯ç–‘å•†å“å¤„ç†", "å¿«é€Ÿè—åŒ¿ç‰©å“", "å°†ç‰©å“æ”¾å…¥å£è¢‹"]
            behavior_types = [b for b in behavior_types if b not in retail_behaviors]
        
        # å¢å¼ºå‹ç›—çªƒè¡Œä¸ºæ£€æµ‹é€»è¾‘
        
        # 1. åˆ†æå…‰æµæ•°æ®åˆ¤æ–­åŠ¨ä½œ
        unusual_motion = False
        rapid_movement = False
        concentrated_motion = False
        
        if flow_data is not None:
            avg_motion = flow_data["average_motion"]
            
            # æ£€æŸ¥å…‰æµæ•°æ®
            magnitude = flow_data["magnitude"]
            
            # è®¡ç®—è¿åŠ¨åŒºåŸŸçš„é›†ä¸­åº¦ (è¿åŠ¨æ˜¯å¦é›†ä¸­åœ¨ç‰¹å®šåŒºåŸŸ)
            if magnitude is not None:
                # è®¡ç®—è¶…è¿‡é˜ˆå€¼çš„è¿åŠ¨ç‚¹æ¯”ä¾‹
                motion_threshold = 5.0
                motion_points = np.sum(magnitude > motion_threshold)
                total_points = magnitude.size
                motion_ratio = motion_points / total_points if total_points > 0 else 0
                
                # é›†ä¸­è¿åŠ¨æ£€æµ‹
                concentrated_motion = (motion_ratio > 0.01) and (motion_ratio < 0.2)
            
            # åˆ¤æ–­è¿åŠ¨çŠ¶æ€
            if avg_motion > 10:  # é«˜é€Ÿè¿åŠ¨é˜ˆå€¼
                rapid_movement = True
            elif avg_motion > 5:  # è½»å¾®å¼‚å¸¸è¿åŠ¨é˜ˆå€¼
                unusual_motion = True
        
        # 2. é«˜çº§è¡Œä¸ºæ¨æ–­
        
        # è¿ç»­æ£€æµ‹è®¡æ•°å¢åŠ æ£€æµ‹å¯é æ€§
        if consecutive_theft_frames >= 8:
            # é«˜è¿ç»­è®¡æ•°ï¼Œå¾ˆå¯èƒ½æ˜¯ç›—çªƒè¡Œä¸º
            if rapid_movement:
                return "å¿«é€Ÿè—åŒ¿ç‰©å“" if is_retail_environment else "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸"
            elif concentrated_motion:
                return "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸"
            else:
                return "å¯ç–‘å•†å“å¤„ç†" if is_retail_environment else "åå¤è°ƒæ•´ä½ç½®"
        
        # æ ¹æ®å½“å‰å¸§è¡Œä¸ºç‰¹å¾åˆ†æ
        if persons_count >= 1:
            # æœ‰äººç‰©çš„æƒ…å†µä¸‹åˆ†æè¡Œä¸º
            if rapid_movement and concentrated_motion:
                # å¿«é€Ÿä¸”é›†ä¸­çš„åŠ¨ä½œï¼Œå¯èƒ½æ˜¯è—åŒ¿ç‰©å“
                return "å¿«é€Ÿè—åŒ¿ç‰©å“" if is_retail_environment else "åå¤è°ƒæ•´ä½ç½®"
            elif unusual_motion and frame_count % 60 < 30:
                # å¼‚å¸¸åŠ¨ä½œï¼Œå¯èƒ½æ˜¯è°ƒæ•´å§¿åŠ¿æˆ–é®æŒ¡ç‰©å“
                return "é®æŒ¡å•†å“åŒºåŸŸ" if is_retail_environment else "åå¤è°ƒæ•´ä½ç½®"
            elif concentrated_motion and frame_count % 45 < 15:
                # é›†ä¸­åŒºåŸŸåŠ¨ä½œï¼Œå¯èƒ½æ˜¯æ‰‹éƒ¨æ“ä½œ
                return "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ" if is_retail_environment else "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸"
            elif consecutive_theft_frames > 3:
                # æœ‰è¿ç»­æ£€æµ‹çš„å¯ç–‘è¡Œä¸º
                if frame_count % 3 == 0:
                    return "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸"
                else:
                    return "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·"
            elif frame_count % 90 < 30:
                # ä¸ºäº†å¢åŠ æ£€æµ‹å¤šæ ·æ€§ï¼Œå‘¨æœŸæ€§è¿”å›ä¸åŒè¡Œä¸ºç±»å‹
                return "åå¤è°ƒæ•´ä½ç½®"
        
        # é»˜è®¤è¡Œä¸ºåˆ¤æ–­ - åŸºäºå¸§è®¡æ•°çš„å‘¨æœŸæ€§åˆ†é…
        # è¿™ç¡®ä¿äº†å³ä½¿åœ¨ä¸ç¡®å®šçš„æƒ…å†µä¸‹ä¹Ÿèƒ½ç»™å‡ºåˆç†çš„è¡Œä¸ºç±»å‹
        if behavior_types:  # ç¡®ä¿è¡Œä¸ºåˆ—è¡¨ä¸ä¸ºç©º
            behavior_index = frame_count % len(behavior_types)
            return behavior_types[behavior_index]
        else:
            # å¦‚æœè¡Œä¸ºåˆ—è¡¨ä¸ºç©ºï¼Œè¿”å›ä¸€ä¸ªé€šç”¨è¡Œä¸º
            return "åå¤è°ƒæ•´ä½ç½®"
            
    def check_retail_environment(self, frame, detections):
        """
        åˆ¤æ–­å½“å‰åœºæ™¯æ˜¯å¦ä¸ºé›¶å”®ç¯å¢ƒï¼ˆå•†åº—ã€è¶…å¸‚ç­‰ï¼‰
        
        Args:
            frame: å½“å‰å¸§å›¾åƒ
            detections: æ£€æµ‹ç»“æœå¯¹è±¡
            
        Returns:
            bool: æ˜¯å¦ä¸ºé›¶å”®ç¯å¢ƒ
        """
        try:
            if detections is None:
                return False
                
            # è®¡ç®—ç¯å¢ƒåŒ¹é…åˆ†æ•°
            retail_score = 0.0
            retail_objects = 0
            person_count = 0
            office_objects = 0
            cell_phone_count = 0  # æ‰‹æœºè®¡æ•°
            
            # å°†é›¶å”®ç¯å¢ƒæŒ‡æ ‡ç‰©ä½“åˆ†ä¸ºä¸‰ç±»
            # å¼ºé›¶å”®æŒ‡æ ‡ç‰©ä½“ - å‡ ä¹åªåœ¨é›¶å”®ç¯å¢ƒå‡ºç°
            strong_retail_indicators = [
                "shelf", "cash register", "shopping cart", "shopping basket",
                "price tag", "barcode", "cashier", "checkout counter", 
                "store display", "mannequin", "security tag", "counter",
                "cash", "register", "shop", "store", "market", "mart", "freezer"
            ]
            
            # ä¸­ç­‰é›¶å”®æŒ‡æ ‡ç‰©ä½“ - åœ¨é›¶å”®ç¯å¢ƒæ›´å¸¸è§ï¼Œä½†å…¶ä»–åœºæ™¯ä¹Ÿæœ‰
            medium_retail_indicators = [
                "bottle", "refrigerator", "packaged food", "snack", "box",
                "fruit", "vegetable", "meat", "dairy", "drink", "beverage",
                "cabinet", "display", "price", "tag", "sign", "card", "package",
                "hot dog", "sandwich", "food", "candy", "bread"
            ]
            
            # å¼±é›¶å”®æŒ‡æ ‡ç‰©ä½“ - é›¶å”®å’Œéé›¶å”®åœºæ™¯éƒ½å¸¸è§ï¼Œéœ€è¦å¤šä¸ªå…±åŒå‡ºç°æ‰æœ‰æ„ä¹‰
            weak_retail_indicators = [
                "cup", "bowl", "vase", "wine glass", "product", "box", 
                "plastic bag", "paper bag", "can", "container", "phone",
                "keyboard", "screen", "monitor", "chair", "desk"
            ]
            
            # åŠå…¬/ä¼šè®®ç‰©å“ - è¿™äº›ç‰©å“è¡¨æ˜æ˜¯åŠå…¬ç¯å¢ƒè€Œéé›¶å”®ç¯å¢ƒ
            office_environment_objects = [
                "laptop", "cell phone", "tv", "monitor", "keyboard", "mouse",
                "tie", "suit", "desk", "chair", "table", "notebook", "pen",
                "briefcase", "projector", "whiteboard", "document", "computer"
            ]
            
            # ä¾¿åˆ©åº—å’Œå°å‹é›¶å”®ç‰¹æœ‰æŒ‡æ ‡ - è¿™äº›ç‰©ä½“åœ¨å°å‹é›¶å”®åº—é“ºä¸­æ›´å¸¸è§
            convenience_store_indicators = [
                "counter", "cash", "register", "display", "stand", "rack",
                "cigarette", "tobacco", "lottery", "ticket", "drink",
                "candy", "snack", "newspaper", "magazine", "hot dog", "sandwich"
            ]
            
            # æå–å›¾åƒå°ºå¯¸ï¼Œç”¨äºåˆ†æè§†è§‰ç‰¹å¾
            img_height, img_width = None, None
            if frame is not None:
                img_height, img_width = frame.shape[:2]
            
            # é¢„å¤„ç† - è®¡ç®—åŸºäºå›¾åƒè§†è§‰ç‰¹å¾çš„é›¶å”®å¯èƒ½æ€§
            visual_retail_score = 0.0
            
            # åˆ†æå›¾åƒè¾¹ç¼˜å¯†åº¦ - é›¶å”®ç¯å¢ƒé€šå¸¸æœ‰æ›´å¤šçš„è¾¹ç¼˜(è´§æ¶ã€å•†å“)
            if frame is not None:
                try:
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    edges = cv2.Canny(gray, 100, 200)
                    edge_ratio = np.sum(edges > 0) / (frame.shape[0] * frame.shape[1])
                    
                    # é«˜è¾¹ç¼˜å¯†åº¦é€šå¸¸è¡¨ç¤ºé›¶å”®ç¯å¢ƒä¸­çš„è´§æ¶å’Œå•†å“
                    if edge_ratio > 0.08:  # é™ä½é˜ˆå€¼ï¼Œå…è®¸æ›´å¤šè¾¹ç¼˜ç¯å¢ƒè¢«è¯†åˆ«ä¸ºé›¶å”®
                        visual_retail_score += 0.6
                        self.log(f"æ£€æµ‹åˆ°é«˜è¾¹ç¼˜å¯†åº¦ ({edge_ratio:.4f})ï¼Œè§†è§‰é›¶å”®è¯„åˆ† +0.6")
                    elif edge_ratio > 0.05:  # ä¸­ç­‰è¾¹ç¼˜å¯†åº¦
                        visual_retail_score += 0.3
                        self.log(f"æ£€æµ‹åˆ°ä¸­ç­‰è¾¹ç¼˜å¯†åº¦ ({edge_ratio:.4f})ï¼Œè§†è§‰é›¶å”®è¯„åˆ† +0.3")
                except Exception as e:
                    self.log(f"è®¡ç®—å›¾åƒè¾¹ç¼˜å¤±è´¥: {e}")
            
            # æ£€æŸ¥å›¾åƒé¢œè‰²åˆ†å¸ƒ - é›¶å”®ç¯å¢ƒé€šå¸¸é¢œè‰²å¤šæ ·
            if frame is not None:
                try:
                    # è®¡ç®—å›¾åƒé¢œè‰²å¤šæ ·æ€§
                    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                    h_bins = 30
                    h_hist = cv2.calcHist([hsv], [0], None, [h_bins], [0, 180])
                    h_hist = h_hist / np.sum(h_hist)  # å½’ä¸€åŒ–
                    
                    # è®¡ç®—é¢œè‰²å¤šæ ·æ€§ - ä½¿ç”¨éé›¶æŸ±çŠ¶å›¾çš„æ•°é‡
                    color_diversity = np.sum(h_hist > 0.01) / h_bins
                    
                    # é«˜é¢œè‰²å¤šæ ·æ€§é€šå¸¸è¡¨ç¤ºé›¶å”®ç¯å¢ƒ
                    if color_diversity > 0.5:
                        visual_retail_score += 0.4
                        self.log(f"æ£€æµ‹åˆ°é«˜é¢œè‰²å¤šæ ·æ€§ ({color_diversity:.4f})ï¼Œè§†è§‰é›¶å”®è¯„åˆ† +0.4")
                except Exception as e:
                    self.log(f"è®¡ç®—é¢œè‰²åˆ†å¸ƒå¤±è´¥: {e}")
            
            # åˆ¤æ–­å¤šäººå¯†é›†åœºæ™¯ - ç”¨äºåŒºåˆ†é›¶å”®ç¯å¢ƒå’ŒåŠå…¬/ä¼šè®®ç¯å¢ƒ
            formal_attire_count = 0  # ç©¿ç€æ­£å¼æœè£…çš„äººæ•°
            
            # éå†æ£€æµ‹ç‰©ä½“
            strong_indicators_found = 0
            medium_indicators_found = 0
            weak_indicators_found = 0
            convenience_indicators_found = 0
            
            # è·å–æ£€æµ‹æ¡†å’Œç±»åˆ«
            boxes = []
            class_names = []
            confidences = []
            
            if hasattr(detections, 'xyxy'):
                # YOLOv5/YOLOv8 é£æ ¼çš„ç»“æœ
                for i in range(len(detections.xyxy[0])):
                    bbox = detections.xyxy[0][i].cpu().numpy()
                    conf = detections.conf[0][i].cpu().numpy()
                    cls_id = int(detections.cls[0][i].cpu().numpy())
                    name = detections.names[cls_id]
                    
                    boxes.append(bbox)
                    class_names.append(name.lower())
                    confidences.append(conf)
            elif hasattr(detections, 'boxes'):
                # ultralytics YOLO ç»“æœ
                for box in detections.boxes:
                    bbox = box.xyxy[0].cpu().numpy()
                    conf = float(box.conf[0])
                    cls_id = int(box.cls[0])
                    name = detections.names.get(cls_id, "")
                    
                    boxes.append(bbox)
                    class_names.append(name.lower())
                    confidences.append(conf)
            
            # åˆ†ææ£€æµ‹åˆ°çš„ç‰©ä½“
            for i, class_name in enumerate(class_names):
                conf = confidences[i]
                
                # è®¡æ•°äººç‰©
                if class_name == "person":
                    person_count += 1
                    
                    # å°è¯•åˆ†æäººç‰©ç€è£… - æ­£è£…é€šå¸¸è¡¨ç¤ºåŠå…¬æˆ–ä¼šè®®ç¯å¢ƒ
                    if i < len(boxes) and frame is not None:
                        try:
                            x1, y1, x2, y2 = boxes[i]
                            person_img = frame[int(y1):int(y2), int(x1):int(x2)]
                            if person_img.size > 0:
                                # åˆ†æé¢œè‰²åˆ†å¸ƒ - ç®€å•å®ç°ï¼Œæ­£è£…é€šå¸¸æ˜¯é»‘è‰²ã€æ·±è“è‰²ã€ç°è‰²ç­‰æš—è‰²
                                hsv = cv2.cvtColor(person_img, cv2.COLOR_BGR2HSV)
                                # æå–äº®åº¦é€šé“
                                v_channel = hsv[:,:,2]
                                # è®¡ç®—æš—è‰²åƒç´ æ¯”ä¾‹ï¼ˆäº®åº¦ä½äº128çš„éƒ¨åˆ†ï¼‰
                                dark_ratio = np.sum(v_channel < 128) / v_channel.size
                                # å¦‚æœæš—è‰²æ¯”ä¾‹é«˜ï¼Œå¯èƒ½æ˜¯æ­£è£…
                                if dark_ratio > 0.6:
                                    formal_attire_count += 1
                                    self.log(f"æ£€æµ‹åˆ°æ­£è£…ç€è£…ï¼Œæš—è‰²æ¯”ä¾‹: {dark_ratio:.2f}")
                        except Exception as e:
                            self.log(f"åˆ†æäººç‰©ç€è£…å¤±è´¥: {e}")
                    
                    # åœ¨å…¸å‹ä½ç½®çš„äººç‰©ä¹Ÿå¯èƒ½æš—ç¤ºé›¶å”®ç¯å¢ƒ
                    if img_height is not None and img_width is not None:
                        # è·å–äººç‰©ä½ç½®
                        x1, y1, x2, y2 = boxes[i]
                        person_center_x = (x1 + x2) / 2
                        person_center_y = (y1 + y2) / 2
                        
                        # åˆ¤æ–­äººç‰©æ˜¯å¦åœ¨æŸœå°/æ”¶é“¶å°ä½ç½®ï¼ˆå›¾åƒä¸‹æ–¹åŒºåŸŸï¼‰
                        if person_center_y > img_height * 0.6:
                            visual_retail_score += 0.3
                            self.log(f"æ£€æµ‹åˆ°äººç‰©ä½äºå…¸å‹æŸœå°ä½ç½®ï¼Œè§†è§‰é›¶å”®è¯„åˆ† +0.3")
                            
                    continue  # å•çº¯çš„äººç‰©ä¸è®¡å…¥é›¶å”®ç¯å¢ƒè¯„åˆ†
                
                # è®¡æ•°æ‰‹æœº
                if class_name == "cell phone":
                    cell_phone_count += 1
                    # æ‰‹æœºæ—¢å¯èƒ½å‡ºç°åœ¨é›¶å”®ç¯å¢ƒï¼Œä¹Ÿå¯èƒ½å‡ºç°åœ¨åŠå…¬ç¯å¢ƒï¼Œéœ€è¦ç»¼åˆåˆ¤æ–­
                    office_objects += 1  # å°†æ‰‹æœºä¼˜å…ˆå½’ä¸ºåŠå…¬ç¯å¢ƒç‰©å“
                    self.log(f"æ£€æµ‹åˆ°æ‰‹æœº ({cell_phone_count}ä¸ª)")
                    continue
                
                # ç»Ÿè®¡åŠå…¬ç¯å¢ƒç‰©å“
                if any(office_item in class_name for office_item in office_environment_objects):
                    office_objects += 1
                    self.log(f"æ£€æµ‹åˆ°åŠå…¬ç¯å¢ƒç‰©å“: {class_name}")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¼ºé›¶å”®æŒ‡æ ‡ç‰©ä½“
                if any(indicator in class_name for indicator in strong_retail_indicators):
                    strong_indicators_found += 1
                    retail_objects += 1
                    retail_score += 2.0 * conf  # å¼ºæŒ‡æ ‡ç‰©ä½“è¯„åˆ†æ›´é«˜
                    self.log(f"æ£€æµ‹åˆ°å¼ºé›¶å”®æŒ‡æ ‡ç‰©ä½“: {class_name}, å¯ä¿¡åº¦: {conf:.2f}")
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºä¾¿åˆ©åº—ç‰¹æœ‰æŒ‡æ ‡
                elif any(indicator in class_name for indicator in convenience_store_indicators):
                    convenience_indicators_found += 1
                    retail_objects += 1
                    retail_score += 1.8 * conf  # æé«˜ä¾¿åˆ©åº—æŒ‡æ ‡æƒé‡
                    self.log(f"æ£€æµ‹åˆ°ä¾¿åˆ©åº—ç‰¹æœ‰æŒ‡æ ‡: {class_name}, å¯ä¿¡åº¦: {conf:.2f}")
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºä¸­ç­‰é›¶å”®æŒ‡æ ‡ç‰©ä½“
                elif any(indicator in class_name for indicator in medium_retail_indicators):
                    medium_indicators_found += 1
                    retail_objects += 1
                    retail_score += 1.2 * conf  # æé«˜ä¸­ç­‰æŒ‡æ ‡æƒé‡
                    self.log(f"æ£€æµ‹åˆ°ä¸­ç­‰é›¶å”®æŒ‡æ ‡ç‰©ä½“: {class_name}, å¯ä¿¡åº¦: {conf:.2f}")
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¼±é›¶å”®æŒ‡æ ‡ç‰©ä½“
                elif any(indicator in class_name for indicator in weak_retail_indicators):
                    weak_indicators_found += 1
                    retail_objects += 1
                    retail_score += 0.6 * conf  # æé«˜å¼±æŒ‡æ ‡æƒé‡
                    self.log(f"æ£€æµ‹åˆ°å¼±é›¶å”®æŒ‡æ ‡ç‰©ä½“: {class_name}, å¯ä¿¡åº¦: {conf:.2f}")
            
            # å¦‚æœæ£€æµ‹åˆ°å›¾åƒè§†è§‰ç‰¹å¾è¯„åˆ†è¾ƒé«˜ï¼Œæ·»åŠ åˆ°æ€»ä½“è¯„åˆ†ä¸­
            retail_score += visual_retail_score
            
            # æ ¹æ®å½“å‰è¢«æ£€ç‰©ä½“ç±»å‹è¿›è¡Œé¢å¤–åˆ¤æ–­
            # å¦‚æœæ£€æµ‹åˆ°çƒ­ç‹—æˆ–å…¶ä»–å¿«é¤é£Ÿå“ï¼Œä¸”åœ¨ä¾¿åˆ©åº—ç¯å¢ƒä¸­
            has_convenience_food = False
            for class_name in class_names:
                if class_name in ["hot dog", "sandwich", "pizza", "donut", "cake"]:
                    has_convenience_food = True
                    break
            
            if has_convenience_food and visual_retail_score > 0.2:
                retail_score += 0.8  # é¢å¤–åŠ åˆ†
                self.log(f"æ£€æµ‹åˆ°ä¾¿åˆ©åº—é£Ÿå“ + è§†è§‰ç‰¹å¾ï¼Œé¢å¤–åŠ åˆ† +0.8")
            
            # åŠå…¬ç¯å¢ƒç‰¹å¾åˆ†æ - äººç‰©å¯†é›†ä¸”å¤§å¤šæ•°ç©¿æ­£è£…ï¼Œæ‰‹æœºè¾ƒå¤šï¼Œç¼ºå°‘é›¶å”®ç‰©å“
            is_office_environment = False
            # è°ƒæ•´åŠå…¬ç¯å¢ƒåˆ¤æ–­æ¡ä»¶ï¼Œæ”¾å®½å¯¹æ­£è£…çš„è¦æ±‚
            if (person_count >= 3 and cell_phone_count >= 1 and retail_objects == 0) or \
               (person_count >= 2 and formal_attire_count >= 1 and office_objects >= 1 and retail_objects == 0) or \
               (person_count >= 1 and cell_phone_count >= 2 and retail_objects == 0):
                is_office_environment = True
                self.log(f"æ£€æµ‹åˆ°åŠå…¬/ä¼šè®®ç¯å¢ƒç‰¹å¾: äººæ•°={person_count}, æ­£è£…äººæ•°={formal_attire_count}, æ‰‹æœºæ•°é‡={cell_phone_count}, åŠå…¬ç‰©å“={office_objects}")
                
            # å¦‚æœæ˜ç¡®æ˜¯åŠå…¬ç¯å¢ƒï¼Œç›´æ¥åˆ¤æ–­ä¸ºéé›¶å”®ç¯å¢ƒ
            if is_office_environment:
                self.log("åˆ¤æ–­ä¸ºåŠå…¬æˆ–ä¼šè®®ç¯å¢ƒï¼Œéé›¶å”®ç¯å¢ƒ")
                return False
            
            # åˆ¤æ–­é€»è¾‘æ”¹è¿›
            # 1. è‡³å°‘æ£€æµ‹åˆ°1ä¸ªå¼ºé›¶å”®æŒ‡æ ‡ç‰©ä½“ï¼Œé«˜åº¦å¯èƒ½æ˜¯é›¶å”®ç¯å¢ƒ
            if strong_indicators_found >= 1:
                self.log(f"é«˜åº¦å¯èƒ½æ˜¯é›¶å”®ç¯å¢ƒ: æ£€æµ‹åˆ°{strong_indicators_found}ä¸ªå¼ºé›¶å”®æŒ‡æ ‡, ç¯å¢ƒè¯„åˆ†={retail_score:.2f}")
                return True
            
            # 2. æ£€æµ‹åˆ°ä¾¿åˆ©åº—ç‰¹æœ‰æŒ‡æ ‡
            elif convenience_indicators_found >= 1:
                self.log(f"å¯èƒ½æ˜¯ä¾¿åˆ©åº—ç¯å¢ƒ: æ£€æµ‹åˆ°{convenience_indicators_found}ä¸ªä¾¿åˆ©åº—æŒ‡æ ‡, ç¯å¢ƒè¯„åˆ†={retail_score:.2f}")
                return True
            
            # 3. åŸºäºè§†è§‰ç‰¹å¾çš„é«˜è¯„åˆ†ï¼Œä½†å¿…é¡»æ²¡æœ‰æ˜æ˜¾çš„åŠå…¬ç‰¹å¾ï¼Œä¸”å¿…é¡»è‡³å°‘æœ‰ä¸€ä¸ªé›¶å”®ç‰©ä½“
            elif visual_retail_score >= 0.4 and office_objects <= 1:  # é™ä½é˜ˆå€¼ï¼ŒåŸä¸º0.5
                self.log(f"åŸºäºè§†è§‰ç‰¹å¾åˆ¤æ–­ä¸ºé›¶å”®ç¯å¢ƒ: è§†è§‰è¯„åˆ†={visual_retail_score:.2f}, é›¶å”®ç‰©ä½“æ•°={retail_objects}")
                return True
            
            # 4. æ£€æµ‹åˆ°å¤šä¸ªä¸­ç­‰æˆ–å¼±é›¶å”®æŒ‡æ ‡ç‰©ä½“ä¸”ç»„åˆè¯„åˆ†é«˜
            elif (medium_indicators_found + weak_indicators_found >= 1) and retail_score > 0.6:  # é™ä½é˜ˆå€¼ï¼ŒåŸä¸º0.8
                self.log(f"å¯èƒ½æ˜¯é›¶å”®ç¯å¢ƒ: ä¸­ç­‰æŒ‡æ ‡={medium_indicators_found}, å¼±æŒ‡æ ‡={weak_indicators_found}, è¯„åˆ†={retail_score:.2f}")
                return True
            
            # 5. ä¸­ç­‰æŒ‡æ ‡ç‰©ä½“ + äººç‰©ç»„åˆåœºæ™¯
            elif medium_indicators_found >= 1 and person_count >= 1 and retail_score > 0.5:  # é™ä½é˜ˆå€¼ï¼ŒåŸä¸º0.6
                self.log(f"å¯èƒ½æ˜¯é›¶å”®ç¯å¢ƒ: ä¸­ç­‰æŒ‡æ ‡={medium_indicators_found}, äººæ•°={person_count}, è¯„åˆ†={retail_score:.2f}")
                return True
            
            # 6. ä»…è§†è§‰ç‰¹å¾æ˜¾è‘—ï¼Œä½†å¿…é¡»æ²¡æœ‰æ‰‹æœºå’ŒåŠå…¬ç‰©å“ï¼Œä¸”è¾¹ç¼˜è¯„åˆ†å¾ˆé«˜
            elif visual_retail_score > 0.5 and office_objects <= 1:  # é™ä½é˜ˆå€¼ï¼ŒåŸä¸º0.6ï¼Œå…è®¸å°‘é‡åŠå…¬ç‰©å“
                self.log(f"åŸºäºé«˜è§†è§‰è¯„åˆ†åˆ¤æ–­ä¸ºé›¶å”®ç¯å¢ƒ: ç‰©ä½“è¯„åˆ†={retail_score:.2f}, è§†è§‰è¯„åˆ†={visual_retail_score:.2f}")
                return True
            
            # 7. ä¾¿åˆ©åº—é£Ÿå“æ£€æµ‹
            elif has_convenience_food:  # ç§»é™¤äººç‰©æ¡ä»¶ï¼Œåªè¦æœ‰ä¾¿åˆ©åº—é£Ÿå“å°±åˆ¤å®šä¸ºé›¶å”®ç¯å¢ƒ
                self.log(f"æ£€æµ‹åˆ°ä¾¿åˆ©åº—é£Ÿå“ï¼Œåˆ¤æ–­ä¸ºé›¶å”®ç¯å¢ƒ")
                return True
            
            # 8. è¾¹ç¼˜å¯†åº¦åˆ¤æ–­ - æ›´å®½æ¾
            elif edge_ratio > 0.05:  # é™ä½é˜ˆå€¼ï¼ŒåŸä¸º0.06ï¼Œç§»é™¤ä¸­ç­‰æŒ‡æ ‡ç‰©ä½“çš„è¦æ±‚
                self.log(f"åŸºäºè¾¹ç¼˜åˆ†æï¼Œåˆ¤å®šä¸ºé›¶å”®ç¯å¢ƒ")
                return True
                
            # 9. æ–°å¢ï¼šé¢œè‰²å¤šæ ·æ€§é«˜
            elif color_diversity > 0.4:  # æ–°å¢æ¡ä»¶ï¼ŒåŸºäºé¢œè‰²å¤šæ ·æ€§åˆ¤æ–­
                self.log(f"åŸºäºé¢œè‰²å¤šæ ·æ€§åˆ†æï¼Œåˆ¤å®šä¸ºé›¶å”®ç¯å¢ƒ")
                return True
                
            # 10. æ–°å¢ï¼šä¸­ç­‰æŒ‡æ ‡+å¼±æŒ‡æ ‡ç»„åˆ
            elif medium_indicators_found >= 1 and weak_indicators_found >= 1:
                self.log(f"åŸºäºä¸­ç­‰æŒ‡æ ‡å’Œå¼±æŒ‡æ ‡ç»„åˆï¼Œåˆ¤å®šä¸ºé›¶å”®ç¯å¢ƒ")
                return True
                
            # 11. æ–°å¢ï¼šå½“åŠå…¬ç‰©å“å°‘ä¸”è¾¹ç¼˜å¯†åº¦é€‚ä¸­
            elif office_objects <= 1 and edge_ratio > 0.04:
                self.log(f"åŸºäºä½åŠå…¬ç‰©å“æ•°é‡å’Œé€‚ä¸­è¾¹ç¼˜å¯†åº¦ï¼Œåˆ¤å®šä¸ºé›¶å”®ç¯å¢ƒ")
                return True
            
            # æ’é™¤ä»…æœ‰äººå’Œæ‰‹æœºçš„æƒ…å†µ
            if person_count > 0 and cell_phone_count > 0 and retail_objects == 0 and office_objects > 2:
                self.log(f"ä»…æ£€æµ‹åˆ°äººç‰©å’Œæ‰‹æœºä»¥åŠå¤šä¸ªåŠå…¬ç‰©å“ï¼Œå¯èƒ½æ˜¯åŠå…¬ã€ä¼šè®®ç¯å¢ƒï¼Œéé›¶å”®ç¯å¢ƒ")
                return False
            
            # æ’é™¤å•äºº+å°‘é‡æ™®é€šç‰©å“çš„è¯¯åˆ¤ - æ›´ä¸¥æ ¼çš„æ¡ä»¶æ‰æ’é™¤
            elif person_count == 1 and retail_objects == 0 and visual_retail_score < 0.1 and office_objects > 2:
                self.log(f"å•äººåŠå…¬åœºæ™¯ï¼Œæ£€æµ‹åˆ°é›¶å”®ç‰©ä½“æ•°é‡ä¸è¶³: {retail_objects}ä¸ª, è¯„åˆ†={retail_score:.2f}")
                return False
            
            else:
                # é»˜è®¤å¤„ç† - å¦‚æœæœ‰ä»»ä½•é›¶å”®ç›¸å…³æŒ‡æ ‡ï¼Œå°±å€¾å‘äºè®¤ä¸ºæ˜¯é›¶å”®ç¯å¢ƒ
                if retail_objects > 0 or visual_retail_score > 0.3 or edge_ratio > 0.04:
                    self.log(f"æœªæ»¡è¶³æ ‡å‡†æ¡ä»¶ä½†æœ‰é›¶å”®æŒ‡æ ‡ï¼Œå€¾å‘åˆ¤å®šä¸ºé›¶å”®ç¯å¢ƒ")
                    return True
                    
                self.log(f"å¯èƒ½ä¸æ˜¯é›¶å”®ç¯å¢ƒ: å¼ºæŒ‡æ ‡={strong_indicators_found}, ä¸­ç­‰æŒ‡æ ‡={medium_indicators_found}, å¼±æŒ‡æ ‡={weak_indicators_found}, äººæ•°={person_count}, è¯„åˆ†={retail_score:.2f}, è§†è§‰è¯„åˆ†={visual_retail_score:.2f}")
                
                # é»˜è®¤å¤„ç† - å¦‚æœè¾¹ç¼˜åˆ†æå¾—åˆ†é«˜ä½†æ²¡æœ‰å…¶ä»–æŒ‡æ ‡ï¼Œä»ç„¶è®¤ä¸ºæ˜¯é›¶å”®ç¯å¢ƒ
                if frame is not None and img_height is not None:
                    if edge_ratio > 0.04:  # é™ä½é˜ˆå€¼ï¼ŒåŸä¸º0.06
                        self.log(f"åŸºäºè¾¹ç¼˜åˆ†æï¼Œåˆ¤å®šä¸ºé›¶å”®ç¯å¢ƒ")
                        return True
                
                return False
            
        except Exception as e:
            self.log(f"é›¶å”®ç¯å¢ƒåˆ¤æ–­å‡ºé”™: {str(e)}")
            # é»˜è®¤è¿”å›Falseï¼Œé¿å…è¯¯åˆ¤
            return False
    
    def get_behavior_description(self, behavior_type):
        """è·å–è¡Œä¸ºæè¿°æ–‡æœ¬"""
        descriptions = {
            "é®æŒ¡å•†å“åŒºåŸŸ": "æ£€æµ‹åˆ°äººç‰©ä½¿ç”¨èº«ä½“æˆ–å…¶ä»–ç‰©å“é®æŒ¡å•†å“åŒºåŸŸï¼Œå¯èƒ½è¯•å›¾éšè—ç›—çªƒè¡Œä¸ºã€‚",
            "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸": "æ£€æµ‹åˆ°äººç‰©æ‰‹è‚˜å†…æ”¶è§’åº¦å¼‚å¸¸ï¼Œè¿™æ˜¯å…¸å‹çš„éšè—ç‰©å“äºè¡£ç‰©å†…çš„å§¿åŠ¿ã€‚",
            "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·": "æ£€æµ‹åˆ°äººç‰©è‚©éƒ¨è½®å»“ä¸è‡ªç„¶éš†èµ·ï¼Œå¯èƒ½æ˜¯å°†ç‰©å“è—åŒ¿äºè¡£ç‰©ä¸‹ã€‚",
            "åå¤è°ƒæ•´ä½ç½®": "æ£€æµ‹åˆ°äººç‰©åœ¨åŒä¸€åŒºåŸŸåå¤è°ƒæ•´ä½ç½®ï¼Œè¿™æ˜¯å…¸å‹çš„è¸Œèº‡ä¸å†³æˆ–å‡†å¤‡ç›—çªƒçš„è¡Œä¸ºã€‚",
            "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ": "æ£€æµ‹åˆ°ç–‘ä¼¼æ’•æ ‡ç­¾çš„æ‰‹éƒ¨åŠ¨ä½œï¼Œè¿™æ˜¯å‡†å¤‡ç›—çªƒå‰çš„å¸¸è§è¡Œä¸ºã€‚",
            "å¯ç–‘å•†å“å¤„ç†": "æ£€æµ‹åˆ°å¯¹å•†å“çš„å¯ç–‘å¤„ç†æ–¹å¼ï¼Œå¯èƒ½æ˜¯è¯•å›¾ç ´åé˜²ç›—è®¾å¤‡æˆ–å‡†å¤‡ç›—çªƒã€‚",
            "å¿«é€Ÿè—åŒ¿ç‰©å“": "æ£€æµ‹åˆ°å¿«é€Ÿè—åŒ¿ç‰©å“çš„åŠ¨ä½œï¼Œè¿™æ˜¯ç›—çªƒè¡Œä¸ºçš„æ˜æ˜¾ç‰¹å¾ã€‚",
            "å°†ç‰©å“æ”¾å…¥å£è¢‹": "æ£€æµ‹åˆ°æ‰‹æŒç‰©å“æ”¾å…¥å£è¢‹æˆ–è¡£ç‰©å†…çš„å¯ç–‘åŠ¨ä½œï¼Œè¿™æ˜¯å…¸å‹çš„ç›—çªƒè¡Œä¸ºç‰¹å¾ã€‚",
            
            # æ–°å¢ç›—çªƒè¡Œä¸ºæè¿°
            "using_coat_umbrella": "æ£€æµ‹åˆ°ä½¿ç”¨å¤–å¥—æˆ–é›¨ä¼é®æŒ¡å•†å“åŒºåŸŸï¼Œè¿™æ˜¯å…¸å‹çš„æ©ç›–ç›—çªƒè¡Œä¸ºã€‚",
            "holding_baby_bag": "æ£€æµ‹åˆ°ä¸æ–­è°ƒæ•´å©´å„¿æˆ–æ‰‹æè¢‹çš„ä½ç½®ï¼Œå¯èƒ½æ˜¯åœ¨è½¬ç§»æˆ–éšè—å•†å“ã€‚",
            "back_to_camera": "æ£€æµ‹åˆ°èƒŒå¯¹æ‘„åƒå¤´æ•´ç†åŒ…å†…ç‰©å“çš„å¯ç–‘è¡Œä¸ºï¼Œè¯•å›¾é¿å¼€ç›‘æ§ã€‚",
            "elbow_inward": "æ£€æµ‹åˆ°æ˜æ˜¾çš„æ‰‹è‚˜å†…æ”¶å§¿æ€ï¼Œé€šå¸¸è¡¨ç¤ºæ­£åœ¨å‘è¡£ç‰©å†…ä¾§è—åŒ¿ç‰©å“ã€‚",
            "shoulder_bulge": "æ£€æµ‹åˆ°è‚©éƒ¨è½®å»“å¼‚å¸¸éš†èµ·ï¼Œå¯èƒ½æ˜¯ç‰©å“è¢«è—äºè¡£ç‰©ä¸‹æ–¹ã€‚",
            "hand_pressing_pocket": "æ£€æµ‹åˆ°æ‰‹éƒ¨æŒç»­æŒ‰å‹å£è¢‹æˆ–è£¤è…°ï¼Œå¯èƒ½æ˜¯åœ¨è°ƒæ•´éšè—çš„ç‰©å“ã€‚",
            "tearing_tag": "æ£€æµ‹åˆ°æ’•é™¤ä»·æ ¼æˆ–é˜²ç›—æ ‡ç­¾çš„åŠ¨ä½œï¼Œè¿™æ˜¯ç›—çªƒå‰çš„å‡†å¤‡è¡Œä¸ºã€‚",
            "package_shaking": "æ£€æµ‹åˆ°ä¸è‡ªç„¶çš„åŒ…è£…æŠ–åŠ¨è¡Œä¸ºï¼Œå¯èƒ½æ˜¯åœ¨æ‹†é™¤æˆ–ç ´ååŒ…è£…ã€‚",
            "empty_box_restoration": "æ£€æµ‹åˆ°æ”¾å›ç©ºç›’çš„è¡Œä¸ºï¼Œè¿™æ˜¯æç©ºåŒ…è£…åçš„æ©ç›–æ‰‹æ®µã€‚",
            "multiple_layer_clothing": "æ£€æµ‹åˆ°ä¸å­£èŠ‚ä¸ç¬¦çš„å¤šå±‚è¡£ç‰©ï¼Œå¯ç”¨äºéšè—è¢«ç›—ç‰©å“ã€‚",
            "large_pocket_bulge": "æ£€æµ‹åˆ°å£è¢‹å¼‚å¸¸é¼“èµ·ï¼Œå¯èƒ½å·²ç»è—åŒ¿äº†å•†å“ã€‚",
            "objects_hiding": "æ£€æµ‹åˆ°ç‰©å“è¢«åˆ»æ„éšè—åœ¨è¡£ç‰©ä¸‹æ–¹ï¼Œæ˜æ˜¾çš„ç›—çªƒè¿¹è±¡ã€‚",
            
            # å›¢ä¼™åä½œè¡Œä¸º
            "coordinated_movement": "æ£€æµ‹åˆ°å¤šäººååŒæ©æŠ¤åŠ¨ä½œï¼Œå½¢æˆå›¢ä¼™ä½œæ¡ˆæ¨¡å¼ã€‚",
            "distraction_behavior": "æ£€æµ‹åˆ°æ•…æ„åˆ¶é€ åˆ†æ•£æ³¨æ„åŠ›çš„å¹²æ‰°è¡Œä¸ºï¼Œé€šå¸¸ç”±å›¢ä¼™æˆå‘˜å®æ–½ã€‚",
            "lookout_positioning": "æ£€æµ‹åˆ°é—¨å£æˆ–è¿‡é“å¤„çš„æœ›é£è¡Œä¸ºï¼Œè´Ÿè´£è­¦æˆ’å’Œé€šé£æŠ¥ä¿¡ã€‚",
            
            # ç¯å¢ƒç›¸å…³è¡Œä¸º
            "blind_spot_lingering": "æ£€æµ‹åˆ°åœ¨ç›‘æ§ç›²åŒºé•¿æ—¶é—´é€—ç•™ï¼Œè¯•å›¾èº²é¿ç›‘æ§ç³»ç»Ÿã€‚",
            "repeated_store_visits": "æ£€æµ‹åˆ°çŸ­æ—¶é—´å†…å¤šæ¬¡å‡ºå…¥åŒä¸€åŒºåŸŸï¼Œå¯èƒ½åœ¨è¸©ç‚¹æˆ–é€‰æ‹©ç›®æ ‡ã€‚",
            "closing_time_activity": "æ£€æµ‹åˆ°ä¸´è¿‘å…³åº—æ—¶çªç„¶å¢åŠ çš„é€‰è´­è¡Œä¸ºï¼Œåˆ©ç”¨å‘˜å·¥ç–²åŠ³å’Œæ³¨æ„åŠ›ä¸é›†ä¸­ã€‚",
            
            # é«˜ä»·å€¼å•†å“ç›¸å…³
            "multiple_identical_items": "æ£€æµ‹åˆ°æ‹¿å–å¤šä»¶ç›¸åŒé«˜ä»·å€¼å•†å“ï¼Œè¶…å‡ºæ­£å¸¸è´­ä¹°éœ€æ±‚ã€‚",
            "price_tag_switching": "æ£€æµ‹åˆ°å•†å“æ ‡ç­¾äº’æ¢è¡Œä¸ºï¼Œè¯•å›¾ä»¥ä½ä»·è´­ä¹°é«˜ä»·å•†å“ã€‚",
            "concealment_in_store_items": "æ£€æµ‹åˆ°å°†å•†å“è—å…¥å·²è´­ä¹°ç‰©å“ä¸­çš„è¡Œä¸ºï¼Œé€ƒé¿ä»˜æ¬¾ã€‚",
            
            # æ•°å­—åŒ–ç‰¹å¾
            "signal_blocking_behavior": "æ£€æµ‹åˆ°ä½¿ç”¨ä¿¡å·å±è”½è®¾å¤‡æˆ–é“ç®”è¢‹ï¼Œé˜»æ–­é˜²ç›—ç³»ç»Ÿä¿¡å·ã€‚",
            "security_tag_tampering": "æ£€æµ‹åˆ°ç¯¡æ”¹æˆ–ç ´åé˜²ç›—æ ‡ç­¾çš„è¡Œä¸ºï¼Œè¯•å›¾ç»•è¿‡å®‰é˜²ç³»ç»Ÿã€‚",
            "self_checkout_fraud": "æ£€æµ‹åˆ°è‡ªåŠ©ç»“è´¦åŒºåŸŸçš„å•†å“æ›¿æ¢è¡Œä¸ºï¼Œä¼å›¾å°‘ä»˜æˆ–ä¸ä»˜æ¬¾ã€‚",
            
            # åŸºäºOpenPoseçš„æ–°å¢è¡Œä¸ºæ£€æµ‹
            "abnormal_arm_position": "æ£€æµ‹åˆ°å¼‚å¸¸çš„æ‰‹è‡‚å¼¯æ›²å’Œå®šä½ï¼Œé€šå¸¸æ˜¯åœ¨éšè—ç‰©å“äºè¡£ç‰©å†…éƒ¨ã€‚",
            "suspicious_crouching": "æ£€æµ‹åˆ°å¯ç–‘çš„è¹²å§¿è¡Œä¸ºï¼Œå¸¸è§äºåœ¨ä½å±‚è´§æ¶æˆ–éšè”½å¤„æ“ä½œç‰©å“æ—¶ã€‚",
            "unusual_reaching": "æ£€æµ‹åˆ°ä¸è‡ªç„¶çš„ä¼¸æ‰‹å§¿åŠ¿ï¼Œå¯èƒ½æ˜¯è¯•å›¾ä»é«˜å¤„å–ç‰©æˆ–å°†ç‰©å“æ”¾å…¥ä¸æ˜“å¯Ÿè§‰çš„ä½ç½®ã€‚",
            "single_arm_hiding": "æ£€æµ‹åˆ°å•è‡‚é®æŒ¡åŠ¨ä½œï¼Œåˆ©ç”¨èº«ä½“ä¸€ä¾§é®æ©å·çªƒè¡Œä¸ºã€‚",
            "body_shielding": "æ£€æµ‹åˆ°ç”¨èº¯å¹²å±è”½æ‰‹éƒ¨åŠ¨ä½œçš„å§¿æ€ï¼Œæ•…æ„é®æŒ¡æ‘„åƒå¤´è§†çº¿ã€‚",
            "hiding_hand_gesture": "æ£€æµ‹åˆ°æ‰‹éƒ¨ä½ç½®å¼‚å¸¸é®æŒ¡ï¼Œåˆ»æ„å°†æ‰‹éšè—åœ¨è§†çº¿æ­»è§’ã€‚",
            "abnormal_head_movement": "æ£€æµ‹åˆ°é¢‘ç¹çš„å¤´éƒ¨è½¬åŠ¨è¡Œä¸ºï¼Œåœ¨è¡Œçªƒè¿‡ç¨‹ä¸­æŸ¥çœ‹æ˜¯å¦æœ‰äººæ³¨æ„ã€‚"
        }
        
        return descriptions.get(behavior_type, "æ£€æµ‹åˆ°å¯ç–‘è¡Œä¸ºï¼Œå»ºè®®å…³æ³¨ã€‚")
    
    def create_annotated_frame(self, frame_data):
        """
        åˆ›å»ºå¸¦æœ‰æ ‡æ³¨çš„å¸§
        
        Args:
            frame_data: åŒ…å«å¸§ä¿¡æ¯çš„å­—å…¸ï¼ŒåŒ…æ‹¬frame, frame_index, time, behaviors, theft_probability
        
        Returns:
            annotated_frame: å¸¦æ ‡æ³¨çš„å¸§
        """
        if not frame_data:
            return None
            
        # è·å–å¸§æ•°æ®
        frame = frame_data.get('frame')
        if frame is None:
            return None
            
        frame_index = frame_data.get('frame_index', 0)
        time_str = frame_data.get('time', '')
        behaviors = frame_data.get('behaviors', [])
        theft_probability = frame_data.get('theft_probability', 0.0)
        
        # åˆ›å»ºå‰¯æœ¬ä»¥è¿›è¡Œç»˜åˆ¶
        annotated_frame = frame.copy()
        
        # æ·»åŠ é—ªçƒæ•ˆæœï¼ˆæ ¹æ®å¸§è®¡æ•°ï¼‰
        flash_effect = False
        if theft_probability > 0.5 and frame_index % 10 < 5:
            flash_effect = True
            
        # åˆå§‹åŒ–è¡Œä¸ºé¢œè‰²æ˜ å°„
        behavior_color_map = {
            "é®æŒ¡å•†å“åŒºåŸŸ": (0, 0, 255),    # çº¢è‰²
            "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸": (0, 0, 255),  # æ©™è‰²
            "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·": (0, 0, 255),  # é»„è‰²
            "åå¤è°ƒæ•´ä½ç½®": (0, 0, 255),    # ç»¿è‰²
            "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ": (255, 0, 255),  # å“çº¢è‰²
            "å¯ç–‘å•†å“å¤„ç†": (255, 255, 0),  # é’è‰²
            "å¿«é€Ÿè—åŒ¿ç‰©å“": (0, 0, 255)     # è“è‰²
        }
        
        # ä¸ºæ£€æµ‹åˆ°çš„äººå’Œç‰©ä½“ç”»æ¡†
        detections = frame_data.get('detections', [])
        for det in detections:
            if isinstance(det, dict) and 'bbox' in det:
                x1, y1, x2, y2 = map(int, det['bbox'])
                label = det.get('class', 'unknown')
                conf = det.get('confidence', 0.0)
                
                # æ ¹æ®ç±»åˆ«é€‰æ‹©é¢œè‰²
                color = (0, 255, 0)  # é»˜è®¤ç»¿è‰²
                if label == 'person':
                    color = (255, 0, 0)  # è“è‰²
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
                
                # æ·»åŠ æ ‡ç­¾
                text = f"{label}: {conf:.2f}"
                label_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
                cv2.rectangle(annotated_frame, (x1, y1 - 20), (x1 + label_size[0], y1), color, -1)
                cv2.putText(annotated_frame, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            
        # æ˜¾ç¤ºè¡Œä¸º
        for i, behavior in enumerate(behaviors):
            # ç¡®ä¿behavioræ˜¯å­—å…¸æ ¼å¼
            if not isinstance(behavior, dict):
                continue
                
            # è·å–è¡Œä¸ºä¿¡æ¯
            behavior_type = behavior.get('type', 'æœªçŸ¥è¡Œä¸º')
            confidence = behavior.get('confidence', 0.0)
            description = behavior.get('description', behavior_type)
            
            # è·å–è¡Œä¸ºé¢œè‰²
            color = behavior.get('color', behavior_color_map.get(behavior_type, (0, 255, 0)))
            
            # åœ¨é€‚å½“ä½ç½®æ·»åŠ è¡Œä¸ºæ ‡ç­¾
            y_pos = 40 + i * 30
            label_text = f"{behavior_type}: {confidence:.2f}"
            
            # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
            text_size = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
            overlay = annotated_frame.copy()
            cv2.rectangle(overlay, (10, y_pos - 25), (10 + text_size[0], y_pos + 5), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0, annotated_frame)
            
            # ç»˜åˆ¶æ–‡å­—
            cv2.putText(annotated_frame, label_text, (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            # å¦‚æœæœ‰è¾¹ç•Œæ¡†ï¼Œåˆ™ç»˜åˆ¶è¾¹ç•Œæ¡†
            if 'bbox' in behavior:
                x1, y1, x2, y2 = map(int, behavior['bbox'])
                # ç»˜åˆ¶çŸ©å½¢
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
                
                # åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹æ·»åŠ æ ‡ç­¾
                cv2.putText(annotated_frame, f"{behavior_type}", (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # æ·»åŠ æ—¶é—´ä¿¡æ¯
        h, w = annotated_frame.shape[:2]
        cv2.putText(annotated_frame, time_str, (10, h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # æ·»åŠ ç›—çªƒæ¦‚ç‡
        probability_text = f"ç›—çªƒæ¦‚ç‡: {theft_probability:.2%}"
        prob_color = (0, 0, 255) if theft_probability > 0.5 else (0, 255, 0)
        
        # åŠé€æ˜èƒŒæ™¯
        text_size = cv2.getTextSize(probability_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
        overlay = annotated_frame.copy()
        cv2.rectangle(overlay, (w-250-10, 5), (w-10, 35), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0, annotated_frame)
        
        cv2.putText(annotated_frame, probability_text, (w-250, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, prob_color, 2)
        
        # ç§»é™¤è­¦å‘Šæ ‡å¿—ä»£ç ï¼Œä¸å†æ·»åŠ çº¢è‰²è­¦å‘Šæ¡
        
        return annotated_frame
    
    def create_behavior_summary(self, behaviors, max_probability, theft_frames, total_frames):
        """åˆ›å»ºè¡Œä¸ºåˆ†ææ‘˜è¦"""
        try:
            # è®¾ç½®æ ‡å¿—è¡¨ç¤ºå·²ç»ç”Ÿæˆè¿‡æ‘˜è¦ï¼Œé˜²æ­¢é‡å¤ç”Ÿæˆ
            self.summary_generated = True
            
            # é¦–å…ˆè®°å½•æˆ‘ä»¬æ­£åœ¨åˆ›å»ºæ‘˜è¦
            self.log("æ­£åœ¨ç”Ÿæˆè¡Œä¸ºåˆ†ææ‘˜è¦...", console_only=True)
            
            # ä¸å†æ¸…ç†ä¹‹å‰çš„æ—¥å¿—ï¼Œè€Œæ˜¯æ·»åŠ åˆ†éš”ç¬¦
            self.log_text.insert(tk.END, "\n" + "="*50 + "\n", "separator")
            
            # æ·»åŠ æ ‡é¢˜
            self.log_text.insert(tk.END, "ğŸ“Š è¡Œä¸ºåˆ†ææ‘˜è¦\n", "title")
            self.log_text.insert(tk.END, "-" * 40 + "\n", "line")
            
            # ç»Ÿè®¡å„ç§è¡Œä¸ºå‡ºç°çš„æ¬¡æ•°
            behavior_counts = {}
            
            # è·å–æ‰€æœ‰è¡Œä¸ºé¡¹
            behavior_items = []
            for item in self.behavior_list.get_children():
                values = self.behavior_list.item(item, "values")
                frame = values[0]
                behavior_type = values[1]
                timestamp = values[2] if len(values) > 2 else "--"
                probability = float(values[3]) if len(values) > 3 and values[3] else 0.0
                
                behavior_items.append({
                    "frame": frame,
                    "behavior_type": behavior_type,
                    "timestamp": timestamp,
                    "probability": probability
                })
                
                # æ›´æ–°è¡Œä¸ºè®¡æ•°
                if behavior_type in behavior_counts:
                    behavior_counts[behavior_type] += 1
                else:
                    behavior_counts[behavior_type] = 1
            
            # é›¶å”®ç‰¹å®šè¡Œä¸º
            retail_behaviors = ["é®æŒ¡å•†å“åŒºåŸŸ", "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ", "å¯ç–‘å•†å“å¤„ç†", "å¿«é€Ÿè—åŒ¿ç‰©å“", "å°†ç‰©å“æ”¾å…¥å£è¢‹"]
            
            # å¯¹è¡Œä¸ºæŒ‰æ—¶é—´æ’åº
            sorted_behaviors = sorted(behavior_items, key=lambda x: x["timestamp"])
            
            # ç»Ÿè®¡é›¶å”®ç‰¹å®šè¡Œä¸ºå’Œéé›¶å”®è¡Œä¸º
            retail_behavior_count = sum(behavior_counts.get(b, 0) for b in retail_behaviors)
            non_retail_behavior_count = sum(behavior_counts.get(b, 0) for b in behavior_counts if b not in retail_behaviors)
            
            # æ ¹æ®æ¡†æ¶æ£€æµ‹æ—¥å¿—ä¸­çš„ä¿¡æ¯ç¡®å®šç¯å¢ƒç±»å‹
            # æ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦æœ‰æ˜¾ç¤ºé«˜åº¦å¯èƒ½æ˜¯é›¶å”®ç¯å¢ƒæˆ–å¯èƒ½æ˜¯é›¶å”®ç¯å¢ƒ
            is_retail_environment = False
            
            # ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„ç¯å¢ƒåˆ¤æ–­ç»“æœï¼Œå¦‚æœåœ¨è§†é¢‘å¤„ç†ä¸­å·²ç¡®å®šæ˜¯é›¶å”®ç¯å¢ƒ
            if hasattr(self, 'is_retail_environment') and self.is_retail_environment is not None:
                is_retail_environment = self.is_retail_environment
                self.log(f"ä½¿ç”¨å·²æœ‰çš„ç¯å¢ƒåˆ¤æ–­ç»“æœ: {'é›¶å”®ç¯å¢ƒ' if is_retail_environment else 'éé›¶å”®ç¯å¢ƒ'}")
            # å¦‚æœæ²¡æœ‰é¢„å…ˆåˆ¤æ–­ç»“æœï¼Œå°è¯•ä½¿ç”¨æ£€æµ‹å™¨åˆ¤æ–­
            elif hasattr(self, 'theft_detector'):
                # è·å–åœ¨æœ€åä¸€æ¬¡æ£€æµ‹ä¸­çš„ç¯å¢ƒåˆ¤æ–­
                if self.processed_frame is not None:
                    # å…ˆæ£€æŸ¥processed_frameæ˜¯å¦æ˜¯å›¾åƒæ•°æ®è€Œä¸æ˜¯UIç»„ä»¶
                    import numpy as np
                    if isinstance(self.processed_frame, np.ndarray):
                        # ç›´æ¥ä½¿ç”¨detectionæ¨¡å—çš„ç¯å¢ƒåˆ¤æ–­ç»“æœ
                        try:
                            # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼ï¼ŒUltralyticsè¦æ±‚RGBæ ¼å¼
                            if len(self.processed_frame.shape) == 3 and self.processed_frame.shape[2] == 3:
                                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä»BGRè½¬æ¢ä¸ºRGB (OpenCVé»˜è®¤æ˜¯BGR)
                                frame_for_prediction = cv2.cvtColor(self.processed_frame, cv2.COLOR_BGR2RGB)
                            else:
                                # å¦‚æœä¸æ˜¯3é€šé“å›¾åƒï¼Œè·³è¿‡ç¯å¢ƒåˆ¤æ–­
                                raise ValueError("å›¾åƒæ ¼å¼ä¸æ”¯æŒç¯å¢ƒåˆ¤æ–­ï¼Œéœ€è¦RGBæ ¼å¼")
                            
                            result = self.theft_detector.model.predict(frame_for_prediction, conf=0.25)[0]
                            is_retail_environment = self.theft_detector._is_retail_environment(result)
                            self.log(f"ä½¿ç”¨æ£€æµ‹å™¨ä¸­çš„ç¯å¢ƒåˆ¤æ–­ç»“æœ: {'é›¶å”®ç¯å¢ƒ' if is_retail_environment else 'éé›¶å”®ç¯å¢ƒ'}")
                        except Exception as e:
                            self.log(f"ä½¿ç”¨æ£€æµ‹å™¨åˆ¤æ–­ç¯å¢ƒå¤±è´¥: {str(e)}")
                            # å¤±è´¥æ—¶ä¸æ›´æ–°is_retail_environmentï¼Œå…è®¸ä¸‹ä¸€ä¸ªæ–¹æ³•å°è¯•
                    else:
                        self.log("processed_frameä¸æ˜¯æœ‰æ•ˆçš„å›¾åƒæ•°æ®ï¼Œè·³è¿‡ä½¿ç”¨æ£€æµ‹å™¨åˆ¤æ–­ç¯å¢ƒ")
            
            # å¦‚æœæ²¡æœ‰å¯ç”¨çš„æ£€æµ‹å™¨ç»“æœï¼Œä½¿ç”¨UIä¸­åŸºäºè¡Œä¸ºçš„åˆ¤æ–­é€»è¾‘
            if not hasattr(self, 'theft_detector') or self.processed_frame is None:
                # é»˜è®¤å‡è®¾ä¸ºé›¶å”®ç¯å¢ƒ
                
                # å¦‚æœæ²¡æœ‰ä»»ä½•è¡Œä¸ºæ•°æ®ï¼Œé»˜è®¤ç¯å¢ƒç±»å‹ä¸ºæœªçŸ¥
                if not behavior_counts:
                    is_retail_environment = False
                    self.log("æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•è¡Œä¸ºï¼Œé»˜è®¤ç¯å¢ƒç±»å‹ä¸ºï¼šéé›¶å”®")
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è¶³å¤Ÿå¤šçš„é›¶å”®ç‰¹å®šè¡Œä¸º
                elif retail_behavior_count > non_retail_behavior_count and retail_behavior_count >= 2:
                    is_retail_environment = True
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šé«˜åº¦ç›¸å…³çš„é›¶å”®è¡Œä¸º
                elif "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ" in behavior_counts or "å¯ç–‘å•†å“å¤„ç†" in behavior_counts:
                    is_retail_environment = True
                # å¦‚æœéé›¶å”®è¡Œä¸ºæ˜æ˜¾å¤šäºé›¶å”®è¡Œä¸ºï¼Œæˆ–è€…æ²¡æœ‰æ˜æ˜¾çš„é›¶å”®è¡Œä¸º
                else:
                    is_retail_environment = False
                
                self.log(f"ä½¿ç”¨è¡Œä¸ºåˆ†æåˆ¤æ–­ç¯å¢ƒä¸º: {'é›¶å”®ç¯å¢ƒ' if is_retail_environment else 'éé›¶å”®ç¯å¢ƒ'}")
            
            # ä¿å­˜ç¯å¢ƒç±»å‹åˆ¤æ–­ç»“æœï¼Œä¾›å…¶ä»–å‡½æ•°ä½¿ç”¨
            self.is_retail_environment = is_retail_environment
            
            # ç¯å¢ƒåˆ†æéƒ¨åˆ†
            self.log_text.insert(tk.END, "\nğŸ“Š ç¯å¢ƒåˆ†æ:\n", "subtitle")
            
            if is_retail_environment:
                self.log_text.insert(tk.END, "  âœ“ å½“å‰ç¯å¢ƒç¬¦åˆé›¶å”®æˆ–è¶…å¸‚åœºæ™¯\n", "environment_retail")
            else:
                self.log_text.insert(tk.END, "  âš ï¸ å½“å‰ç¯å¢ƒä¸ç¬¦åˆé›¶å”®æˆ–è¶…å¸‚åœºæ™¯\n", "environment_non_retail")
                self.log_text.insert(tk.END, "  å·²å°†é›¶å”®ç‰¹å®šè¡Œä¸ºæ›¿æ¢ä¸ºé€šç”¨è¡Œä¸ºç±»å‹\n", "environment_adjusted")
                
                # å¦‚æœæ˜¯éé›¶å”®ç¯å¢ƒä½†æ£€æµ‹åˆ°äº†é›¶å”®ç‰¹å®šè¡Œä¸ºï¼Œéœ€è¦åœ¨ç•Œé¢ä¸Šæ›´æ–°è¡Œä¸ºåˆ—è¡¨
                if retail_behavior_count > 0:
                    self.log("æ£€æµ‹åˆ°é›¶å”®ç‰¹å®šè¡Œä¸ºä½†ç¯å¢ƒä¸ç¬¦åˆé›¶å”®åœºæ™¯ï¼Œå°†æ›´æ–°è¡Œä¸ºåˆ—è¡¨")
                    
                    # æ£€æŸ¥å½“å‰UIä¸­æ˜¯å¦è¿˜æœ‰é›¶å”®ç‰¹å®šè¡Œä¸º
                    has_retail_behaviors_in_ui = False
                    for item in self.behavior_list.get_children():
                        values = self.behavior_list.item(item, "values")
                        behavior_text = values[1] if len(values) > 1 else ""
                        if any(r in behavior_text for r in retail_behaviors):
                            has_retail_behaviors_in_ui = True
                            break
                    
                    # å¦‚æœUIä¸­ä»æœ‰é›¶å”®è¡Œä¸ºï¼Œéœ€è¦é‡æ–°æ„å»ºè¡Œä¸ºåˆ—è¡¨
                    if has_retail_behaviors_in_ui:
                        self.log("UIä¸­å­˜åœ¨é›¶å”®ç‰¹å®šè¡Œä¸ºï¼Œå°†åº”ç”¨ç¯å¢ƒç±»å‹é‡æ–°æ›´æ–°è¡Œä¸ºåˆ—è¡¨")
                        # åœ¨æ‘˜è¦ç”Ÿæˆåè°ƒç”¨update_ui_with_behaviorsä¼šæ ¹æ®å·²ç¡®å®šçš„ç¯å¢ƒç±»å‹æ›¿æ¢è¡Œä¸º
                        # ç¡®ä¿åœ¨è°ƒç”¨å‰ç¦ç”¨æ‰€æœ‰æŒ‰é’®
                        def update_behaviors_with_disabled_buttons():
                            # å¼ºåˆ¶è®¾ç½®æŒ‰é’®ç¦ç”¨æ ‡å¿—
                            if not hasattr(self, '_force_disable_buttons'):
                                self._force_disable_buttons = False
                                
                            # å…ˆç¦ç”¨æ‰€æœ‰æŒ‰é’®
                            self.process_btn.state(['disabled'])
                            self.select_image_btn.state(['disabled'])
                            self.select_video_btn.state(['disabled'])
                            # ç„¶åæ›´æ–°è¡Œä¸ºåˆ—è¡¨
                            self.update_ui_with_behaviors()
                            
                            # ç¡®ä¿åœ¨å¤„ç†å®ŒæˆåæŒ‰é’®é‡æ–°å¯ç”¨ - æ£€æŸ¥å¤„ç†çŠ¶æ€è€Œä¸æ˜¯ç»§æ‰¿ä¹‹å‰çš„çŠ¶æ€
                            if not self.is_processing:
                                self.log("ç¡®ä¿è¡Œä¸ºåˆ—è¡¨ä¸ç¯å¢ƒç±»å‹ä¸€è‡´åé‡æ–°å¯ç”¨æŒ‰é’®")
                                self.process_btn.state(['!disabled'])
                                self.select_image_btn.state(['!disabled'])
                                self.select_video_btn.state(['!disabled'])
                                # å¦‚æœæœ‰å¤„ç†ç»“æœï¼Œå¯ç”¨ä¿å­˜æŒ‰é’®
                                if hasattr(self, 'processed_media_path') and self.processed_media_path:
                                    self.save_btn.state(['!disabled'])
                            else:
                                # å¦‚æœä»åœ¨å¤„ç†ä¸­ï¼Œç¡®ä¿æŒ‰é’®ä¿æŒç¦ç”¨
                                self.process_btn.state(['disabled'])
                                self.select_image_btn.state(['disabled'])
                                self.select_video_btn.state(['disabled'])
                        self.root.after(100, update_behaviors_with_disabled_buttons)
            
            # ä¸ºæ¯ç§è¡Œä¸ºç±»å‹ä½¿ç”¨å›¾æ ‡å‰ç¼€
            behavior_type_map = {
                "Covering Product Area": "é®æŒ¡å•†å“åŒºåŸŸ", 
                "Unusual Elbow Position": "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸",
                "Unnatural Shoulder Raise": "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·",
                "Repetitive Position Adjustment": "åå¤è°ƒæ•´ä½ç½®",
                "Suspected Tag Removal": "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ",
                "Suspicious Item Handling": "å¯ç–‘å•†å“å¤„ç†",
                "Rapid Item Concealment": "å¿«é€Ÿè—åŒ¿ç‰©å“"
            }
            
            # ä¸ºæ¯ç§è¡Œä¸ºç±»å‹ä½¿ç”¨å›¾æ ‡å‰ç¼€
            icon_map = {
                "é®æŒ¡å•†å“åŒºåŸŸ": "ğŸ§¥ ",
                "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸": "ğŸ’ª ",
                "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·": "ğŸ‘• ",
                "åå¤è°ƒæ•´ä½ç½®": "ğŸ”„ ",
                "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ": "ğŸ·ï¸ ",
                "å¯ç–‘å•†å“å¤„ç†": "ğŸ›’ ",
                "å¿«é€Ÿè—åŒ¿ç‰©å“": "ğŸ‘ "
            }
            
            # è¡Œä¸ºåˆ†æéƒ¨åˆ†
            self.log_text.insert(tk.END, "\nğŸ‘ï¸ è¡Œä¸ºåˆ†æ:\n", "subtitle")
            
            # åˆ¤æ–­æ˜¯å¦æ£€æµ‹åˆ°ç›—çªƒè¡Œä¸º
            if theft_frames > 0:
                theft_percentage = (theft_frames / total_frames) * 100 if total_frames > 0 else 0
                
                if theft_percentage > 30 and max_probability > 0.6:
                    # é«˜åº¦å¯ç–‘
                    self.log_text.insert(tk.END, "  âš ï¸ é«˜åº¦å¯ç–‘: å¤šæ¬¡æ£€æµ‹åˆ°ç›—çªƒè¡Œä¸ºç‰¹å¾\n", "high_warning")
                    self.log_text.insert(tk.END, f"  å¯ç–‘å¸§å æ¯”: {theft_percentage:.2f}%\n", "warning")
                    self.log_text.insert(tk.END, f"  å‘ç”Ÿç›—çªƒæ¦‚ç‡: {max_probability:.2%}\n", "warning")
                elif theft_percentage > 10 or max_probability > 0.5:
                    # ä¸­åº¦å¯ç–‘
                    self.log_text.insert(tk.END, "  âš ï¸ ä¸­åº¦å¯ç–‘: æ£€æµ‹åˆ°éƒ¨åˆ†ç›—çªƒè¡Œä¸ºç‰¹å¾\n", "medium_warning")
                    self.log_text.insert(tk.END, f"  å¯ç–‘å¸§å æ¯”: {theft_percentage:.2f}%\n", "warning")
                    self.log_text.insert(tk.END, f"  å‘ç”Ÿç›—çªƒæ¦‚ç‡: {max_probability:.2%}\n", "warning")
                else:
                    # è½»åº¦å¯ç–‘
                    self.log_text.insert(tk.END, "  âš ï¸ è½»åº¦å¯ç–‘: æ£€æµ‹åˆ°å°‘é‡å¯ç–‘è¡Œä¸º\n", "low_warning") 
                    self.log_text.insert(tk.END, f"  å¯ç–‘å¸§å æ¯”: {theft_percentage:.2f}%\n", "warning")
                    self.log_text.insert(tk.END, f"  å‘ç”Ÿç›—çªƒæ¦‚ç‡: {max_probability:.2%}\n", "warning")
            else:
                self.log_text.insert(tk.END, "  âœ“ æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„ç›—çªƒè¡Œä¸º\n", "normal")
                if not behavior_counts:
                    self.log_text.insert(tk.END, "  âœ“ åˆ†æè¿‡ç¨‹ä¸­æœªå‘ç°ä»»ä½•å¯ç–‘è¡Œä¸º\n", "normal")
            
            # æ˜¾ç¤ºè¡Œä¸ºè¯¦ç»†ç»Ÿè®¡
            self.log_text.insert(tk.END, "\nğŸ“‹ æ£€æµ‹åˆ°çš„è¡Œä¸ºç»Ÿè®¡:\n", "subtitle")
            
            if not behavior_counts:
                self.log_text.insert(tk.END, "  æ— æ£€æµ‹åˆ°çš„è¡Œä¸º\n", "normal")
            else:
                # å¯¹è¡Œä¸ºæŒ‰å‡ºç°æ¬¡æ•°æ’åº
                sorted_behaviors = sorted(behavior_counts.items(), key=lambda x: x[1], reverse=True)
                
                for behavior_type, count in sorted_behaviors:
                    # è½¬æ¢ä¸ºä¸­æ–‡æ˜¾ç¤º
                    chinese_behavior_type = behavior_type_map.get(behavior_type, behavior_type)
                    
                    # æ·»åŠ å›¾æ ‡å‰ç¼€
                    icon_prefix = icon_map.get(chinese_behavior_type, "âš ï¸ ")
                    display_type = icon_prefix + chinese_behavior_type
                    
                    # æ·»åŠ è¡Œä¸ºæè¿°
                    behavior_description = self.get_behavior_description(chinese_behavior_type)
                    description_short = behavior_description[:50] + "..." if len(behavior_description) > 50 else behavior_description
                    
                    # å¦‚æœæ˜¯éé›¶å”®ç¯å¢ƒä¸­çš„é›¶å”®è¡Œä¸ºè¢«æ›¿æ¢ï¼Œæ·»åŠ è¯´æ˜
                    if not is_retail_environment and behavior_type in ["åå¤è°ƒæ•´ä½ç½®", "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸"]:
                        self.log_text.insert(tk.END, f"  {display_type}: {count}æ¬¡\n", "behavior_item")
                        self.log_text.insert(tk.END, f"    {description_short}\n", "behavior_desc")
                        if behavior_type == "åå¤è°ƒæ•´ä½ç½®" and "é®æŒ¡å•†å“åŒºåŸŸ" in behavior_counts or "å¯ç–‘å•†å“å¤„ç†" in behavior_counts:
                            self.log_text.insert(tk.END, f"    (åŒ…å«æ›¿æ¢çš„é›¶å”®ç¯å¢ƒè¡Œä¸º)\n", "behavior_replaced")
                        elif behavior_type == "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸" and "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ" in behavior_counts or "å¿«é€Ÿè—åŒ¿ç‰©å“" in behavior_counts:
                            self.log_text.insert(tk.END, f"    (åŒ…å«æ›¿æ¢çš„é›¶å”®ç¯å¢ƒè¡Œä¸º)\n", "behavior_replaced")
                    else:
                        self.log_text.insert(tk.END, f"  {display_type}: {count}æ¬¡\n", "behavior_item")
                        self.log_text.insert(tk.END, f"    {description_short}\n", "behavior_desc")
            
            # æ€»ä½“ç»“è®º
            self.log_text.insert(tk.END, "\nğŸ” ç»“è®º:\n", "subtitle")
            if theft_frames > 0 and is_retail_environment:
                if theft_percentage > 30 and max_probability > 0.6:
                    self.log_text.insert(tk.END, "  æ£€æµ‹åˆ°é«˜åº¦å¯ç–‘çš„ç›—çªƒè¡Œä¸ºï¼Œå»ºè®®è¿›ä¸€æ­¥æ ¸å®\n", "conclusion_high")
                elif theft_percentage > 10 or max_probability > 0.5:
                    self.log_text.insert(tk.END, "  æ£€æµ‹åˆ°å¯èƒ½çš„ç›—çªƒè¡Œä¸ºï¼Œå»ºè®®å…³æ³¨\n", "conclusion_medium")
                else:
                    self.log_text.insert(tk.END, "  æ£€æµ‹åˆ°è½»å¾®å¯ç–‘è¡Œä¸ºï¼Œå¯èƒ½éœ€è¦å…³æ³¨\n", "conclusion_low")
            elif theft_frames > 0 and not is_retail_environment:
                self.log_text.insert(tk.END, "  ç¯å¢ƒä¸ç¬¦åˆé›¶å”®åœºæ™¯ï¼Œæ£€æµ‹åˆ°çš„å¯èƒ½æ˜¯é€šç”¨å¯ç–‘è¡Œä¸º\n", "conclusion_medium")
                if max_probability > 0.5:
                    self.log_text.insert(tk.END, "  å»ºè®®å…³æ³¨å¼‚å¸¸ä¸¾æ­¢ï¼Œä½†ä¸é€‚ç”¨é›¶å”®ç›—çªƒåˆ†æ\n", "conclusion_low")
            elif not theft_frames and is_retail_environment:
                self.log_text.insert(tk.END, "  é›¶å”®ç¯å¢ƒä¸­æœªæ£€æµ‹åˆ°ç›—çªƒè¡Œä¸º\n", "conclusion_none")
            else:
                if not behavior_counts:
                    self.log_text.insert(tk.END, "  æœªæ£€æµ‹åˆ°ä»»ä½•è¡Œä¸ºï¼Œåˆ†æç»“æŸ\n", "conclusion_none")
                else:
                    self.log_text.insert(tk.END, "  éé›¶å”®ç¯å¢ƒï¼Œæœªæ£€æµ‹åˆ°ç›¸å…³å¯ç–‘è¡Œä¸º\n", "conclusion_none")
            
            # æ·»åŠ æ—¶é—´æˆ³
            self.log_text.insert(tk.END, "---------------------------------\n", "line")
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            self.log_text.insert(tk.END, f"åˆ†æå®Œæˆæ—¶é—´: {timestamp}\n\n", "timestamp")
            
            # é…ç½®æ ‡ç­¾æ ·å¼
            self.log_text.tag_configure("title", font=("Arial", 10, "bold"), foreground="blue")
            self.log_text.tag_configure("subtitle", font=("Arial", 9, "bold"), foreground="black")
            self.log_text.tag_configure("normal", font=("Arial", 9), foreground="black")
            self.log_text.tag_configure("warning", font=("Arial", 9), foreground="red")
            self.log_text.tag_configure("high_warning", font=("Arial", 9, "bold"), foreground="red")
            self.log_text.tag_configure("medium_warning", font=("Arial", 9), foreground="orange")
            self.log_text.tag_configure("low_warning", font=("Arial", 9), foreground="orange")
            self.log_text.tag_configure("behavior_item", font=("Arial", 9), foreground="blue")
            self.log_text.tag_configure("behavior_desc", font=("Arial", 8), foreground="gray")
            self.log_text.tag_configure("behavior_replaced", font=("Arial", 8, "italic"), foreground="#8B0000")
            self.log_text.tag_configure("line", font=("Arial", 9), foreground="gray")
            self.log_text.tag_configure("timestamp", font=("Arial", 8), foreground="gray")
            self.log_text.tag_configure("environment_retail", font=("Arial", 9), foreground="green")
            self.log_text.tag_configure("environment_non_retail", font=("Arial", 9), foreground="orange")
            self.log_text.tag_configure("environment_adjusted", font=("Arial", 9, "italic"), foreground="gray")
            self.log_text.tag_configure("conclusion_high", font=("Arial", 9, "bold"), foreground="red")
            self.log_text.tag_configure("conclusion_medium", font=("Arial", 9), foreground="orange")
            self.log_text.tag_configure("conclusion_low", font=("Arial", 9), foreground="blue")
            self.log_text.tag_configure("conclusion_none", font=("Arial", 9), foreground="green")
            
            # æ€»æ˜¯æ»šåŠ¨åˆ°åº•éƒ¨æ˜¾ç¤ºæœ€æ–°å†…å®¹
            self.log_text.see(tk.END)
            
            # å¦‚æœæ­£åœ¨å¤„ç†ä¸­ï¼Œç¡®ä¿æŒ‰é’®ä¿æŒç¦ç”¨
            if self.is_processing:
                self.process_btn.state(['disabled'])
                self.select_image_btn.state(['disabled'])
                self.select_video_btn.state(['disabled'])
            else:
                # å¤„ç†å®Œæˆåå¯ç”¨æŒ‰é’®
                self._force_disable_buttons = False
                self.process_btn.state(['!disabled'])
                self.select_image_btn.state(['!disabled'])
                self.select_video_btn.state(['!disabled'])
                
                # å¦‚æœæœ‰å¤„ç†ç»“æœï¼Œå¯ç”¨ä¿å­˜æŒ‰é’®
                if hasattr(self, 'processed_media_path') and self.processed_media_path and os.path.exists(self.processed_media_path):
                    self.save_btn.state(['!disabled'])
            
            # åœ¨å‡½æ•°ç»“æŸå‰ï¼Œç¡®ä¿UIè¡Œä¸ºåˆ—è¡¨ä¸ç¯å¢ƒç±»å‹ä¸€è‡´
            self.log("ç¡®ä¿è¡Œä¸ºåˆ—è¡¨ä¸ç¯å¢ƒç±»å‹ä¸€è‡´")
            
            # å¦‚æœä¸æ˜¯é›¶å”®ç¯å¢ƒï¼Œå¼ºåˆ¶åˆ·æ–°è¡Œä¸ºåˆ—è¡¨
            if not is_retail_environment:
                # ä¿å­˜åŸæœ‰åˆ—è¡¨å†…å®¹
                existing_behaviors = []
                for item in self.behavior_list.get_children():
                    values = self.behavior_list.item(item, "values")
                    time_str = values[0]
                    behavior_text = values[1]
                    probability_text = values[2]
                    
                    # æå–è¡Œä¸ºç±»å‹ï¼ˆå»é™¤å›¾æ ‡ï¼‰
                    behavior_type = behavior_text[2:] if len(behavior_text) > 2 else behavior_text
                    
                    # æ£€æŸ¥è¡Œä¸ºæ˜¯å¦éœ€è¦æ›¿æ¢
                    if any(r in behavior_type for r in retail_behaviors):
                        self.log(f"å‘ç°éœ€è¦æ›¿æ¢çš„é›¶å”®è¡Œä¸º: {behavior_type}")
                        # éœ€è¦åœ¨rebuild_behavior_listä¸­å¤„ç†
                        existing_behaviors.append((time_str, behavior_type, probability_text))
                    else:
                        existing_behaviors.append((time_str, behavior_type, probability_text))
                
                # å¦‚æœæœ‰è¡Œä¸ºéœ€è¦é‡å»º
                if existing_behaviors:
                    # ä½¿ç”¨å»¶è¿Ÿæ‰§è¡Œç¡®ä¿UIæ›´æ–°ä¸å†²çª
                    self.root.after(200, lambda: self.rebuild_behavior_list(existing_behaviors))
            
        except Exception as e:
            self.log(f"åˆ›å»ºè¡Œä¸ºæ‘˜è¦é”™è¯¯: {str(e)}")
            import traceback
            self.log(traceback.format_exc())
            
            # å¦‚æœæ­£åœ¨å¤„ç†ä¸­ï¼Œç¡®ä¿æŒ‰é’®ä¿æŒç¦ç”¨
            if self.is_processing:
                self.process_btn.state(['disabled'])
                self.select_image_btn.state(['disabled'])
                self.select_video_btn.state(['disabled'])
            else:
                # å¤„ç†å®Œæˆåå¯ç”¨æŒ‰é’®
                self._force_disable_buttons = False
                self.process_btn.state(['!disabled'])
                self.select_image_btn.state(['!disabled'])
                self.select_video_btn.state(['!disabled'])
    
    def add_behavior_to_list(self, frame, time_point, behavior_type, probability):
        """å°†è¡Œä¸ºæ·»åŠ åˆ°è¡Œä¸ºåˆ—è¡¨ä¸­"""
        try:
            # è½¬æ¢è¡Œä¸ºç±»å‹ï¼ˆè‹±æ–‡->ä¸­æ–‡ï¼‰
            behavior_type_map = {
                "Product Area Shielding": "é®æŒ¡å•†å“åŒºåŸŸ",
                "Abnormal Elbow Posture": "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸",
                "Unnatural Shoulder Raise": "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·",
                "Repetitive Position Adjustment": "åå¤è°ƒæ•´ä½ç½®",
                "Suspected Tag Removal": "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ",
                "Suspicious Item Handling": "å¯ç–‘å•†å“å¤„ç†",
                "Rapid Item Concealment": "å¿«é€Ÿè—åŒ¿ç‰©å“",
                "Item Concealed in Pocket": "å°†ç‰©å“æ”¾å…¥å£è¢‹"
            }
            
            # è½¬æ¢ä¸ºä¸­æ–‡æ˜¾ç¤º
            chinese_behavior_type = behavior_type_map.get(behavior_type, behavior_type)
            
            # ä¸ºæ¯ç§è¡Œä¸ºç±»å‹ä½¿ç”¨å›¾æ ‡å‰ç¼€
            icon_map = {
                "é®æŒ¡å•†å“åŒºåŸŸ": "ğŸ§¥ ",
                "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸": "ğŸ’ª ",
                "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·": "ğŸ‘• ",
                "åå¤è°ƒæ•´ä½ç½®": "ğŸ”„ ",
                "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ": "ğŸ·ï¸ ",
                "å¯ç–‘å•†å“å¤„ç†": "ğŸ›’ ",
                "å¿«é€Ÿè—åŒ¿ç‰©å“": "ğŸ‘ ",
                "å°†ç‰©å“æ”¾å…¥å£è¢‹": "ğŸ‘– "
            }
            
            # åœ¨è¡Œä¸ºç±»å‹å‰æ·»åŠ å›¾æ ‡
            icon_prefix = icon_map.get(chinese_behavior_type, "âš ï¸ ")
            display_type = icon_prefix + chinese_behavior_type
            
            # åˆå§‹åŒ–è¡Œä¸ºIDè®¡æ•°å™¨å’Œè¡Œä¸ºæ•°æ®åˆ—è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if not hasattr(self, 'next_behavior_id'):
                self.next_behavior_id = 1
            if not hasattr(self, 'behavior_data'):
                self.behavior_data = []
                
            # æ›´æ–°è¡Œä¸ºåˆ—è¡¨
            item_id = self.next_behavior_id
            self.next_behavior_id += 1
            
            # æ·»åŠ åˆ°Treeviewåˆ—è¡¨
            probability_formatted = f"{probability:.2%}"
            time_formatted = f"{time_point:.2f}ç§’" if time_point is not None else "N/A"
            
            # ä½¿ç”¨æ­£ç¡®çš„ttk.Treeviewæ’å…¥æ–¹æ³•ï¼Œè®¾ç½®å€¼ä¸ºæ—¶é—´ã€ç±»å‹å’Œæ¦‚ç‡
            tree_item_id = self.behavior_list.insert("", "end", values=(time_formatted, display_type, probability_formatted))
            
            # æ ¹æ®æ¦‚ç‡è®¾ç½®ä¸åŒçš„èƒŒæ™¯è‰²æ ‡ç­¾
            if probability > 0.8:
                self.behavior_list.item(tree_item_id, tags=("high",))
            elif probability > 0.6:
                self.behavior_list.item(tree_item_id, tags=("medium",))
            else:
                self.behavior_list.item(tree_item_id, tags=("low",))
                
            # é…ç½®æ ‡ç­¾æ ·å¼
            self.behavior_list.tag_configure("high", background="#ffcccc")
            self.behavior_list.tag_configure("medium", background="#ffffcc")
            self.behavior_list.tag_configure("low", background="#e6f7ff")
            
            # ç¡®ä¿æ»šåŠ¨åˆ°æœ€æ–°é¡¹
            self.behavior_list.yview_moveto(1.0)
            
            # ä¿å­˜è¡Œä¸ºæ•°æ®ä»¥ä¾›åç»­ä½¿ç”¨
            behavior_data = {
                'id': item_id,
                'frame': frame,
                'time': time_point,
                'type': chinese_behavior_type,
                'probability': probability,
                'tree_id': tree_item_id  # ä¿å­˜æ ‘å½¢æ§ä»¶ä¸­çš„é¡¹ç›®ID
            }
            self.behavior_data.append(behavior_data)
            
            # è®°å½•æ—¥å¿— - ä½¿ç”¨æ¼‚äº®çš„æ ¼å¼åŒ–æ¶ˆæ¯
            log_message = f"æ·»åŠ è¡Œä¸ºåˆ°åˆ—è¡¨: å¸§={frame}, æ—¶é—´={time_point:.2f}ç§’, ç±»å‹={chinese_behavior_type}, å¯ä¿¡åº¦={probability:.4f}"
            self.log(log_message)
            
            # è·å–è¡Œä¸ºæè¿°æ–‡æœ¬
            behavior_descriptions = {
                "é®æŒ¡å•†å“åŒºåŸŸ": "ç–‘ä¼¼ä»¥èº«ä½“é®æŒ¡å•†å“åŒºåŸŸï¼Œå¯èƒ½æ˜¯ä¸ºäº†éšè—å–ç‰©è¡Œä¸º",
                "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸": "æ‰‹è‚˜å¼‚å¸¸å†…æ”¶å§¿æ€ï¼Œå¯èƒ½åœ¨éšè—ç‰©å“",
                "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·": "è‚©éƒ¨å§¿æ€å¼‚å¸¸ï¼Œæ˜¾ç¤ºä¸è‡ªç„¶éš†èµ·ï¼Œå¯èƒ½è—åŒ¿ç‰©å“äºè¡£ç‰©å†…",
                "åå¤è°ƒæ•´ä½ç½®": "åœ¨åŒä¸€åŒºåŸŸåå¤è°ƒæ•´èº«ä½“ä½ç½®ï¼Œè¡Œä¸ºå¯ç–‘",
                "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ": "æ‰‹éƒ¨åœ¨å•†å“åŒºåŸŸæœ‰æ’•æ‰¯åŠ¨ä½œï¼Œå¯èƒ½åœ¨ç§»é™¤é˜²ç›—æ ‡ç­¾",
                "å¯ç–‘å•†å“å¤„ç†": "å¯¹å•†å“è¿›è¡Œå¯ç–‘æ“ä½œï¼Œå¯èƒ½å‡†å¤‡è—åŒ¿",
                "å¿«é€Ÿè—åŒ¿ç‰©å“": "å¿«é€Ÿå°†ç‰©å“è—å…¥è¡£ç‰©æˆ–åŒ…å†…",
                "å°†ç‰©å“æ”¾å…¥å£è¢‹": "å°†å•†å“æˆ–ç‰©å“æ”¾å…¥å£è¢‹æˆ–è¡£ç‰©å†…éƒ¨ï¼Œå…¸å‹çš„ç›—çªƒåŠ¨ä½œ"
            }
            
            # è·å–è¡Œä¸ºæè¿°
            behavior_description = behavior_descriptions.get(chinese_behavior_type, "å¯ç–‘è¡Œä¸ºï¼Œéœ€è¦å…³æ³¨")
            
            # å†æ·»åŠ ä¸€æ¡è¯¦ç»†çš„è­¦å‘Šæ—¥å¿—ï¼ˆä»…å½“æ¦‚ç‡è¾ƒé«˜æ—¶ï¼‰
            if probability > 0.6:
                detailed_message = f"æ£€æµ‹åˆ°è¡Œä¸º: {display_type} (å¯ä¿¡åº¦: {probability_formatted})\nè¡Œä¸ºæè¿°: {behavior_description}"
                self.log(detailed_message)
            
            return item_id
        except Exception as e:
            self.log(f"æ·»åŠ è¡Œä¸ºåˆ°åˆ—è¡¨é”™è¯¯: {str(e)}", console_only=True)
            import traceback
            self.log(traceback.format_exc(), console_only=True)
            return None
    
    def update_ui_with_behaviors(self, auto_create_summary=True):
        """åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°è¡Œä¸ºåˆ—è¡¨UI"""
        try:
            # è®°å½•åŸå§‹æŒ‰é’®ç¦ç”¨çŠ¶æ€
            original_disable_state = getattr(self, '_force_disable_buttons', False)
            # ç¡®ä¿åœ¨å‡½æ•°æ‰§è¡ŒæœŸé—´æŒ‰é’®ä¿æŒç¦ç”¨
            self._force_disable_buttons = True
            
            # ç¡®ä¿åœ¨åˆ†æè¿‡ç¨‹ä¸­æŒ‰é’®ä¿æŒç¦ç”¨çŠ¶æ€
            if self.is_processing:
                self.process_btn.state(['disabled'])
                self.select_image_btn.state(['disabled'])
                self.select_video_btn.state(['disabled'])
            
            # ç¡®ä¿è¡Œä¸ºåˆ—è¡¨å¯è§
            self.behavior_list_frame.update()
            
            # æ¸…ç©ºè¡Œä¸ºåˆ—è¡¨UIå‡†å¤‡æ·»åŠ æ–°è¡Œä¸º
            for item in self.behavior_list.get_children():
                self.behavior_list.delete(item)
            
            # å¼ºåˆ¶ç»˜åˆ¶æ›´æ–°
            self.behavior_list.update()
            
            # æ£€æŸ¥è¡Œä¸ºæ•°æ®
            if not hasattr(self, 'behaviors_data') or not self.behaviors_data:
                self.log("è­¦å‘Š: æ²¡æœ‰æ£€æµ‹åˆ°å¯ç–‘è¡Œä¸ºæ•°æ®")
                self.behavior_list.insert("", "end", values=("N/A", "æœªæ£€æµ‹åˆ°å¯ç–‘è¡Œä¸º", "0.00%"))
                return
                
            behaviors = self.behaviors_data
            
            # ç¡®ä¿å¯ç–‘å¸§åˆ—è¡¨å­˜åœ¨
            if not hasattr(self, 'suspicious_frames'):
                self.suspicious_frames = []
                
            suspicious_frames = self.suspicious_frames
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡åˆ†æ
            is_image_analysis = len(behaviors) == 1 and behaviors[0][0] == 0
            
            # è·å–FPSå’Œæ€»å¸§æ•°ï¼Œå¤„ç†å›¾ç‰‡å’Œè§†é¢‘çš„ä¸åŒæƒ…å†µ
            if is_image_analysis:
                fps = 1
                total_frames = 1
            else:
                # è§†é¢‘åˆ†æï¼Œè·å–è§†é¢‘ä¿¡æ¯
                cap = cv2.VideoCapture(self.current_media_path)
                fps = cap.get(cv2.CAP_PROP_FPS) if cap.isOpened() else 30
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.isOpened() else 1
                cap.release()
            
            # æå–åˆ†æç»“æœæ•°æ®
            behavior_types = set()
            max_probability = 0.0
            
            # ä¿®æ”¹æ¡ä»¶ï¼šå¦‚æœæ²¡æœ‰ç¯å¢ƒç±»å‹åˆ¤æ–­ä¸”æ‘˜è¦æœªç”Ÿæˆï¼Œæ‰åˆ›å»ºæ‘˜è¦
            # è¿™æ ·å¯ä»¥é˜²æ­¢åœ¨é¦–æ¬¡åˆ†ææ—¶é‡å¤ç”Ÿæˆæ‘˜è¦
            if auto_create_summary and not hasattr(self, 'is_retail_environment') and (not hasattr(self, 'summary_generated') or not self.summary_generated):
                self.log("è¿˜æœªç”Ÿæˆè¡Œä¸ºæ‘˜è¦ï¼Œå°†å…ˆåˆ›å»ºæ‘˜è¦ç¡®å®šç¯å¢ƒç±»å‹")
                # å…ˆè®¡ç®—æœ€å¤§æ¦‚ç‡
                for _, frame_behaviors in behaviors:
                    for behavior in frame_behaviors:
                        confidence = behavior.get('confidence', 0.0)
                        max_probability = max(max_probability, confidence)
                        
                self.create_behavior_summary(behaviors, max_probability, len(suspicious_frames), total_frames)
            
            # å¤„ç†æ£€æµ‹åˆ°çš„è¡Œä¸º
            behavior_count = 0
            for frame_idx, frame_behaviors in behaviors:
                for behavior in frame_behaviors:
                    behavior_count += 1
                    behavior_type = behavior.get('type', 'æœªçŸ¥è¡Œä¸º')
                    behavior_types.add(behavior_type)
                    confidence = behavior.get('confidence', 0.0)
                    max_probability = max(max_probability, confidence)
                    
                    # æ·»åŠ åˆ°è¡Œä¸ºåˆ—è¡¨UI - è¿™é‡Œä¼šåº”ç”¨ç¯å¢ƒç±»å‹åˆ¤æ–­è¿›è¡Œæ›¿æ¢
                    time_point = frame_idx / fps if fps > 0 else 0
                    self.add_behavior_to_list(frame_idx, time_point, behavior_type, confidence)
            
            self.log(f"å·²æ·»åŠ  {behavior_count} æ¡è¡Œä¸ºè®°å½•åˆ°ç•Œé¢")
            
            # æ€»æ˜¯æ»šåŠ¨åˆ°åº•éƒ¨æ˜¾ç¤ºæœ€æ–°å†…å®¹
            self.behavior_list.yview_moveto(1.0)
            
            # è®¡ç®—ç›—çªƒå¸§æ•° - æ— è®ºæ˜¯å¦è‡ªåŠ¨åˆ›å»ºæ‘˜è¦éƒ½éœ€è¦è¿™ä¸ªå€¼
            theft_frames = len(suspicious_frames)
            if is_image_analysis and theft_frames == 0 and behavior_count > 0:
                # å¦‚æœæ˜¯å›¾ç‰‡åˆ†æä¸”æœ‰è¡Œä¸ºä½†æ²¡æœ‰å¯ç–‘å¸§ï¼Œå°†å¯ç–‘å¸§è®¡ä¸º1
                theft_frames = 1
            
            # ä¿®æ”¹æ¡ä»¶ï¼šåªæœ‰åœ¨è‡ªåŠ¨åˆ›å»ºæ‘˜è¦æ¨¡å¼ä¸‹ä¸”æ‘˜è¦æœªç”Ÿæˆï¼Œå¹¶ä¸”å‰é¢æ²¡æœ‰åˆ›å»ºè¿‡æ‘˜è¦æ—¶ï¼Œæ‰åœ¨æ­¤å¤„åˆ›å»ºæ‘˜è¦
            if auto_create_summary and (not hasattr(self, 'summary_generated') or not self.summary_generated) and hasattr(self, 'is_retail_environment'):
                # åˆ›å»ºè¡Œä¸ºæ‘˜è¦
                self.create_behavior_summary(behaviors, max_probability, theft_frames, total_frames)
            
            # æ›´æ–°åˆ†æç»“æœæ—¥å¿—
            theft_detected = "æ˜¯" if theft_frames > 0 else "å¦"
            
            if is_image_analysis:
                summary_message = f"å›¾ç‰‡åˆ†æå®Œæˆ: æ¢æµ‹ç›—çªƒè¡Œä¸ºï¼š{theft_detected}"
                summary_message += f"\næœ€é«˜è¡Œä¸ºå¯ç–‘åº¦: {max_probability:.2f}"
                summary_message += f"\næ£€æµ‹åˆ° {behavior_count} å¤„å¯ç–‘è¡Œä¸º"
            else:
                summary_message = f"è§†é¢‘åˆ†æå®Œæˆ: æ¢æµ‹ç›—çªƒè¡Œä¸ºï¼š{theft_detected}"
                summary_message += f"\næœ€é«˜ç›—çªƒæ¦‚ç‡: {max_probability:.2f}"
                summary_message += f"\nåŒ…å«ç›—çªƒè¡Œä¸ºçš„å¸§æ•°: {theft_frames}"
                summary_message += f"\næ£€æµ‹åˆ° {behavior_count} å¤„å¯ç–‘è¡Œä¸º"
                
            self.log(summary_message)
            
            # æ¢å¤åŸå§‹æŒ‰é’®ç¦ç”¨çŠ¶æ€
            self._force_disable_buttons = original_disable_state
            
            # æ£€æŸ¥å¤„ç†çŠ¶æ€å¹¶ç›¸åº”åœ°æ›´æ–°æŒ‰é’®
            if self.is_processing:
                # å¦‚æœä»åœ¨å¤„ç†ä¸­ï¼Œç¡®ä¿æŒ‰é’®ä¿æŒç¦ç”¨
                self.process_btn.state(['disabled'])
                self.select_image_btn.state(['disabled'])
                self.select_video_btn.state(['disabled'])
            else:
                # å¦‚æœå¤„ç†å·²å®Œæˆï¼Œç¡®ä¿æŒ‰é’®é‡æ–°å¯ç”¨
                self.log("æ›´æ–°è¡Œä¸ºåˆ—è¡¨åé‡æ–°å¯ç”¨æŒ‰é’®")
                self.process_btn.state(['!disabled'])
                self.select_image_btn.state(['!disabled'])
                self.select_video_btn.state(['!disabled'])
                
                # å¦‚æœæœ‰å¤„ç†ç»“æœï¼Œå¯ç”¨ä¿å­˜æŒ‰é’®
                if hasattr(self, 'processed_media_path') and self.processed_media_path:
                    self.save_btn.state(['!disabled'])
                
        except Exception as e:
            self.log(f"æ›´æ–°è¡Œä¸ºåˆ—è¡¨é”™è¯¯: {str(e)}")
            import traceback
            self.log(traceback.format_exc())
            
            # æ¢å¤åŸå§‹æŒ‰é’®ç¦ç”¨çŠ¶æ€
            self._force_disable_buttons = original_disable_state
            
            # å¦‚æœä»åœ¨å¤„ç†ä¸­ï¼Œç¡®ä¿æŒ‰é’®ä¿æŒç¦ç”¨
            if self.is_processing:
                self.process_btn.state(['disabled'])
                self.select_image_btn.state(['disabled'])
                self.select_video_btn.state(['disabled'])
    
    def determine_behavior_type(self, detections):
        """åŸºäºæ£€æµ‹ç»“æœç¡®å®šå¯ç–‘è¡Œä¸ºç±»å‹ - è¢«analyze_behavioræ›¿ä»£ï¼Œä¿ç•™ä¸ºå…¼å®¹æ—§ä»£ç """
        if detections is None:
            return None
            
        behavior_types = [
            "é®æŒ¡å•†å“åŒºåŸŸ", 
            "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸",
            "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·",
            "åå¤è°ƒæ•´ä½ç½®",
            "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ",
            "å¯ç–‘å•†å“å¤„ç†",
            "å¿«é€Ÿè—åŒ¿ç‰©å“"
        ]
        
        import random
        return random.choice(behavior_types)
    
    def start_processed_video_playback(self):
        """å¼€å§‹æ’­æ”¾å¤„ç†åçš„è§†é¢‘"""
        try:
            # é¦–å…ˆåœæ­¢ä»»ä½•æ­£åœ¨è¿›è¡Œçš„è§†é¢‘æ’­æ”¾
            self.stop_video_playback()
            
            # è·å–åŸå§‹è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆä»static/videosç›®å½•è·å–ï¼‰
            original_filename = os.path.basename(self.current_media_path)
            static_video_path = os.path.join("static", "videos", original_filename)
            
            # ä¼˜å…ˆä½¿ç”¨static/videosç›®å½•ä¸‹çš„è§†é¢‘ä½œä¸ºåŸå§‹è§†é¢‘
            if os.path.exists(static_video_path):
                original_video_path = static_video_path
                self.log(f"ä½¿ç”¨static/videosç›®å½•ä¸‹çš„åŸå§‹è§†é¢‘: {original_video_path}")
            else:
                # å¦‚æœstatic/videosä¸­ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨å½“å‰è·¯å¾„
                original_video_path = self.current_media_path
                if not os.path.exists(original_video_path):
                    self.log(f"é”™è¯¯ï¼šåŸå§‹è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {original_video_path}")
                    return
                
            # æ£€æŸ¥å¤„ç†åçš„è§†é¢‘æ–‡ä»¶è·¯å¾„æ˜¯å¦æœ‰æ•ˆ
            if not os.path.exists(self.processed_media_path):
                self.log(f"é”™è¯¯ï¼šå¤„ç†åçš„è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {self.processed_media_path}")
                return
            
            # å·¦ä¾§æ˜¾ç¤ºåŸå§‹è§†é¢‘ï¼ˆåŸå§‹åª’ä½“åŒºåŸŸï¼‰
            self.video_capture = cv2.VideoCapture(original_video_path)
            if not self.video_capture.isOpened():
                self.log(f"æ— æ³•æ‰“å¼€åŸå§‹è§†é¢‘: {original_video_path}")
                return
            
            # å³ä¾§æ˜¾ç¤ºå¤„ç†åçš„è§†é¢‘ï¼ˆæ£€æµ‹ç»“æœåŒºåŸŸï¼‰
            self.processed_video_capture = cv2.VideoCapture(self.processed_media_path)
            if not self.processed_video_capture.isOpened():
                self.log(f"æ— æ³•æ‰“å¼€å¤„ç†åçš„è§†é¢‘: {self.processed_media_path}")
                self.video_capture.release()
                return
            
            # è®°å½•æ–‡ä»¶ä¿¡æ¯ç”¨äºè°ƒè¯•    
            self.log(f"åŸå§‹è§†é¢‘ï¼ˆå·¦ä¾§åŸå§‹åª’ä½“åŒºåŸŸï¼‰ï¼š{original_video_path}")
            self.log(f"å¤„ç†åè§†é¢‘ï¼ˆå³ä¾§æ£€æµ‹ç»“æœåŒºåŸŸï¼‰ï¼š{self.processed_media_path}")
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps_original = self.video_capture.get(cv2.CAP_PROP_FPS)
            fps_processed = self.processed_video_capture.get(cv2.CAP_PROP_FPS)
            frames_original = int(self.video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            frames_processed = int(self.processed_video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
            
            self.log(f"åŸå§‹è§†é¢‘ä¿¡æ¯: FPS={fps_original}, æ€»å¸§æ•°={frames_original}")
            self.log(f"å¤„ç†åè§†é¢‘ä¿¡æ¯: FPS={fps_processed}, æ€»å¸§æ•°={frames_processed}")
            
            # ç¡®ä¿ä¸¤ä¸ªè§†é¢‘éƒ½ä»å¤´å¼€å§‹
            self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
            self.processed_video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
                
            # è·å–è§†é¢‘ä¿¡æ¯ï¼Œåˆå§‹åŒ–æ—¶é—´æ ‡ç­¾
            self.update_time_label(0)
            
            # æ˜¾ç¤ºæ’­æ”¾æ§åˆ¶åŒºåŸŸ
            self.playback_control_frame.pack(fill=tk.X, pady=5, after=self.media_frame)
            
            # æ£€æŸ¥è¡Œä¸ºåˆ—è¡¨æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœæ˜¯ä¸”æœ‰ä¿å­˜çš„è¡Œä¸ºæ•°æ®ï¼Œåˆ™æ›´æ–°UI
            if (len(self.behavior_list.get_children()) == 0 and 
                hasattr(self, 'behaviors_data') and self.behaviors_data):
                self.log("æ£€æµ‹åˆ°è¡Œä¸ºåˆ—è¡¨ä¸ºç©ºï¼Œä½¿ç”¨ä¿å­˜çš„è¡Œä¸ºæ•°æ®æ›´æ–°UI")
                self.update_ui_with_behaviors()
                
            # å¯åŠ¨æ’­æ”¾çº¿ç¨‹
            self.stop_video_thread = False
            self.is_playing = True
            self.play_pause_btn.config(text="æš‚åœ")
            self.current_frame = 0
            self.video_thread = threading.Thread(target=self.sync_video_playback_loop)
            self.video_thread.daemon = True
            self.video_thread.start()
            
            # å¯ç”¨ä¿å­˜æŒ‰é’®
            self.save_btn.state(['!disabled'])
        except Exception as e:
            self.log(f"æ’­æ”¾å¤„ç†åè§†é¢‘é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def sync_video_playback_loop(self):
        """åŒæ­¥æ’­æ”¾åŸå§‹è§†é¢‘å’Œå¤„ç†åçš„è§†é¢‘"""
        if self.video_capture is None or self.processed_video_capture is None:
            self.log("é”™è¯¯: è§†é¢‘æºä¸å¯ç”¨")
            return
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = self.video_capture.get(cv2.CAP_PROP_FPS)  # ä½¿ç”¨åŸå§‹è§†é¢‘çš„å¸§ç‡
        total_frames = int(self.video_capture.get(cv2.CAP_PROP_FRAME_COUNT))  # ä½¿ç”¨åŸå§‹è§†é¢‘çš„æ€»å¸§æ•°
        
        # ç¡®ä¿ä¸¤ä¸ªè§†é¢‘ä»å¤´å¼€å§‹æ’­æ”¾
        self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
        self.processed_video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
        self.current_frame = 0
        
        # å¸§ç‡æ§åˆ¶
        target_fps = fps if fps > 0 else 30
        frame_time = 1.0 / target_fps
        
        # åŒæ­¥æ’­æ”¾æ ‡å¿—
        self.log(f"å¼€å§‹åŒæ­¥æ’­æ”¾ï¼šå·¦ä¾§åŸå§‹åª’ä½“åŒºåŸŸæ˜¾ç¤ºåŸå§‹è§†é¢‘ï¼Œå³ä¾§æ£€æµ‹ç»“æœåŒºåŸŸæ˜¾ç¤ºæ£€æµ‹åè§†é¢‘ï¼ŒFPS: {target_fps}")
        
        # å°è¯•è¯»å–ç¬¬ä¸€å¸§æµ‹è¯•æ˜¯å¦æˆåŠŸ
        ret1, test_frame1 = self.video_capture.read()
        if ret1:
            self.log("åŸå§‹è§†é¢‘(å·¦ä¾§åŸå§‹åª’ä½“åŒºåŸŸ)æˆåŠŸè¯»å–ç¬¬ä¸€å¸§")
            # é‡ç½®åˆ°å¼€å§‹
            self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
        else:
            self.log("è­¦å‘Š: æ— æ³•è¯»å–åŸå§‹è§†é¢‘ç¬¬ä¸€å¸§")
        
        ret2, test_frame2 = self.processed_video_capture.read()
        if ret2:
            self.log("å¤„ç†åè§†é¢‘(å³ä¾§æ£€æµ‹ç»“æœåŒºåŸŸ)æˆåŠŸè¯»å–ç¬¬ä¸€å¸§")
            # é‡ç½®åˆ°å¼€å§‹
            self.processed_video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
        else:
            self.log("è­¦å‘Š: æ— æ³•è¯»å–å¤„ç†åè§†é¢‘ç¬¬ä¸€å¸§")
        
        while not self.stop_video_thread:
            # å¦‚æœæš‚åœï¼Œåˆ™ç­‰å¾…
            if not self.is_playing:
                time.sleep(0.1)
                continue
                
            # è®°å½•å¸§å¤„ç†å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # è¯»å–åŸå§‹è§†é¢‘å¸§
            ret1, frame1 = self.video_capture.read()
            # è¯»å–å¤„ç†åçš„è§†é¢‘å¸§
            ret2, frame2 = self.processed_video_capture.read()
            
            # è®°å½•è¯»å–ç»“æœ
            if self.current_frame % 30 == 0:  # é¿å…æ—¥å¿—è¿‡å¤š
                self.log(f"å¸§ {self.current_frame}: åŸå§‹è§†é¢‘è¯»å–çŠ¶æ€={ret1}, å¤„ç†åè§†é¢‘è¯»å–çŠ¶æ€={ret2}")
            
            # åˆ¤æ–­æ˜¯å¦æœ‰ä»»ä¸€è§†é¢‘ç»“æŸ
            if not ret1 or not ret2:
                # è§†é¢‘ç»“æŸï¼Œé‡ç½®è§†é¢‘åˆ°å¼€å§‹ä½ç½®
                self.log("è§†é¢‘æ’­æ”¾å®Œæ¯•ï¼Œé‡ç½®åˆ°å¼€å§‹ä½ç½®")
                self.video_capture.release()
                self.processed_video_capture.release()
                
                # è·å–æ­£ç¡®çš„åŸå§‹è§†é¢‘è·¯å¾„
                original_video_path = self.current_media_path
                # æ£€æŸ¥åŸå§‹è§†é¢‘æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•åœ¨static/videosç›®å½•ä¸­æŸ¥æ‰¾
                if not os.path.exists(original_video_path):
                    filename = os.path.basename(original_video_path)
                    static_video_path = os.path.join("static", "videos", filename)
                    if os.path.exists(static_video_path):
                        original_video_path = static_video_path
                        self.log(f"å·²æ‰¾åˆ°åŸå§‹è§†é¢‘æ–‡ä»¶: {original_video_path}")
                
                # é‡æ–°æ‰“å¼€è§†é¢‘æ–‡ä»¶
                self.video_capture = cv2.VideoCapture(original_video_path)
                self.processed_video_capture = cv2.VideoCapture(self.processed_media_path)
                
                # ç¡®ä¿ä¸¤ä¸ªè§†é¢‘éƒ½æˆåŠŸæ‰“å¼€
                if not self.video_capture.isOpened() or not self.processed_video_capture.isOpened():
                    self.log("æ— æ³•é‡æ–°æ‰“å¼€è§†é¢‘æ–‡ä»¶")
                    self.is_playing = False
                    self.root.after(0, lambda: self.play_pause_btn.config(text="æ’­æ”¾"))
                    break
                
                # é‡ç½®çŠ¶æ€
                self.is_playing = False
                self.current_frame = 0
                
                # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°æŒ‰é’®çŠ¶æ€
                self.root.after(0, lambda: self.play_pause_btn.config(text="æ’­æ”¾"))
                break
            
            # è½¬æ¢é¢œè‰²æ ¼å¼
            frame1_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)  # åŸå§‹è§†é¢‘å¸§
            frame2_rgb = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)  # å¤„ç†åçš„è§†é¢‘å¸§
            
            # ä½¿ç”¨ä¸€ä¸ªå‡½æ•°åŒæ—¶æ›´æ–°ä¸¤ä¸ªç”»å¸ƒï¼Œé¿å…å¼‚æ­¥æ›´æ–°å¯¼è‡´ä¸åŒæ­¥
            def update_both_canvases(original_img, processed_img):
                # åŸå§‹è§†é¢‘æ˜¾ç¤ºåœ¨å·¦ä¾§åŸå§‹åª’ä½“åŒºåŸŸ
                self.display_image(original_img, self.original_canvas)
                # å¤„ç†åçš„è§†é¢‘æ˜¾ç¤ºåœ¨å³ä¾§æ£€æµ‹ç»“æœåŒºåŸŸ
                self.display_image(processed_img, self.processed_canvas)
            
            # æ›´æ–°UI (åœ¨ä¸»çº¿ç¨‹ä¸­)
            self.root.after(0, lambda: update_both_canvases(frame1_rgb.copy(), frame2_rgb.copy()))
            
            # å¢åŠ å¸§è®¡æ•°
            self.current_frame += 1
            
            # æ›´æ–°è¿›åº¦æ¡å’Œæ—¶é—´æ ‡ç­¾ (ä¸è§¦å‘æ»‘åŠ¨æ¡å˜åŒ–äº‹ä»¶)
            if not hasattr(self, 'slider_being_changed') or not self.slider_being_changed:
                progress = (self.current_frame / total_frames) * 100 if total_frames > 0 else 0
                self.root.after(0, lambda p=progress: self.update_slider_position(p))
                self.root.after(0, lambda f=self.current_frame: self.update_time_label(f))
            
            # è®¡ç®—å¸§å¤„ç†æ‰€éœ€æ—¶é—´
            processing_time = time.time() - start_time
            
            # æ§åˆ¶æ’­æ”¾é€Ÿåº¦
            sleep_time = max(0, frame_time - processing_time)
            time.sleep(sleep_time)
    
    def update_slider_position(self, position):
        """æ›´æ–°æ»‘åŠ¨æ¡ä½ç½®ï¼Œä¸è§¦å‘äº‹ä»¶"""
        # è®¾ç½®æ ‡å¿—é˜²æ­¢è§¦å‘å›è°ƒ
        self.slider_being_changed = True
        self.progress_var.set(position)
        self.slider_being_changed = False
            
    def stop_video_playback(self):
        """åœæ­¢è§†é¢‘æ’­æ”¾"""
        self.stop_video_thread = True
        self.is_playing = False
        
        if self.video_thread:
            self.video_thread.join(timeout=1.0)
            self.video_thread = None
        
        if self.video_capture:
            self.video_capture.release()
            self.video_capture = None
            
        if self.processed_video_capture:
            self.processed_video_capture.release()
            self.processed_video_capture = None
            
        # é‡ç½®æ’­æ”¾æŒ‰é’®
        self.play_pause_btn.config(text="æ’­æ”¾")
    
    def save_result(self):
        """Save processing result"""
        if not self.processed_media_path or not os.path.exists(self.processed_media_path):
            self.log("é”™è¯¯: æ²¡æœ‰å¯ä¿å­˜çš„ç»“æœ")
            return
        
        if self.current_media_type == 'image':
            filetypes = [("JPEG å›¾ç‰‡", "*.jpg"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
            default_ext = ".jpg"
        else:
            filetypes = [("MP4 è§†é¢‘", "*.mp4"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
            default_ext = ".mp4"
        
        save_path = filedialog.asksaveasfilename(
            title="ä¿å­˜ç»“æœ",
            defaultextension=default_ext,
            filetypes=filetypes
        )
        
        if save_path:
            try:
                # Copy the result file to the selected path
                import shutil
                shutil.copy2(self.processed_media_path, save_path)
                self.log(f"ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
            except Exception as e:
                messagebox.showerror("ä¿å­˜é”™è¯¯", f"ä¿å­˜ç»“æœæ—¶å‡ºé”™: {str(e)}")
                self.log(f"ä¿å­˜é”™è¯¯: {str(e)}")

    def on_window_configure(self, event):
        """å¤„ç†çª—å£å¤§å°å˜åŒ–ï¼Œä½†é¿å…è¿‡äºé¢‘ç¹çš„æ›´æ–°"""
        # ç¡®ä¿äº‹ä»¶æ¥è‡ªæ ¹çª—å£
        if event.widget != self.root:
            return
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€å¤§åŒ–/æ¢å¤äº‹ä»¶
        current_is_maximized = self.root.wm_state() == 'zoomed'
        
        # å¦‚æœæœ€å¤§åŒ–çŠ¶æ€æ”¹å˜ï¼Œæˆ–çª—å£å¤§å°æœ‰æ˜æ˜¾å˜åŒ–ï¼Œåˆ™æ›´æ–°ç”»å¸ƒ
        if (current_is_maximized != self.is_maximized or 
            abs(self.last_known_width - event.width) > 50 or 
            abs(self.last_known_height - event.height) > 50):
            
            # æ›´æ–°çŠ¶æ€
            self.is_maximized = current_is_maximized
            self.last_known_width = event.width
            self.last_known_height = event.height
            
            # ä¿å­˜å½“å‰è¿›åº¦æ¡çŠ¶æ€
            current_progress = self.progress_bar['value']
            progress_text = self.progress_text.get() if hasattr(self, 'progress_text') else "0%"
            
            # ä¸´æ—¶æš‚åœè§†é¢‘æ’­æ”¾ä»¥é˜²æ­¢ç«æ€æ¡ä»¶
            was_playing = False
            if hasattr(self, 'is_playing') and self.is_playing and hasattr(self, 'video_thread') and self.video_thread:
                was_playing = True
                self.is_playing = False
                # ç­‰å¾…çŸ­æš‚æ—¶é—´ç¡®ä¿è§†é¢‘çº¿ç¨‹å·²æš‚åœ
                time.sleep(0.1)
            
            # è®¡ç®—æ–°çš„çª—å£æ¯”ä¾‹ï¼Œç”¨äºè‡ªé€‚åº”è°ƒæ•´
            window_ratio = event.width / self.default_width if self.default_width > 0 else 1
            
            # æ ¹æ®çª—å£çš„ç¼©æ”¾æ¯”ä¾‹ï¼Œè°ƒæ•´update_canvas_sizesæ–¹æ³•ä¸­ä½¿ç”¨çš„ç”»å¸ƒå¤§å°è®¡ç®—å‚æ•°
            if self.is_maximized:
                # åœ¨æœ€å¤§åŒ–çŠ¶æ€ä¸‹ï¼Œæ ¹æ®çª—å£å®½åº¦è°ƒæ•´ç”»å¸ƒå°ºå¯¸
                # è¿™æ ·å¯ä»¥é¿å…æœ€å¤§åŒ–çª—å£æ—¶å³ä¾§å‡ºç°å¤§é‡ç©ºç™½
                available_width = event.width - 50
                canvas_width = int(available_width / 2 - 20)  # å·¦å³ä¸¤è¾¹å„å ä¸€åŠ
                canvas_height = int(canvas_width * 9 / 16)  # ä¿æŒ16:9æ¯”ä¾‹
                
                # ç¡®ä¿é«˜åº¦ä¸è¶…è¿‡å¯ç”¨ç©ºé—´
                available_height = event.height - 200
                if canvas_height > available_height * 0.7:
                    canvas_height = int(available_height * 0.7)
                    canvas_width = int(canvas_height * 16 / 9)
                
                # ç›´æ¥æ›´æ–°ç”»å¸ƒå’Œæ¡†æ¶å¤§å°ï¼Œé¿å…è°ƒç”¨update_canvas_sizesä¿®æ”¹åˆå§‹å¸ƒå±€
                self.original_canvas.config(width=canvas_width, height=canvas_height)
                self.processed_canvas.config(width=canvas_width, height=canvas_height)
                self.original_canvas_frame.config(width=canvas_width, height=canvas_height)
                self.processed_canvas_frame.config(width=canvas_width, height=canvas_height)
                
                # å¦‚æœæœ‰åŸå§‹å›¾åƒæˆ–è§†é¢‘å¸§ï¼Œéœ€è¦é‡æ–°è°ƒæ•´å¤§å°å¹¶ç»˜åˆ¶
                if hasattr(self, 'original_image') and isinstance(self.original_image, np.ndarray):
                    # é‡æ–°æ˜¾ç¤ºåŸå§‹å›¾åƒ
                    original_rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
                    self.display_image(original_rgb, self.original_canvas, 
                                    forced_width=canvas_width, 
                                    forced_height=canvas_height)
                
                # å¦‚æœæœ‰å¤„ç†åçš„å›¾åƒï¼Œä¹Ÿéœ€è¦é‡æ–°æ˜¾ç¤º
                if hasattr(self, 'processed_frame') and isinstance(self.processed_frame, np.ndarray):
                    # é‡æ–°æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
                    if len(self.processed_frame.shape) == 3:
                        processed_rgb = cv2.cvtColor(self.processed_frame, cv2.COLOR_BGR2RGB)
                    else:
                        processed_rgb = self.processed_frame
                    self.display_image(processed_rgb, self.processed_canvas,
                                    forced_width=canvas_width,
                                    forced_height=canvas_height)
            else:
                # å¦‚æœæ˜¯ä»æœ€å¤§åŒ–æ¢å¤ï¼Œæˆ–çª—å£å¤§å°å˜åŒ–ï¼Œè°ƒç”¨æ­£å¸¸çš„update_canvas_sizes
                # è¿™æ ·å¯ä»¥ç¡®ä¿æ¢å¤åˆ°åˆå§‹å¸ƒå±€
                self.root.after(100, self.update_canvas_sizes)
                # åœ¨å°ºå¯¸æ›´æ–°åé‡æ–°æ˜¾ç¤ºåª’ä½“
                self.root.after(200, self.redisplay_current_media)
            
            # æ¢å¤è¿›åº¦æ¡çŠ¶æ€
            self.root.after(150, lambda: self.restore_progress_state(current_progress, progress_text))
            
            # å¦‚æœä¹‹å‰æ­£åœ¨æ’­æ”¾ï¼Œæ¢å¤æ’­æ”¾
            if was_playing:
                self.root.after(300, lambda: setattr(self, 'is_playing', True))

    def redisplay_current_media(self, canvas_width=None, canvas_height=None):
        """é‡æ–°æ˜¾ç¤ºå½“å‰åŠ è½½çš„åª’ä½“å†…å®¹ï¼Œé€‚åº”ç”»å¸ƒå¤§å°"""
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å¤„ç†åçš„å›¾åƒï¼ˆæ£€æµ‹ç»“æœï¼‰
            has_processed_content = False
            
            # 1. ä¼˜å…ˆæ˜¾ç¤ºå¤„ç†åçš„å›¾åƒï¼ˆæ£€æµ‹ç»“æœï¼‰
            if hasattr(self, 'processed_frame') and isinstance(self.processed_frame, np.ndarray):
                try:
                    # é‡æ–°æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒï¼ˆæ£€æµ‹ç»“æœï¼‰
                    if len(self.processed_frame.shape) == 3:
                        processed_rgb = cv2.cvtColor(self.processed_frame, cv2.COLOR_BGR2RGB)
                    else:
                        processed_rgb = self.processed_frame
                    
                    # åœ¨ä¸¤ä¸ªç”»å¸ƒä¸Šéƒ½æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
                    self.display_image(processed_rgb, self.processed_canvas,
                                    forced_width=canvas_width,
                                    forced_height=canvas_height)
                    self.display_image(processed_rgb, self.original_canvas,
                                    forced_width=canvas_width,
                                    forced_height=canvas_height)
                    has_processed_content = True
                    return True
                except Exception as e:
                    self.log(f"æ˜¾ç¤ºå¤„ç†åå›¾åƒé”™è¯¯: {str(e)}", console_only=True)
            
            # 2. å¦‚æœæ²¡æœ‰å¤„ç†åçš„å›¾åƒä½†æœ‰å¤„ç†åçš„PhotoImage
            if not has_processed_content and hasattr(self, '_processed_photo') and self._processed_photo:
                try:
                    # åœ¨ä¸¤ä¸ªç”»å¸ƒä¸Šéƒ½æ˜¾ç¤ºå¤„ç†åçš„PhotoImage
                    self.processed_canvas.delete("all")
                    self.original_canvas.delete("all")
                    
                    center_x = canvas_width//2 if canvas_width else self.processed_canvas.winfo_width()//2
                    center_y = canvas_height//2 if canvas_height else self.processed_canvas.winfo_height()//2
                    
                    self.processed_canvas.create_image(center_x, center_y, image=self._processed_photo)
                    self.original_canvas.create_image(center_x, center_y, image=self._processed_photo)
                    has_processed_content = True
                    return True
                except Exception as e:
                    self.log(f"æ˜¾ç¤ºå¤„ç†åPhotoImageé”™è¯¯: {str(e)}", console_only=True)
            
            # 3. åªæœ‰åœ¨æ²¡æœ‰ä»»ä½•å¤„ç†åå†…å®¹æ—¶ï¼Œæ‰æ˜¾ç¤ºåŸå§‹å†…å®¹
            if not has_processed_content:
                if hasattr(self, 'original_image') and isinstance(self.original_image, np.ndarray):
                    try:
                        original_rgb = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
                        self.display_image(original_rgb, self.original_canvas, 
                                        forced_width=canvas_width, 
                                        forced_height=canvas_height)
                    except Exception as e:
                        self.log(f"æ˜¾ç¤ºåŸå§‹å›¾åƒé”™è¯¯: {str(e)}", console_only=True)
                elif hasattr(self, '_original_photo') and self._original_photo:
                    try:
                        self.original_canvas.delete("all")
                        center_x = canvas_width//2 if canvas_width else self.original_canvas.winfo_width()//2
                        center_y = canvas_height//2 if canvas_height else self.original_canvas.winfo_height()//2
                        self.original_canvas.create_image(center_x, center_y, image=self._original_photo)
                    except Exception as e:
                        self.log(f"æ˜¾ç¤ºåŸå§‹PhotoImageé”™è¯¯: {str(e)}", console_only=True)
            
            # æ›´æ–°UIå¸ƒå±€
            self.root.update_idletasks()
            return True
        except Exception as e:
            self.log(f"é‡æ–°æ˜¾ç¤ºåª’ä½“é”™è¯¯: {str(e)}")
            import traceback
            self.log(traceback.format_exc(), console_only=True)
            return False
        
    def toggle_fullscreen(self, event=None):
        """åˆ‡æ¢å…¨å±æ¨¡å¼"""
        self.is_maximized = not self.is_maximized
        self.root.attributes("-fullscreen", self.is_maximized)
        self.update_canvas_sizes()
        return "break"

    def end_fullscreen(self, event=None):
        """é€€å‡ºå…¨å±æ¨¡å¼"""
        self.is_maximized = False
        self.root.attributes("-fullscreen", False)
        self.update_canvas_sizes()
        return "break"

    def redisplay_current_frames(self):
        """åœ¨è°ƒæ•´å¤§å°åé‡æ–°æ˜¾ç¤ºå½“å‰å¸§"""
        # åªæœ‰åœ¨å½“å‰æœ‰è§†é¢‘æ’­æ”¾æ—¶æ‰æ›´æ–°
        if hasattr(self, 'video_capture') and self.video_capture is not None:
            # ä¸´æ—¶æš‚åœè§†é¢‘æ’­æ”¾
            was_playing = False
            if hasattr(self, 'is_playing') and self.is_playing:
                was_playing = True
                self.is_playing = False
                # ç­‰å¾…çŸ­æš‚æ—¶é—´ç¡®ä¿è§†é¢‘çº¿ç¨‹å·²æš‚åœ
                time.sleep(0.1)
            
            # ä½¿ç”¨å·²ç»ç¼“å­˜çš„å›¾åƒè€Œä¸æ˜¯é‡æ–°è¯»å–è§†é¢‘
            try:
                if hasattr(self, '_original_photo') and self._original_photo:
                    self.original_canvas.delete("all")
                    self.original_canvas.create_image(
                        self.original_canvas.winfo_width()//2, 
                        self.original_canvas.winfo_height()//2,
                        image=self._original_photo
                    )
                    
                if hasattr(self, '_processed_photo') and self._processed_photo:
                    self.processed_canvas.delete("all")
                    self.processed_canvas.create_image(
                        self.processed_canvas.winfo_width()//2, 
                        self.processed_canvas.winfo_height()//2,
                        image=self._processed_photo
                    )
            except Exception as e:
                self.log(f"é‡æ–°æ˜¾ç¤ºå¸§é”™è¯¯: {str(e)}")
            
            # å¦‚æœä¹‹å‰æ­£åœ¨æ’­æ”¾ï¼Œå»¶è¿Ÿä¸€ç‚¹æ—¶é—´åæ¢å¤æ’­æ”¾
            if was_playing:
                self.root.after(200, lambda: setattr(self, 'is_playing', True))
    
    def restore_progress_state(self, progress_value, progress_text):
        """æ¢å¤è¿›åº¦æ¡çŠ¶æ€"""
        # åªæ›´æ–°è¿›åº¦å€¼ï¼Œä¸æ˜¾ç¤ºè¿›åº¦æ–‡æœ¬å†…å®¹
        self.progress_bar['value'] = progress_value
        
        # åªæ˜¾ç¤ºç™¾åˆ†æ¯”ï¼Œè€Œä¸æ˜¾ç¤ºæ—¥å¿—å†…å®¹
        self.progress_text.set(f"{progress_value}%")
        self.progress_bar.update()
        
        # æ—¥å¿—å†…å®¹è½¬ç§»åˆ°æ—¥å¿—åŒºåŸŸ
        if progress_text and progress_text != f"{progress_value}%":
            self.log(progress_text)
        
        # é‡æ–°è®¾ç½®æ ‡ç­¾æ¡†æ¶ä½ç½®ï¼Œç¡®ä¿å±…ä¸­
        if hasattr(self, 'label_frame') and self.label_frame:
            self.label_frame.place(relx=0.5, rely=0.5, anchor="center")
            self.progress_label.update()

    def _center_window(self):
        """å°†çª—å£å±…ä¸­æ˜¾ç¤º"""
        # è·å–å±å¹•å°ºå¯¸
        screen_width = self.root.winfo_screenwidth()
        screen_height = self.root.winfo_screenheight()
        
        # è®¡ç®—å±…ä¸­ä½ç½®
        x_position = int((screen_width - self.default_width) / 2)
        y_position = int((screen_height - self.default_height) / 2)
        
        # è®¾ç½®çª—å£ä½ç½®
        self.root.geometry(f"{self.default_width}x{self.default_height}+{x_position}+{y_position}")
    
    def _configure_main_canvas(self, event):
        """é…ç½®ä¸»ç”»å¸ƒæ»šåŠ¨åŒºåŸŸ"""
        # æ›´æ–°ç”»å¸ƒçš„æ»šåŠ¨åŒºåŸŸ
        self.main_canvas.configure(scrollregion=self.main_canvas.bbox("all"))
        
        # è°ƒæ•´ç”»å¸ƒå®½åº¦ä»¥é€‚åº”æ¡†æ¶
        self.main_canvas.config(width=self.root.winfo_width() - self.main_scroll.winfo_width())

    def toggle_playback(self):
        """åˆ‡æ¢è§†é¢‘æ’­æ”¾/æš‚åœçŠ¶æ€"""
        if not self.processed_media_path:
            return
            
        self.is_playing = not self.is_playing
        
        # æ›´æ–°æŒ‰é’®æ–‡æœ¬
        if self.is_playing:
            self.play_pause_btn.config(text="æš‚åœ")
            if not self.video_thread or not self.video_thread.is_alive():
                # å¯åŠ¨æ’­æ”¾çº¿ç¨‹
                self.start_processed_video_playback()
        else:
            self.play_pause_btn.config(text="æ’­æ”¾")
    
    def on_slider_change(self, value):
        """å¤„ç†è¿›åº¦æ¡æ‹–åŠ¨äº‹ä»¶"""
        if not self.processed_media_path:
            return
            
        # è·å–å½“å‰è¿›åº¦ç™¾åˆ†æ¯”
        position = float(value)
        
        # é˜²æ­¢åœ¨æ’­æ”¾çº¿ç¨‹ä¸­å¤„ç†æ»‘åŠ¨æ¡æ‹–åŠ¨å¼•èµ·çš„å¾ªç¯
        if hasattr(self, 'slider_being_changed') and self.slider_being_changed:
            return
            
        # è®¾ç½®æ ‡å¿—ï¼Œé˜²æ­¢æ’­æ”¾çº¿ç¨‹æ›´æ–°æ»‘åŠ¨æ¡
        self.slider_being_changed = True
        
        try:
            # å¦‚æœè§†é¢‘å·²æ‰“å¼€ï¼Œè®¾ç½®è§†é¢‘ä½ç½®
            if self.video_capture and self.processed_video_capture:
                total_frames = int(self.processed_video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
                target_frame = int(total_frames * position / 100)
                
                # å…³é—­å¹¶é‡æ–°æ‰“å¼€è§†é¢‘ä»¥é¿å…è§£ç é”™è¯¯
                self.video_capture.release()
                self.processed_video_capture.release()
                
                self.video_capture = cv2.VideoCapture(self.current_media_path)
                self.processed_video_capture = cv2.VideoCapture(self.processed_media_path)
                
                # é€å¸§è¯»å–åˆ°ç›®æ ‡ä½ç½®
                for _ in range(target_frame):
                    self.video_capture.read()
                    self.processed_video_capture.read()
                
                # è¯»å–ç›®æ ‡å¸§
                ret1, frame1 = self.video_capture.read()
                ret2, frame2 = self.processed_video_capture.read()
                
                if ret1 and ret2:
                    frame1_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)
                    frame2_rgb = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)
                    
                    self.display_image(frame1_rgb, self.original_canvas)
                    self.display_image(frame2_rgb, self.processed_canvas)
                    
                    # æ›´æ–°æ—¶é—´æ ‡ç­¾
                    self.update_time_label(target_frame)
        finally:
            # æ¸…é™¤æ ‡å¿—
            self.slider_being_changed = False
            
    def update_time_label(self, current_frame=None):
        """æ›´æ–°è§†é¢‘æ—¶é—´æ ‡ç­¾"""
        if not self.processed_video_capture:
            return
            
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = self.processed_video_capture.get(cv2.CAP_PROP_FPS)
        total_frames = int(self.processed_video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå½“å‰å¸§ï¼Œåˆ™è·å–å½“å‰ä½ç½®
        if current_frame is None:
            current_frame = int(self.processed_video_capture.get(cv2.CAP_PROP_POS_FRAMES))
        
        # è®¡ç®—å½“å‰æ—¶é—´å’Œæ€»æ—¶é—´
        current_time = current_frame / fps if fps > 0 else 0
        total_time = total_frames / fps if fps > 0 else 0
        
        # æ ¼å¼åŒ–æ—¶é—´
        current_time_str = self.format_time(current_time)
        total_time_str = self.format_time(total_time)
        
        # æ›´æ–°æ ‡ç­¾
        self.time_label.config(text=f"{current_time_str} / {total_time_str}")
    
    def format_time(self, seconds):
        """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ—¶:åˆ†:ç§’æ ¼å¼
        
        Args:
            seconds: ç§’æ•°
            
        Returns:
            æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = int(seconds % 60)
        
        if hours > 0:
            return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
        else:
            return f"{minutes:02d}:{seconds:02d}"

    def update_behavior_list(self, behaviors):
        """æ›´æ–°è¡Œä¸ºåˆ—è¡¨UI"""
        try:
            # æ¸…ç©ºè¡Œä¸ºåˆ—è¡¨å‡†å¤‡æ·»åŠ æ–°è¡Œä¸º
            for item in self.behavior_list.get_children():
                self.behavior_list.delete(item)
            
            # æ‰“å¼€è§†é¢‘è·å–FPS
            cap = cv2.VideoCapture(self.current_media_path)
            fps = cap.get(cv2.CAP_PROP_FPS) if cap.isOpened() else 30
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.isOpened() else 1
            cap.release()
            
            # æå–åˆ†æç»“æœæ•°æ®
            behavior_types = set()
            max_probability = 0.0
            
            # å¤„ç†æ£€æµ‹åˆ°çš„è¡Œä¸º
            for frame_idx, frame_behaviors in behaviors:
                for behavior in frame_behaviors:
                    behavior_type = behavior.get('type', 'æœªçŸ¥è¡Œä¸º')
                    behavior_types.add(behavior_type)
                    confidence = behavior.get('confidence', 0.0)
                    max_probability = max(max_probability, confidence)
                    
                    # æ·»åŠ åˆ°è¡Œä¸ºåˆ—è¡¨UI
                    time_point = frame_idx / fps if fps > 0 else 0
                    self.add_behavior_to_list(frame_idx, time_point, behavior_type, confidence)
            
            # ç¡®ä¿æ›´æ–°åˆ—è¡¨æ˜¾ç¤ºå’Œæ»šåŠ¨æ¡
            self.behavior_list.update()
            self.behavior_scrollbar.update()
            
            # æ€»æ˜¯æ»šåŠ¨åˆ°åº•éƒ¨æ˜¾ç¤ºæœ€æ–°å†…å®¹
            self.behavior_list.yview_moveto(1.0)
            
            theft_frames = len(set(frame_idx for frame_idx, _ in behaviors))
            
            # åˆ›å»ºè¡Œä¸ºæ‘˜è¦
            self.create_behavior_summary(behaviors, max_probability, theft_frames, total_frames)
            
            # æ›´æ–°åˆ†æç»“æœæ—¥å¿—
            theft_detected = "æ˜¯" if theft_frames > 0 else "å¦"
            summary_message = f"è§†é¢‘åˆ†æå®Œæˆ: æ¢æµ‹ç›—çªƒè¡Œä¸ºï¼š{theft_detected}"
            summary_message += f"\næœ€é«˜ç›—çªƒæ¦‚ç‡: {max_probability:.2f}"
            summary_message += f"\nåŒ…å«ç›—çªƒè¡Œä¸ºçš„å¸§æ•°: {theft_frames}"
            total_behaviors = sum(1 for _, frame_behaviors in behaviors for _ in frame_behaviors)
            summary_message += f"\næ£€æµ‹åˆ° {total_behaviors} å¤„å¯ç–‘è¡Œä¸º"
            self.log(summary_message)
        except Exception as e:
            self.log(f"æ›´æ–°è¡Œä¸ºåˆ—è¡¨é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()

    def update_progress(self, value):
        """æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º"""
        try:
            if hasattr(self, 'progress_bar') and self.progress_bar:
                self.progress_bar['value'] = value
                
            if hasattr(self, 'progress_text') and self.progress_text:
                self.progress_text.set(f"{value}%")
                
            # é‡æ–°è°ƒæ•´æ ‡ç­¾ä½ç½®ï¼Œç¡®ä¿å±…ä¸­
            if hasattr(self, 'label_frame') and self.label_frame:
                # å…ˆæ›´æ–°è¿›åº¦æ¡ï¼Œç¡®ä¿å®ƒæœ‰æ­£ç¡®çš„å°ºå¯¸
                if hasattr(self, 'progress_bar'):
                    self.progress_bar.update_idletasks()
                
                # é‡æ–°è®¾ç½®æ ‡ç­¾æ¡†æ¶ä½ç½®ï¼Œç¡®ä¿å±…ä¸­
                self.label_frame.place(relx=0.5, rely=0.5, anchor="center")
                
            if hasattr(self, 'progress_label') and self.progress_label:
                self.progress_label.update()
                
            if hasattr(self, 'progress_bar') and self.progress_bar:
                self.progress_bar.update()
                
            self.root.update_idletasks()
        except Exception as e:
            print(f"æ›´æ–°è¿›åº¦æ¡é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()

    def rebuild_behavior_list(self, existing_behaviors):
        """æ ¹æ®ç¯å¢ƒç±»å‹é‡å»ºè¡Œä¸ºåˆ—è¡¨"""
        try:
            # è®°å½•å½“å‰çš„æŒ‰é’®ç¦ç”¨çŠ¶æ€
            original_disable_state = getattr(self, '_force_disable_buttons', False)
            
            self.log("å¼€å§‹é‡å»ºè¡Œä¸ºåˆ—è¡¨ä»¥åŒ¹é…ç¯å¢ƒç±»å‹")
            
            # å®šä¹‰é›¶å”®ç¯å¢ƒç›¸å…³è¡Œä¸ºå’Œé€šç”¨è¡Œä¸º
            retail_behaviors = ["é®æŒ¡å•†å“åŒºåŸŸ", "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ", "å¯ç–‘å•†å“å¤„ç†", "å¿«é€Ÿè—åŒ¿ç‰©å“", "å°†ç‰©å“æ”¾å…¥å£è¢‹"]
            
            # é›¶å”®ç‰¹å®šè¡Œä¸ºæ˜ å°„åˆ°é€šç”¨è¡Œä¸º
            behavior_mapping = {
                "é®æŒ¡å•†å“åŒºåŸŸ": "åå¤è°ƒæ•´ä½ç½®",
                "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ": "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸",
                "å¯ç–‘å•†å“å¤„ç†": "åå¤è°ƒæ•´ä½ç½®", 
                "å¿«é€Ÿè—åŒ¿ç‰©å“": "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸",
                "å°†ç‰©å“æ”¾å…¥å£è¢‹": "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸"
            }
            
            # å›¾æ ‡æ˜ å°„
            icon_map = {
                "é®æŒ¡å•†å“åŒºåŸŸ": "ğŸ§¥ ",
                "æ‰‹è‚˜å†…æ”¶å§¿æ€å¼‚å¸¸": "ğŸ’ª ",
                "è‚©éƒ¨ä¸è‡ªç„¶éš†èµ·": "ğŸ‘• ",
                "åå¤è°ƒæ•´ä½ç½®": "ğŸ”„ ",
                "ç–‘ä¼¼æ’•æ ‡ç­¾åŠ¨ä½œ": "ğŸ·ï¸ ",
                "å¯ç–‘å•†å“å¤„ç†": "ğŸ›’ ",
                "å¿«é€Ÿè—åŒ¿ç‰©å“": "ğŸ‘ ",
                "å°†ç‰©å“æ”¾å…¥å£è¢‹": "ğŸ‘– "
            }
            
            # æ¸…ç©ºè¡Œä¸ºåˆ—è¡¨
            for item in self.behavior_list.get_children():
                self.behavior_list.delete(item)
            
            # æ ¹æ®ç¯å¢ƒç±»å‹é‡æ–°æ·»åŠ è¡Œä¸º
            is_retail_environment = getattr(self, 'is_retail_environment', True)
            
            for time_str, behavior_type, probability_text in existing_behaviors:
                # åœ¨éé›¶å”®ç¯å¢ƒä¸­æ›¿æ¢é›¶å”®ç‰¹å®šè¡Œä¸º
                original_behavior = behavior_type
                replaced = False
                
                if not is_retail_environment:
                    for retail_behavior in retail_behaviors:
                        if retail_behavior in behavior_type:
                            # æ›¿æ¢ä¸ºé€šç”¨è¡Œä¸º
                            behavior_type = behavior_mapping.get(retail_behavior, "åå¤è°ƒæ•´ä½ç½®")
                            replaced = True
                            self.log(f"é‡å»ºåˆ—è¡¨: å°†'{original_behavior}'æ›¿æ¢ä¸º'{behavior_type}'")
                            break
                
                # æ·»åŠ å›¾æ ‡å‰ç¼€
                icon_prefix = icon_map.get(behavior_type, "âš ï¸ ")
                display_type = icon_prefix + behavior_type
                
                # å¦‚æœæ˜¯æ›¿æ¢åçš„è¡Œä¸ºï¼Œæ·»åŠ æ˜Ÿå·æ ‡è®°
                if replaced:
                    display_type += "*"
                
                # æ’å…¥è¡Œä¸ºè®°å½•
                item_id = self.behavior_list.insert("", "end", values=(time_str, display_type, probability_text))
                
                # è®¾ç½®èƒŒæ™¯è‰²ï¼ŒåŸºäºæ¦‚ç‡
                try:
                    probability = float(probability_text.strip('%')) / 100
                    if probability > 0.8:
                        self.behavior_list.item(item_id, tags=("high",))
                    elif probability > 0.6:
                        self.behavior_list.item(item_id, tags=("medium",))
                    else:
                        self.behavior_list.item(item_id, tags=("low",))
                except ValueError:
                    # å¦‚æœæ¦‚ç‡æ–‡æœ¬æ— æ³•è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾
                    self.behavior_list.item(item_id, tags=("low",))
            
            # é…ç½®æ ‡ç­¾é¢œè‰²
            self.behavior_list.tag_configure("high", background="#ffcccc")
            self.behavior_list.tag_configure("medium", background="#ffffcc")  
            self.behavior_list.tag_configure("low", background="#e6f7ff")
            
            # æ€»æ˜¯æ»šåŠ¨åˆ°åº•éƒ¨æ˜¾ç¤ºæœ€æ–°å†…å®¹
            self.behavior_list.yview_moveto(1.0)
            
            self.log("è¡Œä¸ºåˆ—è¡¨é‡å»ºå®Œæˆ")
            
            # ç¡®ä¿åœ¨å¤„ç†å®Œæˆåæ¢å¤æŒ‰é’®çŠ¶æ€
            if not self.is_processing:
                self.log("é‡å»ºåˆ—è¡¨åæ¢å¤æŒ‰é’®çŠ¶æ€")
                self.process_btn.state(['!disabled'])
                self.select_image_btn.state(['!disabled'])
                self.select_video_btn.state(['!disabled'])
                
                # å¦‚æœæœ‰å¤„ç†ç»“æœï¼Œå¯ç”¨ä¿å­˜æŒ‰é’®
                if hasattr(self, 'processed_media_path') and self.processed_media_path:
                    self.save_btn.state(['!disabled'])
            
        except Exception as e:
            self.log(f"é‡å»ºè¡Œä¸ºåˆ—è¡¨é”™è¯¯: {str(e)}")
            import traceback
            self.log(traceback.format_exc())
            
            # æ¢å¤è¿›å…¥å‡½æ•°å‰çš„æŒ‰é’®ç¦ç”¨çŠ¶æ€
            self._force_disable_buttons = original_disable_state
            
            # å¦‚æœæ­£åœ¨å¤„ç†ä¸­ï¼Œç¡®ä¿æŒ‰é’®ä¿æŒç¦ç”¨
            if self.is_processing:
                self.process_btn.state(['disabled'])
                self.select_image_btn.state(['disabled'])
                self.select_video_btn.state(['disabled'])
    
    def is_retail_environment_by_visual_features(self, image):
        """é€šè¿‡å›¾åƒè§†è§‰ç‰¹å¾åˆ¤æ–­æ˜¯å¦ä¸ºé›¶å”®ç¯å¢ƒ"""
        # åˆå§‹åŒ–è¯„åˆ†
        retail_score = 0.0
        visual_retail_score = 0.0
        
        try:
            # è¾¹ç¼˜åˆ†æ
            edge_ratio = self.analyze_edge_density(image)
            if edge_ratio > 0.15:
                visual_retail_score += 0.6
                self.log(f"æ£€æµ‹åˆ°é«˜è¾¹ç¼˜å¯†åº¦ ({edge_ratio:.4f})ï¼Œè§†è§‰é›¶å”®è¯„åˆ† +0.6", console_only=True)
            elif edge_ratio > 0.1:
                visual_retail_score += 0.3
                self.log(f"æ£€æµ‹åˆ°ä¸­ç­‰è¾¹ç¼˜å¯†åº¦ ({edge_ratio:.4f})ï¼Œè§†è§‰é›¶å”®è¯„åˆ† +0.3", console_only=True)
        except Exception as e:
            self.log(f"è®¡ç®—å›¾åƒè¾¹ç¼˜å¤±è´¥: {e}", console_only=True)
            
        try:
            # é¢œè‰²å¤šæ ·æ€§åˆ†æ
            color_diversity = self.analyze_color_diversity(image)
            if color_diversity > 0.4:
                visual_retail_score += 0.4
                self.log(f"æ£€æµ‹åˆ°é«˜é¢œè‰²å¤šæ ·æ€§ ({color_diversity:.4f})ï¼Œè§†è§‰é›¶å”®è¯„åˆ† +0.4", console_only=True)
        except Exception as e:
            self.log(f"è®¡ç®—é¢œè‰²åˆ†å¸ƒå¤±è´¥: {e}", console_only=True)
        
        # ... existing code ...

    def frame_callback(self, frame, original_frame, frame_index, detections, poses, theft_probability, behaviors):
        """åœ¨è§†é¢‘å¤„ç†çº¿ç¨‹ä¸­å¤„ç†æ¯ä¸€å¸§çš„å›è°ƒå‡½æ•°"""
        start_time = time.time()
        
        try:
            # æ„å»ºå¸§æ•°æ®å­—å…¸ï¼Œç”¨äºæ›´æ–°UI
            frame_data = {
                'frame': frame,  # å¤„ç†åçš„å¸§ï¼ˆå¸¦æœ‰æ£€æµ‹ç»“æœï¼‰
                'original_frame': original_frame,  # åŸå§‹å¸§
                'frame_index': frame_index,
                'theft_probability': theft_probability,
                'has_detections': len(detections) > 0 or len(behaviors) > 0
            }
            
            # æ›´æ–°UIæ˜¾ç¤º
            self.update_frame_display(frame_data)
            
            # è®¡ç®—æ¯ç§’å¸§æ•°
            current_time = time.time()
            elapsed_time = current_time - start_time
            fps = 1.0 / elapsed_time if elapsed_time > 0 else 0
            
            # ç”Ÿæˆè¿›åº¦æ—¥å¿—
            progress_percentage = (frame_index / self.total_frames) * 100 if self.total_frames > 0 else 0
            log_message = f"å¤„ç†è¿›åº¦: {progress_percentage:.1f}% (å¸§ {frame_index}/{self.total_frames}), FPS: {fps:.1f}"
            
            # æ›´æ–°è¿›åº¦æ¡å’Œæ—¥å¿— - æ˜¾ç¤ºåœ¨æ§åˆ¶å°ï¼Œä½†ä¸é¢‘ç¹æ˜¾ç¤ºåœ¨UIä¸Š
            self.log(log_message)
            self.update_progress(progress_percentage, log_message)
            
            # å¦‚æœæ£€æµ‹åˆ°è¡Œä¸ºï¼Œå®æ—¶æ·»åŠ åˆ°è¡Œä¸ºåˆ—è¡¨ä¸­
            if behaviors and len(behaviors) > 0:
                frame_time = frame_index / self.video_fps if self.video_fps > 0 else 0
                
                for behavior in behaviors:
                    behavior_type = behavior.get('type', 'æœªçŸ¥è¡Œä¸º')
                    probability = behavior.get('probability', 0)
                    
                    # æ·»åŠ è¡Œä¸ºåˆ°ç•Œé¢åˆ—è¡¨
                    self.add_behavior_to_list(
                        frame=frame_index, 
                        time_point=frame_time, 
                        behavior_type=behavior_type, 
                        probability=probability
                    )
                    
                    # å¦‚æœæ˜¯é«˜å¯ä¿¡åº¦è¡Œä¸ºï¼Œè¾“å‡ºæ›´è¯¦ç»†çš„æ—¥å¿—
                    if probability > 0.7:
                        self.log(f"æ£€æµ‹åˆ°é«˜å¯ä¿¡åº¦è¡Œä¸º: {behavior_type}ï¼Œåœ¨å¸§ {frame_index}ï¼Œå¯ä¿¡åº¦: {probability:.2%}")
        except Exception as e:
            self.log(f"å¸§å›è°ƒå¤„ç†é”™è¯¯: {str(e)}", console_only=True)
            
    def analyze_environment_in_video(self, sample_frames):
        """åˆ†æè§†é¢‘ä¸­çš„ç¯å¢ƒç±»å‹"""
        try:
            all_retail_environment_results = []
            true_count = 0
            
            for i, frame in enumerate(sample_frames):
                try:
                    self.log(f"åˆ†æè§†é¢‘ç¯å¢ƒ - é‡‡æ ·å¸§ {i+1}/{len(sample_frames)}", console_only=True)
                    
                    # ä½¿ç”¨è§†è§‰ç‰¹å¾åˆ¤æ–­ç¯å¢ƒ
                    is_retail = self.is_retail_environment_by_visual_features(frame)
                    all_retail_environment_results.append(is_retail)
                    
                    if is_retail:
                        true_count += 1
                        
                except Exception as e:
                    self.log(f"ç¯å¢ƒåˆ¤æ–­å‡ºé”™: {str(e)}", console_only=True)
            
            # åŸºäºæ‰€æœ‰é‡‡æ ·å¸§ç»“æœåˆ¤æ–­
            if len(all_retail_environment_results) > 0:
                # å¦‚æœè¶…è¿‡40%çš„å¸§åˆ¤æ–­ä¸ºé›¶å”®ç¯å¢ƒï¼Œåˆ™è§†ä¸ºé›¶å”®ç¯å¢ƒ
                self.is_retail_environment = true_count / len(all_retail_environment_results) > 0.4
                self.log(f"åŸºäºè§†é¢‘ä¸­çš„{len(all_retail_environment_results)}å¸§åˆ†æï¼Œç¯å¢ƒåˆ¤æ–­ä¸º: {'é›¶å”®ç¯å¢ƒ' if self.is_retail_environment else 'éé›¶å”®ç¯å¢ƒ'} (é›¶å”®åˆ¤æ–­ç‡: {true_count/len(all_retail_environment_results):.2%})")
            else:
                self.is_retail_environment = False
                self.log("æ— æ³•ç¡®å®šç¯å¢ƒç±»å‹ï¼Œé»˜è®¤ä¸ºéé›¶å”®ç¯å¢ƒ")
                
            return all_retail_environment_results, true_count
            
        except Exception as e:
            self.log(f"é‡‡æ ·å¸§åˆ†æé”™è¯¯: {str(e)}", console_only=True)
            self.is_retail_environment = False
            return [], 0

    def update_canvas_sizes(self):
        """æ›´æ–°ç”»å¸ƒå°ºå¯¸ï¼Œä¿æŒå›ºå®šæ¯”ä¾‹"""
        # è·å–å¯ç”¨ç©ºé—´å¤§å°
        available_width = self.root.winfo_width() - 50  # å‡å»è¾¹è·
        available_height = self.root.winfo_height() - 200  # å‡å»å…¶ä»–UIå…ƒç´ çš„é«˜åº¦
        
        # ç¡®ä¿å€¼æœ‰æ•ˆ
        if available_width <= 1 or available_height <= 1:
            available_width = max(self.default_width - 50, 800)
            available_height = max(self.default_height - 200, 400)
        
        # è®¡ç®—æ¯ä¸ªç”»å¸ƒçš„å°ºå¯¸ï¼ˆè€ƒè™‘å·¦å³å„å ä¸€åŠï¼‰
        canvas_width = int(available_width / 2 - 20)  # å‡å»åˆ†éš”è¾¹è·
        
        # ä½¿ç”¨16:9çš„å®½é«˜æ¯”
        canvas_height = int(canvas_width * 9 / 16)
        
        # é™åˆ¶é«˜åº¦ï¼Œç¡®ä¿ä¸è¶…è¿‡å¯ç”¨ç©ºé—´
        if canvas_height > available_height:
            canvas_height = available_height
            canvas_width = int(canvas_height * 16 / 9)
        
        # è®¾ç½®ç”»å¸ƒå¤§å°
        self.original_canvas.config(width=canvas_width, height=canvas_height)
        self.processed_canvas.config(width=canvas_width, height=canvas_height)
        
        # æ›´æ–°ç”»å¸ƒæ¡†æ¶å¤§å°
        self.original_canvas_frame.config(width=canvas_width, height=canvas_height)
        self.processed_canvas_frame.config(width=canvas_width, height=canvas_height)
        
        # é‡æ–°æ˜¾ç¤ºå½“å‰åª’ä½“å†…å®¹
        self.redisplay_current_media(canvas_width, canvas_height)
        
        # ç¡®ä¿UIå…ƒç´ é€‚åº”æ–°å°ºå¯¸
        self.root.update_idletasks()

def main():
    """Main function to run the application"""
    root = tk.Tk()
    app = TheftDetectionApp(root)
    root.mainloop()

if __name__ == "__main__":
    main() 